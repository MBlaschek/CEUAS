{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecc89777-4cd7-4ad7-bb6c-df06d91ec97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# datasets locations\n",
    "base = '/scratch/das/federico/databases_service2/'\n",
    "npsound = 'NPSOUND-NSIDC0060'\n",
    "hara = 'HARA-NSIDC-0008'\n",
    "ship = 'SHIPSOUND-NSIDC-0054'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dd90f0-a4f4-4b9e-9acf-69d90aecbd39",
   "metadata": {},
   "source": [
    "# NPSOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1604b-6ed3-4542-8bc1-931d7005a31a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d8c2323-3b97-466a-b6e4-7fbfd01ff4c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2010d541-191a-40be-afe0-5a981e9fbefb",
   "metadata": {},
   "source": [
    "# HARA\n",
    "https://nsidc.org/sites/default/files/nsidc-0008-v001-userguide.pdf\n",
    "\n",
    "... As a compromise, the following file structure is used: One file contains a one-year time series of\n",
    "soundings for one station. \n",
    "\n",
    "\n",
    "*1.2.1 Header Record*\n",
    "1. STATION\n",
    "World Meteorological Organization (WMO) station identification number. All stations are ascribed a\n",
    "WMO number, with the exception of \"SHIP M\" (Figure 1; Appendix 1). This was arbitrarily\n",
    "assigned a station code of 80000.\n",
    "2. LATITUDE\n",
    "Latitude of the station in degrees and hundredths of a degree (N).\n",
    "3. LONGITUDE\n",
    "Longitude from 0 to 360 degrees, in degrees and hundredths of a degree, measured\n",
    "counterclockwise from the Greenwich Meridian as viewed from the pole.\n",
    "4. YEAR\n",
    "Year of sounding.\n",
    "5. MONTH\n",
    "Month of sounding.\n",
    "6. DAY\n",
    "Day of sounding.\n",
    "7. HOUR\n",
    "Hour of sounding. This is usually 0000 GMT, 0600 GMT, 1200 GMT, or 1800 GMT. Prior to 1952,\n",
    "however, soundings reported at 0800 GMT and 1400 GMT.\n",
    "8.-10. PROC1, PROC2, PROC3\n",
    "Special processing codes. These are only available for sounding type ID=1. They provide\n",
    "information on special processing, and whether soundings were manually or automatically\n",
    "processed (see Appendix 4). For all other sounding types (ID=2, 3, 4 or 5), PROC1, PROC2, and\n",
    "PROC3 are assigned blanks. Pages 6 and 7 of Office Note 29 (Mulder (1977)), which describe\n",
    "these codes for the ID=1 data, are given in Appendix 5.\n",
    "11. REP\n",
    "Report type. This will always be assigned the value of 011 or 0. It denotes that the sounding was\n",
    "taken at a fixed land station.\n",
    "12. ELEVATION\n",
    "Station elevation in meters above mean sea level. Missing values are 99999.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7c904-a187-41e9-8514-82f4ac423153",
   "metadata": {},
   "source": [
    "1.2.2 Data Records\n",
    "The variables are as follows:\n",
    "1. PRESSURE\n",
    "Pressure in tenths of millibars. Data from most stations are rounded to the nearest 1 mb. Missing\n",
    "values are 99999.\n",
    "2. GEOPOTENTIAL HEIGHT\n",
    "Geopotential height of the pressure level in whole meters. Missing values are 99999.\n",
    "3. TEMPERATURE\n",
    "Temperature in tenths of a degree (degrees C). Missing values are 9999.\n",
    "4. DEWPOINT DEPRESSION\n",
    "Dewpoint depression in tenths of a degree (degrees C). Missing values are 999.\n",
    "5. WIND DIRECTION\n",
    "Wind direction, 0 to 360 degrees, measured clockwise from north (e.g., 90 degrees is east).\n",
    "Missing values are 999.\n",
    "6. WIND SPEED\n",
    "Wind speed in whole meters per second. Missing values are 999.\n",
    "7.-15. QG, QG1, QT, QT1, QD, QD1, QW, QW1, QP\n",
    "Quality control flags for geopotential height (QG, QG1), temperature (QT, QT1), dewpoint\n",
    "depression (QD, QD1), winds (QW, QW1), and pressure (QP). The values of QG, QT, QD, QW,\n",
    "and QP depend on the sources of the sounding as identified by the value of ID (see Appendix 4).\n",
    "These vary considerably among the sources of the original soundings, and on whether the original \n",
    "USER GUIDE: Historical Arctic Rawinsonde Archive, Version 1\n",
    "Page 5 of 37 National Snow and Ice Data Center\n",
    "nsidc.org\n",
    "processing was accomplished automatically (via computer) or manually (designated by \"auto\" or\n",
    "\"man\" Appendix 4). QG1, QT1, QD1 and QW1 are additional quality code flags for geopotential\n",
    "height, temperature, dewpoint depression, and winds, based on our error-checking procedure,\n",
    "described earlier. Values are either 'P' (passed limits check) or 'F' (failed limits check). No limits\n",
    "check quality flag is given for pressure, as we used pressure as the test variable in the limits check.\n",
    "*(These additional codes are not available on Volume 5. Please see Revision below.)\n",
    "16. LEVCK\n",
    "A quality control flag set to 'P' if no errors were detected in the level for any variable, based on the\n",
    "limits check described above. If any errors were detected in the limits check, it is set to 'F'. *(This\n",
    "variable is not available on Volume 5. Please see Revision below.)\n",
    "17. LTYPE\n",
    "Code for level type (surface, significant, or mandatory). Only relevant for soundings of type ID=4\n",
    "(see Appendix 4). For sounding types other than ID=4, the value is assigned a blank. This variable\n",
    "is not available on Volume 5. Please see Revision below.\n",
    "18. LQUAL\n",
    "Flag for quality of level. Only relevant for soundings of type ID=4 (see Appendix 4). This variable is\n",
    "not available on Volume 5. Please see Revision below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f18d4768-7409-4b42-b4d9-962466e11ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 1187.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# find all stations_id\n",
    "\n",
    "stations = []\n",
    "years = os.listdir( base + '/' + hara )\n",
    "for year in tqdm(years):\n",
    "    ydir = base + '/' + hara  + '/' + year\n",
    "    files = os.listdir( ydir )\n",
    "    for f in files:\n",
    "        stat = f.split('.')[0]\n",
    "        if stat not in stations:\n",
    "            stations.append(stat)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85975444-5236-46e2-bd89-48584fb5e774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['70026', '71072', '71074', '71917', '71918']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f068f97-a714-4a9b-96b6-7fae7ca67458",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = os.listdir( base + '/' + hara )\n",
    "\n",
    "meta_dic = {}\n",
    "\n",
    "for v in ['stationid' , 'latitude' , 'longitude' , 'elevation', 'date']:\n",
    "    meta_dic[v] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b8655bb-57d3-4739-a132-211eeb73d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#year\n",
    "def read_hara_data(file):\n",
    "    stat = file.split('/')[-1].split('.')[0]\n",
    "    year = file.split('/')[-2]\n",
    "    #print(stat)\n",
    "    data = {}\n",
    "    var = ['date_time', 'gph', 'temp', 'dew', 'windsp', 'winddir', 'lat', 'lon', 'pressure','month','day','year','hour', 'elev']\n",
    "    for v in var:\n",
    "        data[v] = []\n",
    "        \n",
    "    with open(file, 'r', errors='replace') as filee:\n",
    "        lines = filee.readlines()\n",
    "    \n",
    "    for l in lines:\n",
    "        if stat == l[0:5]:\n",
    "            lat_deg = l[5:8]\n",
    "            lat_cent = l[8:10]\n",
    "            lon_deg = l[10:13]\n",
    "            lon_cent = l[13:15]\n",
    "            lat = float( lat_deg + '.' + lat_cent )\n",
    "            lon = float( lon_deg + '.' + lon_cent )\n",
    "            \n",
    "            if '289.97' in str(lat):\n",
    "                print(file, '  ' , l)\n",
    "            if '289.97' in str(lon):\n",
    "                print(file, '  ' , l)\n",
    "                \n",
    "            # fix problems when reading files with inconsistent coordinates convention \n",
    "            if stat == 20667 and lon == '289.97':\n",
    "                lon = '70.03'\n",
    "                \n",
    "            y,m,d = str(year), str(l[18:20]).replace(' ','') , str(l[20:22]).replace(' ','')\n",
    "            if len(m) < 2 : m = '0' + m\n",
    "            if len(d) < 2 : d = '0' + d\n",
    "            \n",
    "            hour = str(l[22:24]).replace(' ','')\n",
    "\n",
    "            date_time = y + '-' + str(m) + '-' + str(d)\n",
    "        \n",
    "            elev = l.split(' ')[-1].replace('\\n', '')\n",
    "\n",
    "        else:\n",
    "            pressure = l[:6]\n",
    "            gph = l[6:12]\n",
    "            temp = l[12:17]\n",
    "            dew = l[17:21]\n",
    "            \n",
    "            winddir =l[21:25]\n",
    "            windsp = l[25:29]\n",
    "        \n",
    "            data['date_time'].append(date_time)\n",
    "            data['pressure'].append(pressure)\n",
    "            data['gph'].append(gph)\n",
    "            data['temp'].append(temp)\n",
    "\n",
    "            data['dew'].append(dew)\n",
    "            data['windsp'].append(windsp)\n",
    "            data['winddir'].append(winddir)\n",
    "            data['lat'].append(lat)\n",
    "            data['lon'].append(lon)\n",
    "            \n",
    "            data['month'].append(m)\n",
    "            data['year'].append(y)\n",
    "            data['day'].append(d)\n",
    "            data['hour'].append(hour)\n",
    "\n",
    "            data['elev'].append(elev)\n",
    "\n",
    "    df = pd.DataFrame( data )\n",
    "    \n",
    "    return df \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f172939d-54a8-42e8-a2f7-e552c50721ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = '1948/70026.48'\n",
    "d = read_hara_data(base + '/' + hara + '/1948/70026.48' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "521b439f-11e0-452f-b422-1ed90e5500be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>gph</th>\n",
       "      <th>temp</th>\n",
       "      <th>dew</th>\n",
       "      <th>windsp</th>\n",
       "      <th>winddir</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>pressure</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>hour</th>\n",
       "      <th>elev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>-191</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>71.28</td>\n",
       "      <td>203.23</td>\n",
       "      <td>9870</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>1948</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>280</td>\n",
       "      <td>-212</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>71.28</td>\n",
       "      <td>203.23</td>\n",
       "      <td>9500</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>1948</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>686</td>\n",
       "      <td>-239</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>70</td>\n",
       "      <td>71.28</td>\n",
       "      <td>203.23</td>\n",
       "      <td>9000</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>1948</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>1101</td>\n",
       "      <td>-251</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>80</td>\n",
       "      <td>71.28</td>\n",
       "      <td>203.23</td>\n",
       "      <td>8500</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>1948</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1948-01-01</td>\n",
       "      <td>1545</td>\n",
       "      <td>-200</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>90</td>\n",
       "      <td>71.28</td>\n",
       "      <td>203.23</td>\n",
       "      <td>8000</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>1948</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    date_time     gph   temp   dew windsp winddir    lat     lon pressure  \\\n",
       "0  1948-01-01      8   -191    32      7      80   71.28  203.23    9870    \n",
       "1  1948-01-01    280   -212    29     10      70   71.28  203.23    9500    \n",
       "2  1948-01-01    686   -239    28     12      70   71.28  203.23    9000    \n",
       "3  1948-01-01   1101   -251    28     17      80   71.28  203.23    8500    \n",
       "4  1948-01-01   1545   -200    31     22      90   71.28  203.23    8000    \n",
       "\n",
       "  month day  year hour elev  \n",
       "0    01  01  1948    3    4  \n",
       "1    01  01  1948    3    4  \n",
       "2    01  01  1948    3    4  \n",
       "3    01  01  1948    3    4  \n",
       "4    01  01  1948    3    4  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4db84fcd-6ef8-46ef-9efa-fbee4f59cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_ = stations[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01400c-c7a7-47e2-9c09-5837385217d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b97d6496-9dfa-4bc7-a272-2b9dc45a95f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [s for s in stations if '20667' in s ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff276bf-3476-4bad-92fb-cd005e592387",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1027cab9-fa23-4503-a8bb-bd9e2664bb89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 43/49 [00:00<00:00, 135.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/das/federico/databases_service2//HARA-NSIDC-0008/1973/20667.73    20667 733328997 73 810 0 990 11    612  12 1\n",
      "\n",
      "/scratch/das/federico/databases_service2//HARA-NSIDC-0008/1973/20667.73    20667 733328997 7310 1 0 990 11    612  14 1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [00:00<00:00, 136.47it/s]\n"
     ]
    }
   ],
   "source": [
    "for s in stats:\n",
    "    all_station_df = []\n",
    "    \n",
    "    for year in tqdm(years):\n",
    "        ydir = base + '/' + hara  + '/' + year\n",
    "        files = os.listdir( ydir )\n",
    "        for f in files:\n",
    "            file = ydir+'/'+f\n",
    "            if s not in file:\n",
    "                continue\n",
    "\n",
    "            #print(file)\n",
    "            data = read_hara_data(file)\n",
    "            all_station_df.append(data)\n",
    "            \n",
    "    station_df = pd.concat(all_station_df)\n",
    "\n",
    "    # saving the concatenated dataframe to csv \n",
    "    out_dir = '/scratch/das/federico/databases_service2/HARA-NSIDC-0008_csv/'\n",
    "    #station_df.to_csv(out_dir + '/' + s + '_stationfile.csv' , sep = '\\t' , index= False )\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e87541-1678-4fa9-8e2b-5b9d4786ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa56606-cbcd-46cd-bbb6-61194a27eba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "647879f2-c7d1-4812-9453-d019e77e16c2",
   "metadata": {},
   "source": [
    "## Analyze inventory directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17ae7ee6-193b-4917-a01e-8a61a2feb183",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_dir = '/users/staff/federico/GitHub/CEUAS_master_JULY2922/CEUAS/CEUAS/meta/inventory_comparison_2/code/inventories/hara'\n",
    "\n",
    "files = [f for f in os.listdir(inventory_dir) ]\n",
    "\n",
    "ident  = [f for f in files if '_ident' in f ]\n",
    "unid   = [f for f in files if 'noDist' in f ]\n",
    "incons = [f for f in files if 'inco' in f ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "568213d9-a659-4e2b-b2ee-6c91ed9f1f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDENTIFIED:  80\n",
      "UNIDENTIFIED:  2\n",
      "INCOSISTENT COORD:  7\n"
     ]
    }
   ],
   "source": [
    "print('IDENTIFIED: ' , len(ident) ) \n",
    "print('UNIDENTIFIED: ' , len(unid) ) \n",
    "print('INCOSISTENT COORD: ' , len(incons) ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b353e27d-2ad8-4193-a4b2-c1b58b30f9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea9d9d9d-f655-443a-8461-5320f3eb4313",
   "metadata": {},
   "source": [
    "## Analyze station configuration file \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed022f2d-cdf8-428f-a249-804d36849105",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = '/users/staff/federico/GitHub/CEUAS_master_JULY2922/CEUAS/CEUAS/meta/inventory_comparison_2/code/station_configuration/hara_station_configuration_extended.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "561270e9-a4c5-404f-b7c1-27560243a84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0-20000-0-25282', '0-20000-0-23383', '0-20000-0-22235',\n",
       "       '0-20700-0-04210', '0-20000-0-04330', '0-20000-0-21908',\n",
       "       '0-20001-0-01010', '0-20000-0-04231', '0-20000-0-25248',\n",
       "       '0-20000-0-23552'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scdf = pd.read_csv(sc, sep = '\\t')\n",
    "hara_ids = scdf.primary_id.values\n",
    "ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce96286-c31f-48eb-83fc-92c3de31ab83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50899841-8674-467a-bc1b-3137d551fce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0c0a4ab-6f2b-45b1-9fe4-012f50ed4890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all ids found in the merged directory\n",
    "merged_ids = [s.split('_')[0] for s in os.listdir('/scratch/das/federico/MERGED_FEB2023') if '.nc' in s and 'Sensor' not in s ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6900a8e3-8fe6-495a-b6e9-8d103b2b7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stations in HARA dataset but not in merged\n",
    "missing_hara = [s for s in hara_ids if s not in merged_ids ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9cf6c2e8-d8c8-4c36-b2e1-b818c2730b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING HARA STATIONS:  9\n",
      "0-20000-0-23383\n",
      "0-20700-0-04210\n",
      "0-20000-0-25248\n",
      "0-20300-0-04310\n",
      "0-20300-0-04340\n",
      "0-20000-0-71090\n",
      "0-20000-0-71938\n",
      "0-20300-0-71051\n",
      "0-20300-0-71072\n"
     ]
    }
   ],
   "source": [
    "print('MISSING HARA STATIONS: ' , len(missing_hara) )\n",
    "for s in missing_hara:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a8878b-2421-4d62-90d4-7109e1fd9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "4\tNorth America, Central America and the Caribbean\tCanada\tCAN\t0-20000-0-71072\t71072\t0\tTHUNDER BAY, ONT\t48 22 19N\t089 19 18W\t199.30\t\t199.30\t\tmean sea level\t\t\t\t\t\t\t\t\t\t\t\t\t\tSurface land meteorological station (SYNOP), GOS\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
