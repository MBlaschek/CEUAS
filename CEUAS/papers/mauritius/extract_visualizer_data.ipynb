{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6fb64e7-95d0-436f-af81-1c001a5a3733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data from the Mauritius harvested files to compatible format for the visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca3f6b7-41f9-414b-b7b0-13b0b97418ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2894138/2179053797.py:10: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import h5py as h5\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7603f6a-1244-41e1-bc45-71a8bd3b1b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inter_files = [data+'/'+f for f in os.listdir('/data') if 'intercomparison' in f ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd45a58-07fc-4b91-8f0c-fa66f39ff082",
   "metadata": {},
   "source": [
    "### document\n",
    "https://wmoomm.sharepoint.com/sites/wmocpdb/eve_activityarea/Forms/AllItems.aspx?id=%2Fsites%2Fwmocpdb%2Feve%5Factivityarea%2FInstruments%20and%20Methods%20of%20Observation%20Programme%20%28IMOP%29%5F67452102%2D7575%2De911%2Da98e%2D000d3a44bd9c%2FIntercomparisons%2FPast%20Intercomparisons%2FRSO%2DIC%2D2005%5FFinal%5FReport%2Epdf&parent=%2Fsites%2Fwmocpdb%2Feve%5Factivityarea%2FInstruments%20and%20Methods%20of%20Observation%20Programme%20%28IMOP%29%5F67452102%2D7575%2De911%2Da98e%2D000d3a44bd9c%2FIntercomparisons%2FPast%20Intercomparisons&p=true&ga=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baaffd12-98cf-4ab6-8b2a-91b72d8b37c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "digitized = '/scratch/das/federico/databases_service2/MAURITIUS/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bdb939a-57f9-4c55-839e-9cecb50b5ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Graw', 'Graw-GPS', 'MKII', 'Meisei', 'Modem', 'SRS', 'Sip',\n",
       "       'Vaisala', 'Vaisala-GPS'], dtype='<U11')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### create a single file for each sonde type\n",
    "\n",
    "# extracting the list of different sensor types\n",
    "sonde_types = np.unique( [ f.split('_')[1].split('.csv')[0] for f in os.listdir(digitized+'/temp/') if '.csv' in f  ])\n",
    "sonde_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43ba48af-7278-408a-bf72-570de07380e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating single files out of the single ascent files, per sensor \n",
    "\n",
    "# output directory for the processed files \n",
    "outdir = 'data_processed'\n",
    "if not os.path.isdir(outdir):\n",
    "    os.mkdir(outdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e986cd3f-f16f-4366-83a9-d3b912fbbc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975fc287-4ff6-4794-be69-a6d68194b960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/users/staff/federico/GitHub/CEUAS_master_JULY2922/CEUAS/CEUAS/papers/mauritius'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "972fb73a-7acd-4c7e-98a7-be08481af592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting temperature data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 21.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting humidity data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:01<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting temperature data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 27.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting humidity data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:01<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting temperature data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 29.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting humidity data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting temperature data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:01<00:00, 24.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting humidity data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:02<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting temperature data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:01<00:00, 25.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting humidity data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting temperature data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:01<00:00, 25.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting humidity data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:01<00:00, 19.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting temperature data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 24.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting humidity data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:02<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting temperature data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:02<00:00, 28.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting humidity data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:04<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting temperature data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:02<00:00, 26.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Extracting humidity data +++ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:03<00:00, 15.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating single files out of the single ascent files, per sensor \n",
    "\n",
    "# output directory for the processed files \n",
    "outdir = 'data_processed'\n",
    "if not os.path.isdir(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "#sonde_types = ['Vaisala']\n",
    "\n",
    "# looping over each distinct sensor, all the ascents\n",
    "for s in sonde_types:\n",
    "\n",
    "    ### temperature\n",
    "    print('+++ Extracting temperature data +++ ')\n",
    "    all_df_temp = []\n",
    "    files_temp = [ digitized + '/temp/' + f for f in os.listdir(digitized+'/temp/') if f.split('_')[1].split('.csv')[0]== s ]  \n",
    "    files_temp.sort()\n",
    "    for f in tqdm(files_temp):\n",
    "        df_temp = pd.read_csv(f , sep = ',' )\n",
    "        df_temp = df_temp[ [c for c in df_temp.columns if c in ['press','datetime','temp','hum']] ] \n",
    "        all_df_temp.append(df_temp)\n",
    "\n",
    "    df_sum_temp = pd.concat(all_df_temp)\n",
    "    df_sum_temp = df_sum_temp.round(decimals=2)\n",
    "    df_sum_temp['datetime'] = pd.to_datetime(df_sum_temp.datetime,  utc=True)\n",
    "    df_sum_temp = df_sum_temp.dropna(subset=['press'])\n",
    "    df_sum_temp['press'] = df_sum_temp.press.astype(int)\n",
    "\n",
    "    df_sum_temp.to_csv( outdir + '/' + s + '_all_ascents_temp.csv' , sep ='\\t' )\n",
    "\n",
    "    \n",
    "    ### humidity    \n",
    "    print('+++ Extracting humidity data +++ ')\n",
    "    all_df_hum = []\n",
    "    files_hum = [ digitized + '/hum/' + f for f in os.listdir(digitized+'/hum/') if f.split('_')[1].split('.csv')[0]== s ]\n",
    "    files_hum.sort()\n",
    "    for f in tqdm(files_hum):\n",
    "        df_hum = pd.read_csv(f , sep = ',' )\n",
    "        df_hum = df_hum[ [c for c in df_hum.columns if c in ['press','datetime','temp','hum']] ] \n",
    "        all_df_hum.append(df_hum)\n",
    "\n",
    "    df_sum_hum = pd.concat(all_df_hum)\n",
    "    df_sum_hum = df_sum_hum.round(decimals=2)\n",
    "    df_sum_hum['datetime'] = pd.to_datetime(df_sum_hum.datetime, utc=True )\n",
    "    df_sum_hum = df_sum_hum.dropna(subset=['press'])\n",
    "    df_sum_hum['press'] = df_sum_hum.press.astype(int)\n",
    "    df_sum_hum.to_csv( outdir + '/' + s + '_all_ascents_hum.csv' , sep ='\\t' )\n",
    "    \n",
    "    \n",
    "    # merging temp and hum data in one single file per sonde \n",
    "    all_times = list( np.unique(df_sum_temp.datetime) ) + list( np.unique(df_sum_hum.datetime) ) \n",
    "\n",
    "    all_df = []\n",
    "    for dt in all_times:\n",
    "        hum = df_sum_hum.loc[df_sum_hum['datetime'] == dt ][['press','hum']]\n",
    "        temp = df_sum_temp.loc[df_sum_temp['datetime'] == dt ][['press','temp']]\n",
    "\n",
    "        mer= pd.merge(hum,temp, on='press', how='outer')\n",
    "\n",
    "        #mer = pd.concat( [ hum.join(temp, on='press'), temp.join(hum, on='press') ]  ).drop_duplicates(subset=['press'] )\n",
    "        #mer = mer[['press','hum','temp']]\n",
    "        mer['datetime'] = dt \n",
    "        all_df.append(mer)\n",
    "\n",
    "\n",
    "    df = pd.concat(all_df)\n",
    "    df = df.sort_values(by=['datetime','press']) \n",
    "    df.to_csv( outdir + '/' + s + '_all_ascents_fulldata.csv' , sep ='\\t' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f70cb2e1-597a-4305-a947-8b8fa86a8a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>press</th>\n",
       "      <th>temp</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>431</td>\n",
       "      <td>300.48</td>\n",
       "      <td>2005-07-02 10:01:53.551000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>435</td>\n",
       "      <td>298.65</td>\n",
       "      <td>2005-07-02 10:01:53.551000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439</td>\n",
       "      <td>300.80</td>\n",
       "      <td>2005-07-02 10:01:53.551000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>443</td>\n",
       "      <td>299.38</td>\n",
       "      <td>2005-07-02 10:01:53.551000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>448</td>\n",
       "      <td>298.38</td>\n",
       "      <td>2005-07-02 10:01:53.551000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   press    temp                         datetime\n",
       "0  431    300.48 2005-07-02 10:01:53.551000+00:00\n",
       "1  435    298.65 2005-07-02 10:01:53.551000+00:00\n",
       "2  439    300.80 2005-07-02 10:01:53.551000+00:00\n",
       "3  443    299.38 2005-07-02 10:01:53.551000+00:00\n",
       "4  448    298.38 2005-07-02 10:01:53.551000+00:00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_sum_temp)\n",
    "df_sum_temp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b1451f-8812-46c2-b699-8544748d29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum_temp.datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde1aae8-8221-43d0-bb8a-d0b2baa2bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_times = list( np.unique(df_sum_temp.datetime) ) + list( np.unique(df_sum_hum.datetime) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9512ee-dfa3-4fac-a4af-c17522e85473",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_times[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b92d1d-a5ee-4811-ba88-d032afb69fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df_sum_hum)\n",
    "#df_sum_hum.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07e14a-2e92-45bc-be75-59ca372ad860",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = []\n",
    "for dt in all_times:\n",
    "    hum = df_sum_hum.loc[df_sum_hum['datetime'] == dt ]\n",
    "    temp = df_sum_temp.loc[df_sum_temp['datetime'] == dt ]\n",
    "\n",
    "    mer= pd.merge(a,b, on='press', how='outer')\n",
    "    mer = mer[['press','hum','temp']]\n",
    "    mer['datetime'] = dt \n",
    "    all_df.append(mer)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ac4285-ebea-434d-94d5-8d5a179f133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8fb197-f109-4222-af54-788f9ba4f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca447940-c28a-437d-8c7d-a9f927490c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823ae511-d375-4cab-b8cc-3e6aec305c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hum = df_sum_hum.loc[df_sum_hum['datetime'] == all_times[3] ][['hum','press']] [:100]\n",
    "#temp = df_sum_temp.loc[df_sum_temp['datetime'] == all_times[3] ][['temp','press']] [:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ec76f-3000-4cec-91dc-1fea778b2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mer= pd.merge(hum, temp , on='press', how='outer')\n",
    "#mer2= pd.merge(temp, hum , on='press', how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a04b6d-1c31-4313-8f01-4911321b0518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_join = df_sum_hum.join(df_sum_temp,  lsuffix='l' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b781f9be-e7d7-425e-868d-e83899078d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sum_hum = df_sum_hum.set_index('datetime')\n",
    "#df_sum_temp = df_sum_temp.set_index('datetime')\n",
    "\n",
    "\n",
    "#a = df_sum_hum[:100]\n",
    "#b = df_sum_temp[:100]\n",
    "\n",
    "#a['press'] = a.press.astype(int)\n",
    "#b['press'] = b.press.astype(int)\n",
    "\n",
    "#a = a.set_index(['press', 'datetime'])\n",
    "#b = b.set_index(['press', 'datetime'])\n",
    "\n",
    "#df_join = a.join(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15c2581-bc21-4de4-9a29-02ab0ce62ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c3b0ac-7f46-4682-a331-196e9abce347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88c5a0-d45a-45d3-bdd5-5e717423bf67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ebeae-4d8e-4878-a00f-8433a1489462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30d2f8-c883-47d7-a457-cb630a91626f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d75ba15-c3f0-40e7-bbf0-145534082ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd98388-14af-4d82-9a30-53abb19c839e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497c69f0-d9c3-40b1-a544-676e7288af0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1247475-0114-49e5-a101-6599a17a72a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369cc5fa-729f-4f69-92bb-0f48e87a1668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380df72a-673a-4861-9e0a-5fdbf4d0452c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b45fc1-00b3-4440-9cb4-528da7bd43fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8610688b-692b-47e2-8d1a-390083685046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a305ae25-47e8-49eb-9531-77a329e7a9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ccc6e-e639-4641-9f04-0e07998ff8b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d1891-c651-4a16-a0d0-946ef7502c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
