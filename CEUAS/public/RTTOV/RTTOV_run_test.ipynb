{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "962c2df8-e468-42bc-804a-e3b33563aae8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jetfs/manual/rttov/v13.2-gcc-8.5.0/bin/python\n",
      "sys.version_info(major=3, minor=9, micro=0, releaselevel='final', serial=0)\n",
      "no config found\n"
     ]
    }
   ],
   "source": [
    "# System information\n",
    "import pyrttov\n",
    "import numpy as np\n",
    "import os, sys, glob\n",
    "import xarray\n",
    "import xarray as xr\n",
    "print(sys.executable)\n",
    "print(sys.version_info)\n",
    "import pandas as pd\n",
    "import pandas\n",
    "# sys.path.append('/users/staff/uvoggenberger/CEUAS/CEUAS/public/cds-backend/code/')\n",
    "sys.path.append(os.getcwd()+'/../cds-backend/code/')\n",
    "import cds_eua4 as eua\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "# import ray\n",
    "# import time\n",
    "# ray.init(num_cpus=40)\n",
    "\n",
    "# @ray.remote\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1157d56-cf21-4ccb-ba35-256c7fb63320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ef(p, t=None, over_water=True, over_ice=False, **kwargs):\n",
    "    \"\"\"\n",
    "    from\n",
    "    Sugidachi, T. and Fujiwara, M.: Correction of the Stepwise Change Observed at 0C in\n",
    "    Meisei RS2-91, RS-01G, and RS-06G Radiosonde Relative Humidity Profiles,\n",
    "    Journal of the Meteorological Society of Japan. Ser. II, 91(3), 323-336,\n",
    "    doi:10.2151/jmsj.2013-306, 2013.\n",
    "\n",
    "    Args:\n",
    "        t: air temperature K\n",
    "        p: air pressure Pa\n",
    "\n",
    "    Returns:\n",
    "        f : enhancement factor for saturation water vapor pressure\n",
    "            depending on air temperature and air pressure\n",
    "    \"\"\"\n",
    "    # Vaisala / Buck 1981  / WMO 2008\n",
    "    # 1.0016 + 3.15e-6*p - 0.074 / p  # kPa\n",
    "    if over_water:\n",
    "        return 1.0007 + (3.46e-6 * p / 100)\n",
    "    if over_ice:\n",
    "        return 1.0003 + (4.18e-6 * p / 100)\n",
    "    if t is not None:\n",
    "        return np.where(t < 273.16,\n",
    "                        1.0003 + (4.18e-6 * p / 100),\n",
    "                        1.0007 + (3.46e-6 * p / 100))\n",
    "\n",
    "def HylandWexler(temp, over_water=True, over_ice=False, **kwargs):\n",
    "    \"\"\"Hyland and Wexler (1983), also in Wexler and Hyland (1983): Stated ranges 173.16 ?\n",
    "    T < 273.16 for ice and 273.16 > 473.15 for liquid.\n",
    "\n",
    "    Used by Vaisala\n",
    "\n",
    "    ln( ew ) = -5800.2206/t + 1.3914993\n",
    "               - 0.48640239 * 10**(-1)*t\n",
    "               + 0.41764768 * 10**(-4)*t**2\n",
    "               - 0.14452093 * 10**(-7)*t**3\n",
    "               + 6.5459673*math.log(t)\n",
    "\n",
    "    ln( ei ) = -5674.5359/t + 6.3925247\n",
    "               - 0.96778430 * 10**(-2)*t\n",
    "               + 0.62215701 * 10**(-6)*t**2\n",
    "               + 0.20747825 * 10**(-8)*t**3\n",
    "               - 0.94840240 * 10**(-12)*t**4\n",
    "               + 4.1635019*math.log(t)\n",
    "\n",
    "    Args:\n",
    "        temp: air temperature in K\n",
    "        liquid_only: use only water vapor over liquid water\n",
    "        ice_only: use only water vapor over ice\n",
    "        kwargs: dummy\n",
    "\n",
    "    Returns:\n",
    "         es : saturation water vapor pressure in Pa\n",
    "    \"\"\"\n",
    "\n",
    "    def liquid(t):\n",
    "        return np.exp(\n",
    "            -5800.2206 / t + 1.3914993\n",
    "            - 0.48640239e-1 * t\n",
    "            + 0.41764768e-4 * t * t\n",
    "            - 0.14452093e-7 * t * t * t\n",
    "            + 6.5459673 * np.log(t)\n",
    "        )\n",
    "\n",
    "    def ice(t):\n",
    "        return np.exp(\n",
    "            -5674.5359 / t + 6.3925247\n",
    "            - 0.96778430e-2 * t\n",
    "            + 0.62215701e-6 * t * t\n",
    "            + 0.20747825e-8 * t * t * t\n",
    "            - 0.94840240e-12 * t * t * t * t\n",
    "            + 4.1635019 * np.log(t)\n",
    "        )\n",
    "\n",
    "    if over_water:\n",
    "        return liquid(temp)\n",
    "    elif over_ice:\n",
    "        return ice(temp)\n",
    "    else:\n",
    "        return np.where(temp < 273.16, ice(temp), liquid(temp))\n",
    "    \n",
    "def svp(t, method='HylandWexler', p=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Saturation water vapor pressure from Temperature\n",
    "    The equations by Hyland and Wexler [4], the nearly identical equation by Wexler (1976, see reference below) and\n",
    "    the equation by Sonntag [7] are the most commonly used equations among Radiosonde manufacturers\n",
    "    and should be used in upper air applications to avoid inconsistencies.\n",
    "\n",
    "    Known Saturation water Vapor Formulations:\n",
    "\n",
    "    Bolton 1980\n",
    "    Goff 1957, 1965        (180    - 273.15 / 273.15 - 373.15) 1957> WMO\n",
    "    Goff and Gratch 1946   (184    - 273.15 / 273.15 - 373.15)\n",
    "    Hyland and Wexler 1983 (173.16 - 273.15 / 273.15 - 473.15) Vaisala\n",
    "    IAPWS 1995             (173.15 - 273.15 / 273.15 - 647   ) Wagner and Pruss + Wagner 1994\n",
    "    Murphy and Koop 2005   (110    - 273.15 / 132      332   ) Ice formulation as well\n",
    "    Sonntag 1990           (173.15 - 273.15 / 273.15 - 373.15)\n",
    "    Sonntag 1994           (173.15 - 273.15 / 273.15 - 373.15)\n",
    "    Wagner 1994            (190    - 273.15                  )\n",
    "    Wagner and Pruss 1993  (190    - 273.15 / 273.15 - 647   )\n",
    "    Wexler 1976            (                  273.15 - 373.15)\n",
    "    Wright 1997\n",
    "\n",
    "    Args:\n",
    "        t: air temperature\n",
    "        method: string or function\n",
    "        p: pressure\n",
    "        **kwargs: additional keywords passed to function\n",
    "\n",
    "    Returns:\n",
    "        es : saturation water vapor pressure in Pa\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if callable(method):\n",
    "            vpfunc = method\n",
    "        else:\n",
    "            vpfunc = eval(method)\n",
    "\n",
    "        if p is not None:\n",
    "            f = ef(p, **kwargs)\n",
    "        else:\n",
    "            f = 1.\n",
    "        return vpfunc(t, **kwargs) * f\n",
    "    except:\n",
    "        import sys\n",
    "        print(\"Functions: \", \", \".join([i for i in dir(sys.modules[__name__]) if i[0].upper() == i[0]]))\n",
    "        \n",
    "def vap2sh(e, p):\n",
    "    \"\"\" Convert water vapor pressure to specific humidity\n",
    "    Parameters\n",
    "    ----------\n",
    "    e      Water vapor [Pa]\n",
    "    p      total air pressure [Pa]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    specific humidity (1 = kg/kg)\n",
    "    \"\"\"\n",
    "    rd = 287.05\n",
    "    rv = 461.50\n",
    "    c = rd/rv  # Rd/Rv = 0.6219934994582882\n",
    "    pa = p - e  # dry air pressure\n",
    "    return (e * c) / (e * c + pa)\n",
    "\n",
    "def dp_sh(dp, press):\n",
    "        vpdata = svp(dp, p=press)\n",
    "        q = vap2sh(vpdata, press)\n",
    "        return q\n",
    "\n",
    "# @ray.remote       \n",
    "def rttov_calc(tadata, humdata, pressdata, eradata, datedata, chan):\n",
    "    rttov_installdir = '/rttov/'\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Set up the profile data\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    # Declare an instance of Profiles\n",
    "    nlevels = len(pressdata[0])\n",
    "    nprofiles = len(tadata)\n",
    "    myProfiles = pyrttov.Profiles(nprofiles, nlevels)\n",
    "\n",
    "    # Associate the profiles and other data from example_data.h with myProfiles\n",
    "    # Note that the simplecloud, clwscheme, icecloud and zeeman data are not mandatory and\n",
    "    # are omitted here\n",
    "\n",
    "    def expand2nprofiles(n, nprof):\n",
    "        # Transform 1D array to a [nprof, nlevels] array\n",
    "        outp = np.empty((nprof, len(n)), dtype=n.dtype)\n",
    "        for i in range(nprof):\n",
    "            outp[i, :] = n[:]\n",
    "        return outp\n",
    "\n",
    "#     dfsh = ascent.copy()\n",
    "#     consthum =  pickle.load( open( \"dfsh.p\", \"rb\" ) )\n",
    "#     pl = [1000,2000,3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,70000,85000,92500,100000]\n",
    "#     for i in range(len(pl)):\n",
    "#         for j in range(len(ascent)):\n",
    "#             if dfsh.index[j] == pl[i]:\n",
    "#                 dfsh.ta.iloc[j] = consthum[i]\n",
    "    \n",
    "    myProfiles.GasUnits = 0\n",
    "    myProfiles.P = pressdata/100. # expand2nprofiles(pressdata/100., nprofiles) \n",
    "#     print(myProfiles.P)\n",
    "    myProfiles.T = tadata # expand2nprofiles(tadata, nprofiles) \n",
    "#     print(myProfiles.T)\n",
    "    myProfiles.Q = humdata # expand2nprofiles(humdata, nprofiles) \n",
    "#     myProfiles.Q = expand2nprofiles(np.array(dfsh.ta), nprofiles) \n",
    "\n",
    "#     print(myProfiles.Q)\n",
    "    \n",
    "    \n",
    "    \n",
    "    myProfiles.Angles = [[0, 0, 45, 180]] * nprofiles\n",
    "    # satzen, satazi, sunzen, sunazi\n",
    "    myProfiles.SurfType = [[0, 0]] * nprofiles\n",
    "    # skin%surftype\n",
    "    \n",
    "    S2m = []\n",
    "    Skin = []\n",
    "    SurfGeom = []\n",
    "    DateTimes = []\n",
    "        \n",
    "    for i in range(nprofiles):\n",
    "        if np.array(eradata[i].sp).size > 1:\n",
    "            S2m.append([float(eradata[i].sp[0])/100., float(eradata[i].t2m[0]), dp_sh(float(eradata[i].d2m[0]), float(eradata[i].sp[0])), float(eradata[i].u10[0]), float(eradata[i].v10[0]), 100000])\n",
    "            Skin.append([float(eradata[i].skt[0]), 0, 0, 0, 3.0, 5., 15, 0.1, 0.3, 0])\n",
    "        else:\n",
    "            S2m.append([float(eradata[i].sp)/100., float(eradata[i].t2m), dp_sh(float(eradata[i].d2m), float(eradata[i].sp)), float(eradata[i].u10), float(eradata[i].v10), 100000])\n",
    "            Skin.append([float(eradata[i].skt), 0, 0, 0, 3.0, 5., 15, 0.1, 0.3, 0])\n",
    "        SurfGeom.append([float(eradata[i].latitude), float(eradata[i].longitude), 0.])\n",
    "        DateTimes.append([datedata[i].year, datedata[i].month, datedata[i].day, 0, 0, 0])\n",
    "        \n",
    "    myProfiles.S2m = S2m\n",
    "    # s2m%p, s2m%t, s2m%q, s2m%u, s2m%v, s2m%wfetch\n",
    "    myProfiles.Skin = Skin\n",
    "    # (skin%t, skin%salinity, skin%foam_fraction, skin%snow_fraction skin%fastem(1:5)) --> fastem default =  3.0, 5., 15, 0.1, 0.3, 0\n",
    "    myProfiles.SurfGeom = SurfGeom\n",
    "    # (latitude, longitude, elevation)\n",
    "    myProfiles.DateTimes = DateTimes\n",
    "    # (year, month, day, hour, minute, second)\n",
    "\n",
    "    \n",
    "    # ------------------------------------------------------------------------\n",
    "    # Set up Rttov instances for each instrument\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    # Create three Rttov objects for three instruments\n",
    "    msuRttov = pyrttov.Rttov()\n",
    "\n",
    "    nchan_msu = len(chan)\n",
    "    chan_list_msu = chan\n",
    "\n",
    "    # Set the options for each Rttov instance:\n",
    "    # - the path to the coefficient file must always be specified\n",
    "    # - turn RTTOV interpolation on (because input pressure levels differ from\n",
    "    #   coefficient file levels)\n",
    "    # - set the verbose_wrapper flag to true so the wrapper provides more\n",
    "    #   information\n",
    "    # - enable solar simulations for SEVIRI\n",
    "    # - enable CO2 simulations for HIRS (the CO2 profiles are ignored for\n",
    "    #   the SEVIRI and MHS simulations)\n",
    "    # - enable the store_trans wrapper option for MHS to provide access to\n",
    "    #   RTTOV transmission structure\n",
    "#     print(\"/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_14_msu.dat\")\n",
    "#     msuRttov.FileCoef = '{}/{}'.format(rttov_installdir,\n",
    "#                                        \"rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_14_msu.dat\")\n",
    "    msuRttov.FileCoef = \"/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_14_msu.dat\"\n",
    "#     msuRttov.FileCoef = \"/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_15_amsub.dat\"\n",
    "    msuRttov.Options.AddInterp = True\n",
    "#     msuRttov.Options.AddSolar = True\n",
    "#     msuRttov.Options.CO2Data = False\n",
    "    msuRttov.Options.VerboseWrapper = True\n",
    "\n",
    "\n",
    "    # Load the instruments: for HIRS and MHS do not supply a channel list and\n",
    "    # so read all channels\n",
    "#     try:\n",
    "    msuRttov.loadInst(channels=chan_list_msu)\n",
    "#     msuRttov.loadInst()\n",
    "#     except pyrttov.RttovError as e:\n",
    "#         sys.stderr.write(\"Error loading instrument(s): {!s}\".format(e))\n",
    "#         sys.exit(1)\n",
    "\n",
    "    # Associate the profiles with each Rttov instance\n",
    "    msuRttov.Profiles = myProfiles\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Load the emissivity and BRDF atlases\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    # Load the emissivity and BRDF atlases:\n",
    "    # - load data for the month in the profile data\n",
    "    # - load the IR emissivity atlas data for multiple instruments so it can be used for SEVIRI and HIRS\n",
    "    # - SEVIRI is the only VIS/NIR instrument we can use the single-instrument initialisation for the BRDF atlas\n",
    "\n",
    "#     irAtlas = pyrttov.Atlas()\n",
    "#     irAtlas.AtlasPath = '{}/{}'.format(rttov_installdir, \"emis_data\")\n",
    "#     irAtlas.loadIrEmisAtlas(ex.datetimes[1][0], ang_corr=True) # Include angular correction, but do not initialise for single-instrument\n",
    "\n",
    "#     brdfAtlas = pyrttov.Atlas()\n",
    "#     brdfAtlas.AtlasPath = '{}/{}'.format(rttov_installdir, \"brdf_data\")\n",
    "#     brdfAtlas.loadBrdfAtlas(ex.datetimes[1][0], msuRttov) # Supply Rttov object to enable single-instrument initialisation\n",
    "#     brdfAtlas.IncSea = False                                 # Do not use BRDF atlas for sea surface types\n",
    "\n",
    "    # TELSEM2 atlas does not require an Rttov object to initialise\n",
    "    mwAtlas = pyrttov.Atlas()\n",
    "    mwAtlas.AtlasPath = '{}/{}'.format(rttov_installdir, \"emis_data\")\n",
    "    mwAtlas.loadMwEmisAtlas(-1)\n",
    "\n",
    "    # Set up the surface emissivity/reflectance arrays and associate with the Rttov objects\n",
    "    surfemisrefl_msu = np.zeros((2,nprofiles,nchan_msu), dtype=np.float64)\n",
    "\n",
    "#     seviriRttov.SurfEmisRefl = surfemisrefl_msu\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Call RTTOV\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    # Surface emissivity/reflectance arrays must be initialised *before every call to RTTOV*\n",
    "    # Negative values will cause RTTOV to supply emissivity/BRDF values (i.e. equivalent to\n",
    "    # calcemis/calcrefl TRUE - see RTTOV user guide)\n",
    "\n",
    "    surfemisrefl_msu[:,:,:] = -1.\n",
    "\n",
    "    # Call emissivity and BRDF atlases\n",
    "    try:\n",
    "        # Do not supply a channel list for SEVIRI: this returns emissivity/BRDF values for all\n",
    "        # *loaded* channels which is what is required\n",
    "#         surfemisrefl_seviri[0,:,:] = irAtlas.getEmisBrdf(seviriRttov)\n",
    "#         surfemisrefl_seviri[1,:,:] = brdfAtlas.getEmisBrdf(seviriRttov)\n",
    "#         surfemisrefl_hirs[0,:,:] = irAtlas.getEmisBrdf(hirsRttov)\n",
    "#         surfemisrefl_mhs[0,:,:] = mwAtlas.getEmisBrdf(mhsRttov)\n",
    "\n",
    "        surfemisrefl_msu[0,:,:] = mwAtlas.getEmisBrdf(msuRttov)\n",
    "\n",
    "\n",
    "    except pyrttov.RttovError as e:\n",
    "        # If there was an error the emissivities/BRDFs will not have been modified so it\n",
    "        # is OK to continue and call RTTOV with calcemis/calcrefl set to TRUE everywhere\n",
    "        sys.stderr.write(\"Error calling atlas: {!s}\".format(e))\n",
    "\n",
    "    # Call the RTTOV direct model for each instrument:\n",
    "    # no arguments are supplied to runDirect so all loaded channels are\n",
    "    # simulated\n",
    "    try:\n",
    "        msuRttov.runDirect()\n",
    "    except pyrttov.RttovError as e:\n",
    "        sys.stderr.write(\"Error running RTTOV direct model: {!s}\".format(e))\n",
    "        sys.exit(1)\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # Print out some of the output\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    print\n",
    "    print(\"SELECTED OUTPUT\")\n",
    "    print\n",
    "\n",
    "#     print(\"MSU visible channel reflectances, channels 2-4\")\n",
    "#     for p in range(nprofiles):\n",
    "#         print(\"Profile {:d}:\".format(p))\n",
    "#         for c in range(len(chan)):\n",
    "#             print(\"  Ch #{:02d} refl={:f}\".format(chan_list_msu[c],\n",
    "#                                                   msuRttov.BtRefl[p, c]))\n",
    "#         print\n",
    "    return chan_list_msu, msuRttov.BtRefl\n",
    "\n",
    "\n",
    "def calc_station(statid, chum, odir, adj = None):\n",
    "#     print('')\n",
    "#     print(glob.glob('/rttov/rtcoef_rttov12/rttov7pred54L/*ssmt2*'))\n",
    "#     print('')\n",
    "    statlist = statid\n",
    "#     adjstatlist = glob.glob(statlist.split('feedbackmerged')[0]+'feedbackglobbincorrsave_rio24_0*.nc')\n",
    "#     adjstatlist = glob.glob(statlist.split('feedbackmerged')[0]+'feedbackglobbincorrsave_rit24_0*.nc')\n",
    "#     adjstatlist = glob.glob(statlist.split('feedbackmerged')[0]+'feedbackglobbincorrsave0*.nc')\n",
    "#     feedbackglobbincorrmon\n",
    "\n",
    "#     print(statlist.split('feedbackmerged')[0]+'feedbackglobbincorrsave0*.nc', adjstatlist)\n",
    "#     if len(adjstatlist) == 0:\n",
    "# #         print('no adj')\n",
    "#         return\n",
    "#     else:\n",
    "#         adjstatlist = adjstatlist[0]\n",
    "        \n",
    "    statid = statlist.split('.nc')[0][-5:]\n",
    "#     if len(glob.glob(\"./\"+odir+\"/\"+statid)) > 0:\n",
    "#         print('skipped', glob.glob(\"./\"+odir+\"/\"+statid))\n",
    "#         return\n",
    "    try:\n",
    "        os.makedirs(\"./\"+odir+\"/\"+statid+\"/\")\n",
    "    except:\n",
    "        pass\n",
    "    print(statid)\n",
    "\n",
    "    try:\n",
    "\n",
    "        adjstatlist = None\n",
    "        if adj == 'rio':\n",
    "            adjstatlist = glob.glob(statlist.split('feedback')[0]+'feedbackglobbincorrsave_rio24_0*.nc')[0]\n",
    "        elif adj == 'rit':\n",
    "            adjstatlist = glob.glob(statlist.split('feedback')[0]+'feedbackglobbincorrsave_rit24_0*.nc')[0]\n",
    "        if adjstatlist != None:\n",
    "            adj_df = xr.open_dataset(adjstatlist).to_dataframe()\n",
    "            adj_df.press = adj_df.press * 100.\n",
    "            adj_df = adj_df[adj_df.press.isin([3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,70000,85000])]\n",
    "\n",
    "        print(statlist)\n",
    "        df = xr.open_dataset(statlist).to_dataframe()\n",
    "        df.press = df.press * 100.\n",
    "        ###\n",
    "        df = df[df.press.isin([3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,70000,85000])]\n",
    "        df = df.loc[df.index.get_level_values('numdat') == 0]\n",
    "    #     df = df[df.datum.dt.year == 1995]\n",
    "    #     df = df[df.datum.dt.month == 1]\n",
    "        df = df.reset_index()    \n",
    "        df = df.rename({'time':'time_idx'}, axis='columns')\n",
    "        df = df.rename({'datum':'time', 'press':'plev'}, axis='columns')\n",
    "        df = df[df.montemp < 400]\n",
    "\n",
    "        #\n",
    "        ##\n",
    "        ###\n",
    "        ####\n",
    "        #####\n",
    "        if adj in [None, 'rio', 'rit']:\n",
    "            df.montemp = df.montemp + df.rasocorrmon\n",
    "        elif adj == 'raobcore':\n",
    "            pass\n",
    "        else:\n",
    "            print('not a valid adjustment: ', adj)\n",
    "            return\n",
    "        #####\n",
    "        ####\n",
    "        ###\n",
    "        ##\n",
    "        #\n",
    "\n",
    "    #     print('adj_df: ', adj_df)\n",
    "    #     print('df: ',df)\n",
    "        if adjstatlist != None:\n",
    "            for p in [3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,70000,85000]:\n",
    "                print('adjusting: ', p)\n",
    "                for h in [0,1]:\n",
    "                    im = adj_df.loc[(adj_df.press == p) & (adj_df.index.get_level_values('hour') == h)]\n",
    "\n",
    "                    adjs_val = np.array(im.rasocorr)\n",
    "                    adjs_date = np.array(im.datum)\n",
    "                    for t in range(len(adjs_date)-1):\n",
    "        #                 print('ADJUSTMENT: ', adjs_val[t])\n",
    "                        mask = (adjs_date[t] <= df.time) & (df.time < adjs_date[t+1]) & (df.plev == p) & (df.hour == h)\n",
    "        #                 print('before')\n",
    "        #                 print(df.loc[mask, 'montemp'])\n",
    "                        df.loc[mask, 'montemp'] -= adjs_val[t]\n",
    "        #                 print('after')\n",
    "        #                 print(df.loc[mask, 'montemp'])\n",
    "        #                 print('')\n",
    "        #                 print('')\n",
    "\n",
    "\n",
    "        all_dfta = df\n",
    "        all_dfta = all_dfta.rename({'montemp':'ta'}, axis='columns')\n",
    "\n",
    "        all_dfsh = all_dfta\n",
    "        all_dfsh = all_dfsh.rename({'ta':'hus'}, axis='columns')\n",
    "        dfsh = all_dfsh.groupby(['plev']).aggregate({\"hus\":np.mean})\n",
    "        pl = [3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,70000,85000]\n",
    "        for i in range(len(pl)):\n",
    "            for j in range(len(dfsh)):\n",
    "                if dfsh.index[j] == pl[i]:\n",
    "                    dfsh.hus.iloc[j] = chum[i]\n",
    "\n",
    "\n",
    "\n",
    "        tadata = []\n",
    "        daydata = []\n",
    "        datedata = []\n",
    "        humdata = []\n",
    "        eradata = []\n",
    "        chandata = []\n",
    "        pressdata = []\n",
    "        mondata = []\n",
    "\n",
    "        tadata34 = []\n",
    "        daydata34 = []\n",
    "        datedata34 = []\n",
    "        humdata34 = []\n",
    "        eradata34 = []\n",
    "        chandata34 = []\n",
    "        pressdata34 = []\n",
    "        mondata34 = []\n",
    "\n",
    "        wholemon = []\n",
    "\n",
    "        ngoodmon = []\n",
    "        dgoodmon = []\n",
    "\n",
    "    #     print(all_dfta)\n",
    "\n",
    "        for day in [True,False]:\n",
    "            if day:\n",
    "                dn_dfta = all_dfta.loc[all_dfta.hour == 1]\n",
    "            else:\n",
    "                dn_dfta = all_dfta.loc[all_dfta.hour == 0]\n",
    "    #         print(dn_dfta)\n",
    "            goodmon = []\n",
    "            for yr in range(1950,2022,1):\n",
    "                for mon in range(int(str(yr)+'01'), int(str(yr)+'13'), 1):\n",
    "                    wholemon.append(mon)\n",
    "                    ###############\n",
    "                    ##############\n",
    "                    ############\n",
    "    #                     dfta = dn_dfta.loc[(dn_dfta['time'].dt.year==int(str(mon)[:4])) & (dn_dfta['time'].dt.month==int(str(mon)[-2:]))]\n",
    "    #                     df = dfta\n",
    "    #                     mon_mean = df.groupby(['plev']).aggregate({\"ta\":np.mean})\n",
    "                    mon_mean = dn_dfta.loc[(dn_dfta['time'].dt.year==int(str(mon)[:4])) & (dn_dfta['time'].dt.month==int(str(mon)[-2:]))]\n",
    "                    reduced_sh = dfsh\n",
    "                    for j in [3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,70000,85000]:\n",
    "                        if len(mon_mean[mon_mean.plev == j].ta) > 0:\n",
    "                            if np.isnan(mon_mean[mon_mean.plev == j].ta.iloc[0]):\n",
    "                                mon_mean = mon_mean[mon_mean.plev != j]\n",
    "                                #reduced_sh = reduced_sh[reduced_sh.index != j]\n",
    "\n",
    "                    ## append goodmon\n",
    "\n",
    "    #                 print('mon_mean: ')\n",
    "    #                 print(mon_mean)\n",
    "    #                 print('reduced_sh: ')\n",
    "    #                 print(reduced_sh)\n",
    "                    if day:\n",
    "                        dgoodmon.append(np.mean(mon_mean.goodmon))\n",
    "                    else:\n",
    "                        ngoodmon.append(np.mean(mon_mean.goodmon))\n",
    "    #                 print('mon_mean: ', mon_mean)\n",
    "    #                 print('len(mon_mean): ', len(mon_mean))\n",
    "                    if len(mon_mean) >= 9:\n",
    "                        with xarray.open_dataset('./era/era_'+str(yr)+'.nc') as era:\n",
    "                            era_input = era.sel(time = str(yr)+'-'+str(mon)[-2:]+'-01T00:00:00.000000000', latitude = mon_mean.lat.iloc[0], longitude = mon_mean.lon.iloc[0], method='nearest')\n",
    "                        nancheck = False\n",
    "                        for i in era_input:\n",
    "                            if np.isnan(era_input[i]):\n",
    "                                nancheck = True\n",
    "                        if nancheck:\n",
    "                            continue\n",
    "\n",
    "\n",
    "    #                     print('mon_mean.plev: ', mon_mean.plev)\n",
    "                        date = pd.to_datetime(float(era_input.time))\n",
    "                        high_mon_mean = mon_mean[mon_mean.plev.isin([3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,70000])]\n",
    "                        if len(high_mon_mean) >= 9:\n",
    "                            plevs_to_check = np.array(high_mon_mean.plev)\n",
    "                            if((3000. in plevs_to_check and 5000. in plevs_to_check and 7000. in plevs_to_check and 10000. in plevs_to_check and \n",
    "                                    15000. in plevs_to_check and 20000. in plevs_to_check and 25000. in plevs_to_check and \n",
    "                                    30000. in plevs_to_check and 40000. in plevs_to_check and 50000. in plevs_to_check)):\n",
    "                                if(not (70000. in plevs_to_check)):\n",
    "                                    s = high_mon_mean.iloc[0]\n",
    "                                    s.ta = np.nan\n",
    "                                    s.name = 70000.\n",
    "                                    high_mon_mean = high_mon_mean.append(s)\n",
    "\n",
    "                                high_reduced_sh = reduced_sh[reduced_sh.index.isin(high_mon_mean.plev)]\n",
    "                                tadata34.append(high_mon_mean.ta)\n",
    "                                humdata34.append(np.array(high_reduced_sh.hus))\n",
    "                                pressdata34.append(high_mon_mean.plev)\n",
    "                                datedata34.append(date)\n",
    "                                eradata34.append(era_input)  \n",
    "                                chandata34.append(34)\n",
    "                                daydata34.append(day)\n",
    "                                mondata34.append(mon)\n",
    "\n",
    "                        low_mon_mean = mon_mean[mon_mean.plev.isin([5000,7000,10000,15000,20000,25000,30000,40000,50000,70000,85000])]\n",
    "    #                     print('len(low_mon_mean):' ,len(low_mon_mean))\n",
    "                        if len(low_mon_mean) >= 9:\n",
    "                            plevs_to_check = np.array(low_mon_mean.plev)\n",
    "    #                         print('plevs_to_check: ', plevs_to_check)\n",
    "                            if((5000 in plevs_to_check and 7000 in plevs_to_check and 10000 in plevs_to_check and \n",
    "                                    15000 in plevs_to_check and 20000 in plevs_to_check and 25000 in plevs_to_check and \n",
    "                                    30000 in plevs_to_check and 40000 in plevs_to_check and 50000 in plevs_to_check)):\n",
    "                                if(not (70000 in plevs_to_check)):\n",
    "                                    s = low_mon_mean.iloc[0]\n",
    "                                    s.ta = np.nan\n",
    "                                    s.name = 70000\n",
    "                                    low_mon_mean = low_mon_mean.append(s)\n",
    "                                if(not (85000 in plevs_to_check)):\n",
    "                                    s = low_mon_mean.iloc[0]\n",
    "                                    s.ta = np.nan\n",
    "                                    s.plev = 85000\n",
    "                                    low_mon_mean = low_mon_mean.append(s)\n",
    "\n",
    "                                low_reduced_sh = reduced_sh[reduced_sh.index.isin(low_mon_mean.plev)]\n",
    "                                tadata.append(low_mon_mean.ta)\n",
    "                                humdata.append(np.array(low_reduced_sh.hus))\n",
    "                                pressdata.append(low_mon_mean.plev)\n",
    "                                datedata.append(date)\n",
    "                                eradata.append(era_input)  \n",
    "                                chandata.append(2)\n",
    "                                daydata.append(day)\n",
    "                                mondata.append(mon)\n",
    "\n",
    "    #     print('monfiles')\n",
    "    #     print('calc monmeans')\n",
    "\n",
    "    #     return\n",
    "    #     print('tadata: ',np.shape(tadata))\n",
    "    #     print('humdata: ',np.shape(humdata))\n",
    "    #     print('pressdata: ',np.shape(pressdata))\n",
    "    #     print('datedata: ',np.shape(datedata))\n",
    "        print('before 34 c')\n",
    "\n",
    "\n",
    "        a34,b34 = rttov_calc(\n",
    "            np.array(tadata34),\n",
    "            np.array(humdata34),\n",
    "            np.array(pressdata34),\n",
    "            eradata34, # [x for x, y in zip(eradata34, chandata34) if y == 34],\n",
    "            np.array(datedata34), # [np.array(chandata34) == 34],\n",
    "            [3,4]\n",
    "        )\n",
    "\n",
    "        print('before 12 c')\n",
    "        a2,b2 = rttov_calc(\n",
    "            np.array(tadata),\n",
    "            np.array(humdata),\n",
    "            np.array(pressdata),\n",
    "            eradata, # ([x for x, y in zip(eradata, chandata) if y == 2],\n",
    "            np.array(datedata), # [np.array(chandata) == 2],\n",
    "    #         [2]\n",
    "            [1,2]\n",
    "        )\n",
    "\n",
    "        middle_index = len(wholemon)//2    \n",
    "\n",
    "        testb2 =b2[np.array(daydata)[np.array(chandata) == 2] == True]\n",
    "        testb34 = b34[np.array(daydata34)[np.array(chandata34) == 34] == True]\n",
    "        date_out2 = np.array(mondata)[np.array(chandata) == 2][np.array(daydata)[np.array(chandata) == 2] == True]\n",
    "        date_out34 = np.array(mondata34)[np.array(chandata34) == 34][np.array(daydata34)[np.array(chandata34) == 34] == True]\n",
    "\n",
    "        b_final = []\n",
    "        for i in wholemon[:middle_index]:\n",
    "            b = [[np.nan, np.nan, np.nan, np.nan]]\n",
    "            if i in date_out2:\n",
    "                b[0][0] = testb2[date_out2 == i][0][0]\n",
    "                b[0][1] = testb2[date_out2 == i][0][1]\n",
    "            if i in date_out34:\n",
    "                b[0][2] = testb34[date_out34 == i][0][0]\n",
    "                b[0][3] = testb34[date_out34 == i][0][1]\n",
    "            b_final.append(b)\n",
    "\n",
    "        try:\n",
    "            os.makedirs(\"./\"+odir+\"/\"+statid+\"/\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        pickle.dump( b_final, open( odir+\"/\"+statid+\"/\"+statid+\"_day_refl.p\", \"wb\" ) )\n",
    "        pickle.dump( dgoodmon, open( odir+\"/\"+statid+\"/\"+statid+\"_day_goodmon.p\", \"wb\" ) )\n",
    "        pickle.dump( wholemon[:middle_index], open( odir+\"/\"+statid+\"/\"+statid+\"_day_dates.p\", \"wb\" ) )\n",
    "        print('day done: '+statid)\n",
    "\n",
    "\n",
    "        testb2 =b2[np.array(daydata)[np.array(chandata) == 2] == False]\n",
    "        testb34 = b34[np.array(daydata34)[np.array(chandata34) == 34] == False]\n",
    "        date_out2 = np.array(mondata)[np.array(chandata) == 2][np.array(daydata)[np.array(chandata) == 2] == False]\n",
    "        date_out34 = np.array(mondata34)[np.array(chandata34) == 34][np.array(daydata34)[np.array(chandata34) == 34] == False]\n",
    "\n",
    "        b_final = []\n",
    "        for i in wholemon[middle_index:]:\n",
    "            b = [[np.nan, np.nan, np.nan, np.nan]]\n",
    "            if i in date_out2:\n",
    "                b[0][0] = testb2[date_out2 == i][0][0]\n",
    "                b[0][1] = testb2[date_out2 == i][0][1]\n",
    "            if i in date_out34:\n",
    "                b[0][2] = testb34[date_out34 == i][0][0]\n",
    "                b[0][3] = testb34[date_out34 == i][0][1]\n",
    "            b_final.append(b)\n",
    "\n",
    "        pickle.dump( b_final, open( odir+\"/\"+statid+\"/\"+statid+\"_night_refl.p\", \"wb\" ) )\n",
    "        pickle.dump( ngoodmon, open( odir+\"/\"+statid+\"/\"+statid+\"_night_goodmon.p\", \"wb\" ) )\n",
    "        pickle.dump( wholemon[middle_index:], open( odir+\"/\"+statid+\"/\"+statid+\"_night_dates.p\", \"wb\" ) )\n",
    "        print('night done: '+statid)\n",
    "    except:\n",
    "        print('nothing to calculate: '+statid)\n",
    "        return\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7344c821-c5fa-4a52-b25c-9c6680f88189",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/users/scratch/leo/scratch/converted_v13/long/0-20001-0-11035_CEUAS_merged_v1.nc']\n",
      "ed_v1\n",
      "/mnt/users/scratch/leo/scratch/converted_v13/long/0-20001-0-11035_CEUAS_merged_v1.nc\n",
      "nothing to calculate: ed_v1\n",
      "[None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n['/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_8_msu.dat', \\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_17_amsub.dat',\\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_16_amsub.dat',\\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_18_amsua.dat', \\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_15_amsub.dat', \\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_16_amsua.dat', \\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_9_msu.dat',\\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_11_msu.dat',\\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_6_msu.dat', \\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_14_msu.dat', \\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_7_msu.dat', \\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_19_amsua.dat',\\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_15_amsua.dat',\\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_12_msu.dat',\\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_17_amsua.dat',\\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_10_msu.dat', \\n'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_5_msu.dat']\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if __name__ == '__main__': \n",
    "#     [3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,70000,85000]\n",
    "consthum = np.array([3.90, 5.90, 9.17, 20.30,\n",
    "                     285.00, 1464.00 , 2475.60, 6631.20,\n",
    "                     15468.00, 21684.00, 35328.00 , 44220.00]\n",
    "               )/2.\n",
    "statlist = []\n",
    "#     statlist = glob.glob('/mnt/ssdraid/scratch/leo/rise/1.0/exp02/*85469*/feedbackglobbincorrmon0*.nc')\n",
    "#     statlist = glob.glob('/mnt/ssdraid/scratch/leo/rise/1.0/exp02/*17095*/feedbackglobbincorrmon0*.nc')\n",
    "#     statlist = glob.glob('/mnt/ssdraid/scratch/leo/rise/1.0/exp02/*/feedbackglobbincorrmon0*.nc')\n",
    "#     statlist = glob.glob('/mnt/ssdraid/scratch/leo/rise/1.0/exp01/*11035*/feedbackmerged*.nc')\n",
    "stats = glob.glob('/mnt/users/scratch/leo/scratch/converted_v13/long/*11035*_CEUAS_merged_v1.nc')\n",
    "for i in stats:\n",
    "    statlist.append(i)\n",
    "#     calc_station(statlist[0])\n",
    "#     for i in [\"RISE\", \"RASE\"]: #[None, \"RAOBCORE\", \"RICH\", \"RISE\", \"RASE\"]:\n",
    "i = None\n",
    "print(statlist)\n",
    "\n",
    "for i in [None]:# [None, 'raobcore', 'rio', 'rit']:\n",
    "    if i == None:\n",
    "        odir = \"rttov_out_unadj_testing\"\n",
    "    elif i == 'raobcore':\n",
    "        odir = \"rttov_out_raobcore_testing\"\n",
    "    elif i == 'rio':\n",
    "        odir = \"rttov_out_rio_testing\"\n",
    "    elif i == 'rit':\n",
    "        odir = \"rttov_out_rit_testing\"\n",
    "    try:\n",
    "        os.makedirs(\"./\"+odir+\"/\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=20)\n",
    "    func=partial(calc_station, chum = consthum, adj = i, odir = odir)\n",
    "    result_list = list(map(func, statlist[:1]))\n",
    "    print(result_list)\n",
    "'''\n",
    "['/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_8_msu.dat', \n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_17_amsub.dat',\n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_16_amsub.dat',\n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_18_amsua.dat', \n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_15_amsub.dat', \n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_16_amsua.dat', \n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_9_msu.dat',\n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_11_msu.dat',\n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_6_msu.dat', \n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_14_msu.dat', \n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_7_msu.dat', \n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_19_amsua.dat',\n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_15_amsua.dat',\n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_12_msu.dat',\n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_17_amsua.dat',\n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_10_msu.dat', \n",
    "'/rttov/rtcoef_rttov12/rttov7pred54L/rtcoef_noaa_5_msu.dat']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cb9890-19ea-471d-a9b2-21cc6d109c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rttovv13.2 - 3.7.12",
   "language": "python",
   "name": "rttovv13.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
