{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89dbdca-c8ae-4a1c-9f55-3860471f059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "from tkinter import Tk, filedialog\n",
    "from skimage.metrics import structural_similarity\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\"\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "matplotlib.rcParams.update({\"font.size\": 20})\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195480e8-1d33-468f-b0aa-c49f4609bb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value, array_matching = np.nan):\n",
    "    \"\"\"\n",
    "    Find the best match in an array.\n",
    "        Optionally use the found index to retreive the value of an array matching the first one in shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    array : list or np.array\n",
    "        The array which is searched for the value.\n",
    "    value : int, float, double\n",
    "        The numeric value which is searched for. \n",
    "    array_matching : list or np.array, optional\n",
    "        An array matching the shape of \"array\", which can optionally be used as output instead of \"array\". \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int, float, double\n",
    "        The closest match of the searched array, or the element of the same index in an matching array.\n",
    "    \"\"\"\n",
    "\n",
    "    array = np.asarray(array)\n",
    "    # search for the smalles difference\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    # use found index to return output\n",
    "    if np.isnan(array_matching).all():\n",
    "        return array[idx]\n",
    "    else:\n",
    "        return array_matching[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf1ba8-58ca-4ccd-bc68-30db8b6f2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    \"\"\"\n",
    "    Resize an image and interpolate the resolution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : cv2.image \n",
    "        The image to resize.\n",
    "    width : int\n",
    "        Target width in pixel.\n",
    "    height : int\n",
    "        Target height in pixel. \n",
    "    inter : cv2 interpolation method\n",
    "        Interpolation method to shrink or enlarge the image.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cv2.image\n",
    "        The resized image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d56fe-08e2-4d6f-a0cf-51544a6365a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label_x(label, show_input = False, show_plots = True, force_manual=True):\n",
    "    \"\"\"\n",
    "    Convert the image of a lable to characters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label : cv2.image \n",
    "        The image to convert.\n",
    "    show_input : bool\n",
    "        Plot the input before processing.\n",
    "    show_plots : bool\n",
    "        Show image while processing. \n",
    "    force_manual : bool\n",
    "        Set the convertion mode to manual for the user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The converted value.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    \n",
    "    # Set up tesseract parameters for reading the labels of selected grid intersections\n",
    "    # '--psm 6' -> \"Assume a single uniform block of text.\" \n",
    "    # '--oem 3' -> default OCR (optical character recognition) engine\n",
    "    # '-c tessedit_char_whitelist' -> use a whitelist to avoid wrongly read characters\n",
    "    set_psm =  '--psm 6 --oem 3 -c tessedit_char_whitelist=0123456789-,._C preserve_interword_spaces=1' \n",
    "\n",
    "    if show_input:\n",
    "        plt.imshow(label)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    # Resizing the label for ideal readability:\n",
    "    label = image_resize(label, height=100, inter=cv2.INTER_CUBIC)\n",
    "\n",
    "    if force_manual:\n",
    "        plt.imshow(label)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        return_str = input('please help me read this lable: ')\n",
    "    else:\n",
    "        # Enhancing the image to make it easier to read for tesseract:\n",
    "        gray = cv2.cvtColor(label, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "        thresh_val = 50\n",
    "        thresh = cv2.threshold(blur, thresh_val, thresh_val, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        # Separating the characters of the image -> this way it is easier to identify lower quality images\n",
    "        # This done by looking for the spaces inbetween the characters. Their vertical sum should be mostly white\n",
    "        # Sometimes the space between the characters is very small. Depending on the font, examples like \"-4\" are often seen as one character.\n",
    "        edges = cv2.Canny(thresh,100,200)\n",
    "        vertical_sum = np.sum(edges, axis=0)\n",
    "        vertical_sum = vertical_sum != 0\n",
    "        changes = np.logical_xor(vertical_sum[1:], vertical_sum[:-1])\n",
    "        change_pts = np.nonzero(changes)[0]\n",
    "\n",
    "        if show_plots:\n",
    "            print('character detection')\n",
    "            plt.imshow(thresh)\n",
    "            for change in change_pts:\n",
    "                plt.axvline(change+1)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        # Iterating through the parts of the image -> the single characters\n",
    "        for i in range(len(change_pts)-1):\n",
    "            start = change_pts[i]\n",
    "            end =  change_pts[i+1]\n",
    "            if start != end and end-start > 10:\n",
    "                cut = label[:, start:end]\n",
    "                cut = cv2.copyMakeBorder(\n",
    "                         cut, \n",
    "                         1, \n",
    "                         1, \n",
    "                         20, \n",
    "                         20, \n",
    "                         cv2.BORDER_CONSTANT, \n",
    "                         value= [175,175,175]\n",
    "                      )\n",
    "\n",
    "                # Changing back to grey for identification\n",
    "                gray = cv2.cvtColor(cut, cv2.COLOR_BGR2GRAY)\n",
    "                blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "                thresh = cv2.threshold(blur, 255, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "                # Morph open to remove noise and invert image\n",
    "                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "                opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                inverted = 255 - opening\n",
    "                if show_plots:\n",
    "                    plt.imshow(inverted)\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "                out_val = pytesseract.image_to_string(inverted, lang='eng', config= set_psm)\n",
    "\n",
    "                # Catch translation encoding errors:\n",
    "                if out_val == '\\x0c':\n",
    "                    out.append('-')\n",
    "                else:\n",
    "                    out.append( out_val.split('\\n\\x0c')[0])\n",
    "\n",
    "        # Rebuilding the whole lable from its parts:            \n",
    "        return_str = ''.join(out)\n",
    "\n",
    "    # Check for lost \"-\" and search for them the manually identified db:    \n",
    "    minus_signs = [pos for pos, char in enumerate(return_str) if char == '-']\n",
    "    if (minus_signs != [0]) and (minus_signs != []):\n",
    "        match_found = False\n",
    "        for id_img in glob.glob('./identified_images/*.png'):\n",
    "            # Load images from manually identified db:\n",
    "            to_compare_to = cv2.imread(id_img)\n",
    "            if np.all(label == to_compare_to):\n",
    "                match_found = True\n",
    "                if '_' in id_img.split('./identified_images/')[-1]:\n",
    "                    return_str = id_img.split('./identified_images/')[-1].split('_')[0]\n",
    "                else:\n",
    "                    return_str = id_img.split('.png')[0].split('./identified_images/')[-1]\n",
    "                break\n",
    "\n",
    "        if match_found:\n",
    "            return float(return_str)\n",
    "        # if no match is found in the manually identified db, the user is asked to manually identifiy. \n",
    "        else:\n",
    "            plt.imshow(label)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            print(minus_signs)\n",
    "            return_str = input('please help me read this lable: ')\n",
    "            out_nr = 0\n",
    "            while True:\n",
    "                out_name = './identified_images/'+return_str+'_'+str(out_nr)+'.png'\n",
    "                out_nr += 1\n",
    "                if not os.path.isdir(out_name):\n",
    "                    break\n",
    "            \n",
    "            cv2.imwrite(out_name, label)\n",
    "    \n",
    "    return float(return_str)\n",
    "\n",
    "    \n",
    "def convert_label_y(label, show_input = False, show_plots = True, force_manual=True):\n",
    "    \"\"\"\n",
    "    Convert the image of a lable to characters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label : cv2.image \n",
    "        The image to convert.\n",
    "    show_input : bool\n",
    "        Plot the input before processing.\n",
    "    show_plots : bool\n",
    "        Show image while processing. \n",
    "    force_manual : bool\n",
    "        Set the convertion mode to manual for the user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The converted value.\n",
    "    \"\"\"\n",
    "\n",
    "    out = []\n",
    "\n",
    "    # Set up tesseract parameters for reading the labels of selected grid intersections\n",
    "    # '--psm 6' -> \"Assume a single uniform block of text.\" \n",
    "    # '--oem 3' -> default OCR (optical character recognition) engine\n",
    "    # '-c tessedit_char_whitelist' -> use a whitelist to avoid wrongly read characters\n",
    "    set_psm =  '--psm 6 --oem 3 -c tessedit_char_whitelist=0123456789-,._C preserve_interword_spaces=1' #'--psm 6' # 'outputbase digits'\n",
    "\n",
    "    if show_input:\n",
    "        plt.imshow(label)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    \n",
    "    # Resizing the label for ideal readability:    \n",
    "    label = image_resize(label, height=100, inter=cv2.INTER_CUBIC)\n",
    "    \n",
    "    if force_manual:\n",
    "        plt.imshow(label)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        return_str = input('please help me read this lable: ')\n",
    "    else:\n",
    "        # Enhancing the image to make it easier to read for tesseract:\n",
    "        gray = cv2.cvtColor(label, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "        thresh_val = 50\n",
    "        thresh = cv2.threshold(blur, thresh_val, thresh_val, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "        # Separating the characters of the image -> this way it is easier to identify lower quality images\n",
    "        # This done by looking for the spaces inbetween the characters. Their vertical sum should be mostly white\n",
    "        # Sometimes the space between the characters is very small. Depending on the font, examples like \"-4\" are often seen as one character.\n",
    "        edges = cv2.Canny(thresh,100,200)\n",
    "        vertical_sum = np.sum(edges, axis=0)\n",
    "        vertical_sum = vertical_sum != 0\n",
    "        changes = np.logical_xor(vertical_sum[1:], vertical_sum[:-1])\n",
    "        change_pts = np.nonzero(changes)[0]\n",
    "\n",
    "        if show_plots:\n",
    "            print('character detection')\n",
    "            plt.imshow(thresh)\n",
    "            for change in change_pts:\n",
    "                plt.axvline(change+1)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        # Iterating through the parts of the image -> the single characters\n",
    "        for i in range(len(change_pts)-1):\n",
    "            start = change_pts[i]\n",
    "            end =  change_pts[i+1]\n",
    "            if start != end and end-start > 10:\n",
    "                cut = label[:, start:end]\n",
    "                cut = cv2.copyMakeBorder(\n",
    "                         cut, \n",
    "                         1, \n",
    "                         1, \n",
    "                         20, \n",
    "                         20, \n",
    "                         cv2.BORDER_CONSTANT, \n",
    "                         value= [175,175,175]\n",
    "                      )\n",
    "                \n",
    "                # Changing back to grey for identification\n",
    "                gray = cv2.cvtColor(cut, cv2.COLOR_BGR2GRAY)\n",
    "                blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "                thresh = cv2.threshold(blur, 255, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "                # Morph open to remove noise and invert image\n",
    "                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "                opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                inverted = 255 - opening\n",
    "                if show_plots:\n",
    "                    plt.imshow(inverted)\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "                out_val = pytesseract.image_to_string(inverted, lang='eng', config= set_psm)\n",
    "\n",
    "                # Catch translation encoding errors:\n",
    "                if out_val == '\\x0c':\n",
    "                    out.append('')\n",
    "                else:\n",
    "                    out.append( out_val.split('\\n\\x0c')[0])\n",
    "\n",
    "        # Rebuilding the whole lable from its parts:            \n",
    "        return_str = ''.join(out)\n",
    "\n",
    "    # Check for wrongly identified characters:       \n",
    "    error_characters = [pos for pos, char in enumerate(return_str) if not np.isin(char, ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '.'])]\n",
    "    if (error_characters != [0]) and (error_characters != []):\n",
    "        for id_img in glob.glob('./identified_images/*.png'):\n",
    "            # Load images from manually identified db and check how similar they are:\n",
    "            to_compare_to = cv2.imread(id_img)\n",
    "\n",
    "            # Compute SSIM between the two images\n",
    "            (score, diff) = structural_similarity(label, to_compare_to, full=True)\n",
    "            print(\"Image Similarity: {:.4f}%\".format(score * 100))\n",
    "        plt.imshow(label)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        print(error_characters)\n",
    "        # Start manual identification:\n",
    "        return_str = input('please help me read this lable: ')\n",
    "        out_nr = 0\n",
    "        while True:\n",
    "            out_name = './identified_images/'+return_str+'_'+str(out_nr)+'.png'\n",
    "            out_nr += 1\n",
    "            if not os.path.isdir(out_name):\n",
    "                break\n",
    "\n",
    "        cv2.imwrite(out_name, label)\n",
    "\n",
    "    # Usecase specific correction -> catch reduced axis labels (where the whole axis is displayed in e.g. 10Â³)\n",
    "    if len(return_str) < 3:\n",
    "        val = float(return_str)*1000\n",
    "    else:\n",
    "        val = float(return_str)\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040401e2-77d6-46c8-b5b2-607e13b89a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digitize(file, height_input = False, show_plots = False):  \n",
    "    \"\"\"\n",
    "    Digitize an image into data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file : str \n",
    "        Path to the image file. \n",
    "    height_input : bool\n",
    "        True if the image shows height data on the y axis.\n",
    "        If not, it is assumed, that pressure is displayed on the y axis. \n",
    "    show_plots : bool\n",
    "        If True, the script will show all intermediate plots.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Dataframe\n",
    "        The digitized data - also saved to file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Settings for plots:\n",
    "    matplotlib.rcParams[\"figure.figsize\"] = (4, 3)\n",
    "    %matplotlib inline\n",
    "\n",
    "    # Load the image\n",
    "    print(file)\n",
    "    img = cv2.imread(file)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply a threshold to create a binary image\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Find the contours in the binary image\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    # Find the contour with the largest area (i.e., the plot data)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Get the bounding box of the contour\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "    # Crop the image to the bounding box\n",
    "    plot_only = img[y+10:y+h-1, x+1:x+w-1]\n",
    "    relative_y = y+10\n",
    "    relative_x = x+1\n",
    "    relative_y_xaxis =  y+h-1\n",
    "\n",
    "    # Save the cropped image\n",
    "    cv2.imwrite('test_plot_only.png', plot_only)\n",
    "\n",
    "    # Check if there is really data in the plot, otherwise this image is skipped\n",
    "    if np.mean(plot_only) <= 10:\n",
    "        print('All black')\n",
    "        return 0\n",
    "\n",
    "    # Convert the contour to a numpy array and transpose it\n",
    "    plot_data = largest_contour.squeeze().T\n",
    "\n",
    "    # Check if the meta data info box has text in it - if not, no valid data is displayed in this image -> return.\n",
    "    image = img[ 1269:1282, 20:500]\n",
    "    if np.mean(image) >= 205:\n",
    "        print('All white')\n",
    "        return 0\n",
    "\n",
    "    # Make characters sharper and distinguishable from blur:\n",
    "    image_l = image_resize(image, height = 50)\n",
    "    gray = cv2.cvtColor(image_l, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # Morph open to remove noise and invert image\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    inverted = 255 - opening\n",
    "\n",
    "    # Read meta data line:\n",
    "    data = pytesseract.image_to_string(inverted, lang='eng', config= '--psm 7')\n",
    "    \n",
    "    # Open plot image only - has been cropped before: \n",
    "    im = cv2.imread(\"test_plot_only.png\")\n",
    "\n",
    "    # Define lower and upper limits of our blue\n",
    "    BlueMax = np.array([128, 255, 255], np.uint8)\n",
    "    BlueMin = np.array([90, 50, 70], np.uint8)\n",
    "\n",
    "    # Go to HSV colourspace and get mask of blue pixels\n",
    "    HSV = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(HSV, BlueMin, BlueMax)\n",
    "\n",
    "    # Make all pixels in mask white -> the result is only the grid remaining\n",
    "    grid = copy.copy(im)\n",
    "    grid[mask == 0] = [255, 255, 255]\n",
    "    grid[0:, 0:15] = [255, 255, 255]\n",
    "\n",
    "    # Make all the pixels not in mask white -> the result is only the graph\n",
    "    im[mask > 0] = [255, 255, 255]\n",
    "    im[0:100, 0:15] = [255, 255, 255]\n",
    "    im[-2:, :] = [255, 255, 255]\n",
    "\n",
    "    # Save both separated parts of the image\n",
    "    cv2.imwrite(\"test_grid_only.png\", grid)\n",
    "    cv2.imwrite(\"test_data_only.png\", im)\n",
    "\n",
    "    # Start analyzing the grid by converting everything into grays\n",
    "    grid = cv2.imread('test_grid_only.png')\n",
    "    gray = cv2.cvtColor(grid, cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "\n",
    "    # Start analyzing the grid by converting everything into grays\n",
    "    dst = cv2.cornerHarris(gray, 5,19,0.07)\n",
    "    dst = cv2.dilate(dst, None)\n",
    "\n",
    "    # Get coordinates of intersections\n",
    "    ret, dst = cv2.threshold(dst, 0.1 * dst.max(), 255, 0)\n",
    "    dst = np.uint8(dst)\n",
    "\n",
    "    # Find centroids of the intersections \n",
    "    ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
    "\n",
    "    # Define the criteria to stop and refine the corners\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, \n",
    "                0.001)\n",
    "    corners = cv2.cornerSubPix(gray,np.float32(centroids[1:]),(5,5), \n",
    "          (-1,-1),criteria)\n",
    "    \n",
    "    # Get the intersections, but only within the inner 64% of the image, to avoid artifacts from the very outside of the plot \n",
    "    for corner in corners:\n",
    "        grid[int(corner[1]), int(corner[0])] = [0, 0, 255]\n",
    "    corner_coords = np.asarray(corners, dtype = int)\n",
    "    corner_coords = corner_coords[corner_coords[:,0] < np.max(corner_coords[:,0]) * 0.9]\n",
    "    corner_coords = corner_coords[corner_coords[:,1] < np.max(corner_coords[:,1]) * 0.9]\n",
    "    corner_coords = corner_coords[corner_coords[:,0] > np.max(corner_coords[:,0]) * 0.1]\n",
    "    corner_coords = corner_coords[corner_coords[:,1] > np.max(corner_coords[:,1]) * 0.1]\n",
    "    \n",
    "    # Create a image with drawn circles, where intersections are - just as a refference\n",
    "    for co in corner_coords:\n",
    "        grid = cv2.circle(grid, co, radius=4, color=(255, 0, 0), thickness=-1)\n",
    "\n",
    "    # choosing 2 of the intersection -> once with pixel sum maximum and once with pixel sum minimum -> diagonal with largest distance\n",
    "    grid = cv2.imread('test_grid_only.png')\n",
    "    maxcoord = np.argmax(np.sum(corner_coords, axis = 1))\n",
    "    mincoord = np.argmin(np.sum(corner_coords, axis = 1))\n",
    "\n",
    "    # Mark the two selected intersections:\n",
    "    coords_low = corner_coords[mincoord]\n",
    "    coords_high = corner_coords[maxcoord]\n",
    "    grid = cv2.circle(grid, coords_low, radius=4, color=(0, 0, 255), thickness=-1)\n",
    "    grid = cv2.circle(grid, coords_high, radius=4, color=(0, 0, 255), thickness=-1)\n",
    "\n",
    "    # The two selected grid intersections and their two labels (x & y) will be analysed\n",
    "    low_y_label = img[relative_y + coords_low[1]-10: relative_y + coords_low[1]+10, relative_x-45:relative_x-1]\n",
    "    low_y_val = convert_label_y(low_y_label, show_input = False, show_plots = show_plots)\n",
    "    print(low_y_val)\n",
    "    \n",
    "    high_y_label = img[relative_y + coords_high[1]-10: relative_y + coords_high[1]+10, relative_x-45:relative_x-1]\n",
    "    high_y_val = convert_label_y(high_y_label, show_input = False, show_plots = show_plots)\n",
    "    print(high_y_val)\n",
    "\n",
    "    low_x_label = img[relative_y_xaxis+1 : relative_y_xaxis+20, relative_x+coords_low[0]-20:relative_x+coords_low[0]+30]\n",
    "    low_x_val = convert_label_x(low_x_label, show_input = False, show_plots = show_plots)\n",
    "    print(low_x_val)    \n",
    "    \n",
    "    high_x_label = img[relative_y_xaxis+1 : relative_y_xaxis+20, relative_x+coords_high[0]-30:relative_x+coords_high[0]+30]\n",
    "    high_x_val = convert_label_x(high_x_label, show_input = False, show_plots = show_plots)\n",
    "    print(high_x_val)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Quality controll of read data, \"-\" often go missing, if a value lower on the axis is larger than the following one, it can be assumed, that the \"-\" got lost in the process:\n",
    "    if low_x_val > 0 and low_x_val > high_x_val:\n",
    "        low_x_val = str(float(low_x_val) * -1)\n",
    "        print('changed to: ', low_x_val)\n",
    "    \n",
    "    # Converting axis labels to data\n",
    "    xa_p = [coords_low[0], coords_high[0]]\n",
    "    xa_v = [273.15+low_x_val, 273.15+high_x_val]\n",
    "    ya_p = [coords_low[1], coords_high[1]]\n",
    "    ya_v = [low_y_val, high_y_val]\n",
    "    \n",
    "    ###                                                                                         ###\n",
    "    # Now it is necessary to convert the coordinates of the analysed values into a function.      #  \n",
    "    # With that function all points of the graph can then be converted from pixel to data values. #\n",
    "    ###                                                                                         ###\n",
    "\n",
    "    # Calculation of axis functions\n",
    "    # x-axis\n",
    "    x1 = xa_p[0]\n",
    "    a = xa_v[0]\n",
    "    x2 = xa_p[1]\n",
    "    b = xa_v[1]\n",
    "\n",
    "    m_T = (b - a) / (x2 - x1)\n",
    "    c_T = a - m_T * x1\n",
    "    def T(x):\n",
    "        return m_T * x + c_T\n",
    "\n",
    "    # y-axis\n",
    "    if height_input:\n",
    "        y1 = ya_p[0]\n",
    "        ap = ya_v[0]\n",
    "        y2 = ya_p[1]\n",
    "        bp = ya_v[1]\n",
    "    else: \n",
    "        y1 = ya_p[0]\n",
    "        ap = np.log(ya_v[0])\n",
    "        y2 = ya_p[1]\n",
    "        bp = np.log(ya_v[1])\n",
    "\n",
    "    m = (bp - ap) / (y2 - y1)\n",
    "    c = ap - m * y1\n",
    "    def P(x):\n",
    "        return m * x + c\n",
    "    \n",
    "    # Selection of data points via contour of graph:\n",
    "    graph = cv2.imread('test_data_only.png')\n",
    "    edge = cv2.Canny(graph, 30, 200) \n",
    "    ans = []\n",
    "    for y in range(0, edge.shape[0]):\n",
    "        for x in range(0, edge.shape[1]):\n",
    "            if edge[y, x] != 0:\n",
    "                ans = ans + [[x, y]]\n",
    "    ans = np.array(ans)\n",
    "    if len(ans) == 0:\n",
    "        return 0\n",
    "\n",
    "    for co in ans[:]:\n",
    "        image = cv2.circle(graph, co, radius=4, color=(255, 0, 0), thickness=-1)\n",
    "\n",
    "    # Check that all parts of the graph are different and not too close toghter -> avoid false increase of resoultion. \n",
    "    unique_steps = []\n",
    "    for i in range(np.min(ans[:,1]), np.max(ans[:,1])+1):\n",
    "        step = ans[ans[:,1] == i]\n",
    "        if len(step) > 1:\n",
    "            mean_step = (np.mean(step, axis=0))\n",
    "            unique_steps.append([int(mean_step[0]), int(mean_step[1])])\n",
    "        elif len(step) == 1:\n",
    "            unique_steps.append([int(step[0][0]), (step[0][1])])\n",
    "    \n",
    "\n",
    "    # Transform pixel points to data\n",
    "    out = {}\n",
    "    if height_input:\n",
    "        out['press'] = P(np.array(unique_steps)[:,1])\n",
    "    else:\n",
    "        out['press'] = np.exp(P(np.array(unique_steps)[:,1]))\n",
    "    out['temp'] = T(np.array(unique_steps)[:,0])\n",
    "\n",
    "    # Write converted data into a dataframe to save it. \n",
    "    df = pd.DataFrame.from_dict(out)\n",
    "    df = df.sort_values('press')\n",
    "    if height_input:\n",
    "        df.to_csv('./output_height/' + file.split('sc_')[-1].split('.png')[0]+'.csv')\n",
    "    else:\n",
    "        df.to_csv('./output/' + file.split('sc_')[-1].split('.png')[0]+'.csv')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4659c3-03b0-4b16-9d3e-4328d8f43134",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in glob.glob('./new_screen_shots/sc_Modem_26_1*.png')[:]: # MKII_'+str(j)+'\n",
    "    df = digitize(i, height_input = True, show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44327888-fb58-4321-82cb-603b5308c10b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
