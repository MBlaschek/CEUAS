{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "import sys,glob\n",
    "import zipfile, os, time\n",
    "import urllib3\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "import h5py\n",
    "sys.path.append(os.getcwd()+'/../cds-backend/code/')\n",
    "sys.path.append(os.getcwd()+'/../harvest/code/')\n",
    "from harvest_convert_to_netCDF_newfixes import write_dict_h5\n",
    "import cds_eua3 as eua\n",
    "eua.logging_set_level(30)\n",
    "import xarray as xr\n",
    "\n",
    "import cdsapi, zipfile, os, time\n",
    "#import schedule\n",
    "import copy\n",
    "from shutil import copyfile\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as pylab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "\n",
    "# c = cdsapi.Client()\n",
    "# r = c.retrieve(\n",
    "#     'insitu-comprehensive-upper-air-observation-network',\n",
    "#     {\n",
    "#         'variable':['air_temperature',],\n",
    "#         'statid':'all',\n",
    "#         'date': '19780101-20181231',\n",
    "#         'pressure_level': 100,\n",
    "#     })\n",
    "# if True:\n",
    "#     # Start Download\n",
    "#     r.download(target='download.zip')\n",
    "#     # Check file size\n",
    "#     assert os.stat('download.zip').st_size == r.content_length, \"Downloaded file is incomplete\"\n",
    "    \n",
    "# print(\"Time elapsed: \", time.time()-t0, \"s\")\n",
    "# z = zipfile.ZipFile('download.zip')\n",
    "# print(\"Unzipping retrieved files\")\n",
    "# z.extractall(path='./comp100hpa')\n",
    "# z.close()\n",
    "# os.remove('download.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compf = glob.glob('./comp100hpa/*.nc')\n",
    "print(len(compf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(compf[0])\n",
    "df = ds.to_dataframe()\n",
    "np.asarray(df.ta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compf = glob.glob('./comp100hpa/*.nc')[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(compf[1])\n",
    "df = ds.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=time.time()\n",
    "ds = xr.open_dataset(compf[1])\n",
    "a = np.array(ds.time.values)\n",
    "a.astype('M8[D]')\n",
    "# np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(compf[1])\n",
    "ds = ds.where(ds.time < np.datetime64('2006-12-31T00:23:59.999999999'), drop=True)\n",
    "ds.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "5194\n",
      "0\n",
      "6221\n",
      "632\n"
     ]
    }
   ],
   "source": [
    "stations = pickle.load( open( \"stations.p\", \"rb\" ))\n",
    "out = stations[0:0]\n",
    "\n",
    "start = 1978\n",
    "end = 2006\n",
    "dtend = np.datetime64('2006-12-31T00:23:59.999999999')\n",
    "intervall = end - start\n",
    "compf = glob.glob('./comp100hpa/*.nc')[:5]\n",
    "for i in compf:\n",
    "    with xr.open_dataset(i) as ds:\n",
    "        ds = ds.where(ds.time < dtend, drop=True)\n",
    "        timelen = len(np.unique(ds.time.values.astype('M8[D]')))\n",
    "        print(timelen)\n",
    "    #     if timelen >= 0.9*intervall*365:\n",
    "    #         selected = np.asarray(ds.ta.values)\n",
    "    #         datlen = len(selected)\n",
    "    #         try:\n",
    "    #             coefficients, residuals, _, _, _ = np.polyfit(range(datlen),selected,1,full=True)\n",
    "    #             trend = coefficients[0]*(10/intervall*len(ds.ta.values))\n",
    "    #             out.loc[len(out.index)] = [trend, ds.lon.values[0], ds.lat.values[0]]\n",
    "    #         except:\n",
    "    #             pass\n",
    "# pickle.dump( out, open( \"COMP_100hPa_1978_2006_Trend.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pickle.load( open( \"stations.p\", \"rb\" ))\n",
    "start = 1978\n",
    "end = 2006\n",
    "intervall = end - start\n",
    "mindata = int(intervall*0.9)\n",
    "for i in range(len(stations.station_name)):\n",
    "    files = glob.glob('/raid60/scratch/uli/IGRA_Data/temp300h/IGRA_H_' + stations.station_name.iloc[i] + '*.p')\n",
    "#     files = glob.glob('/raid60/scratch/uli/IGRA_Data/temp300/IGRA_' + stations.station_name.iloc[i] + '*.p')\n",
    "    filesinintervall = []\n",
    "    for o in files:\n",
    "        yr = int(o.split('_')[-2])\n",
    "        if yr <= end and yr >= start:\n",
    "            filesinintervall.append(o)\n",
    "    if len(filesinintervall) < mindata:\n",
    "        stations.station_name.iloc[i] = np.nan\n",
    "    else:\n",
    "        temp = []\n",
    "        for j in filesinintervall:\n",
    "            temp.extend(pickle.load( open( j, \"rb\" )))\n",
    "        selected = np.asarray(temp)[~np.isnan(np.asarray(temp))]\n",
    "        datlen = len(selected)\n",
    "        try:\n",
    "            coefficients, residuals, _, _, _ = np.polyfit(range(datlen),selected,1,full=True)\n",
    "            stations.station_name.iloc[i] = coefficients[0]*(10/intervall*len(temp))\n",
    "        except:\n",
    "            stations.station_name.iloc[i] = np.nan\n",
    "pickle.dump( stations, open( \"IGRA_H_300hPa_1978_2006_Trend.p\", \"wb\" ))\n",
    "# pickle.dump( stations, open( \"IGRA_300hPa_1978_2018_Trend.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/raid60/scratch/uli/IGRA_H/*/*global_cdm-lev.csv')\n",
    "# print(len(files_h))\n",
    "# files_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def savetoarray(file, dataset: str='IGRA_H', dest: str='./temp100/'):\n",
    "#     yr = file.split('/')[5]\n",
    "#     plev = 10000\n",
    "#     chunk = pd.read_csv(file, header=12, index_col=False, usecols=['station_name', 'observed_value', 'air_pressure'])\n",
    "#     stations = chunk.station_name.drop_duplicates()\n",
    "#     for i in stations:\n",
    "#         if not os.path.isfile( dest + dataset + '_' + i + '_' + yr + '_' + str(plev) + \".p\"):\n",
    "#             da = chunk[chunk.station_name == i]\n",
    "#             da = da[da.air_pressure == plev]\n",
    "#             pickle.dump( np.asarray(da.observed_value), open( dest + dataset + '_' + i + '_' + yr + '_' + str(plev) + \".p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stations = []\n",
    "# for i in range(len(files)):\n",
    "#     if i == 0:\n",
    "#         chunk = pd.read_csv(files[i], header=12, index_col=False, usecols=['location_longitude', 'location_latitude', 'station_name'])\n",
    "#         stations = chunk.drop_duplicates(['station_name'])\n",
    "#     else:\n",
    "#         chunk = pd.read_csv(files[i], header=12, index_col=False, usecols=['location_longitude', 'location_latitude', 'station_name'])\n",
    "#         stations = pd.concat([stations, chunk.drop_duplicates(['station_name'])], ignore_index=True)\n",
    "# stations = stations.drop_duplicates('station_name')\n",
    "# pickle.dump( stations, open( \"stations.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>location_longitude</th>\n",
       "      <th>location_latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KRM00091487</td>\n",
       "      <td>-159.3670</td>\n",
       "      <td>3.8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHM00055664</td>\n",
       "      <td>87.0830</td>\n",
       "      <td>28.6330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHM00056444</td>\n",
       "      <td>98.8830</td>\n",
       "      <td>28.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BMM00048062</td>\n",
       "      <td>92.8830</td>\n",
       "      <td>20.1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHM00057290</td>\n",
       "      <td>114.0500</td>\n",
       "      <td>32.9670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36592</th>\n",
       "      <td>INM00043110</td>\n",
       "      <td>73.3333</td>\n",
       "      <td>16.9833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37459</th>\n",
       "      <td>INM00042165</td>\n",
       "      <td>73.3000</td>\n",
       "      <td>28.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37460</th>\n",
       "      <td>INM00042328</td>\n",
       "      <td>70.9167</td>\n",
       "      <td>26.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37461</th>\n",
       "      <td>RPM00098233</td>\n",
       "      <td>121.7525</td>\n",
       "      <td>17.6375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37462</th>\n",
       "      <td>USM00074003</td>\n",
       "      <td>-112.9333</td>\n",
       "      <td>40.1667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_name  location_longitude  location_latitude\n",
       "0      KRM00091487           -159.3670             3.8500\n",
       "1      CHM00055664             87.0830            28.6330\n",
       "2      CHM00056444             98.8830            28.4500\n",
       "3      BMM00048062             92.8830            20.1330\n",
       "4      CHM00057290            114.0500            32.9670\n",
       "...            ...                 ...                ...\n",
       "36592  INM00043110             73.3333            16.9833\n",
       "37459  INM00042165             73.3000            28.0000\n",
       "37460  INM00042328             70.9167            26.9000\n",
       "37461  RPM00098233            121.7525            17.6375\n",
       "37462  USM00074003           -112.9333            40.1667\n",
       "\n",
       "[1494 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = pickle.load( open( \"stations.p\", \"rb\" ))\n",
    "stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1979-2019, sowie 1979-2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pickle.load( open( \"stations.p\", \"rb\" ))\n",
    "start = 1978\n",
    "end = 2018\n",
    "intervall = end - start\n",
    "mindata = int(intervall*0.9)\n",
    "for i in range(len(stations.station_name)):\n",
    "    files = glob.glob('/raid60/scratch/uli/IGRA_Data/temp300/IGRA_' + stations.station_name.iloc[i] + '*.p')\n",
    "#     files = glob.glob('/raid60/scratch/uli/IGRA_Data/temp300/IGRA_' + stations.station_name.iloc[i] + '*.p')\n",
    "    filesinintervall = []\n",
    "    for o in files:\n",
    "        yr = int(o.split('_')[-2])\n",
    "        if yr <= end and yr >= start:\n",
    "            filesinintervall.append(o)\n",
    "    if len(filesinintervall) < mindata:\n",
    "        stations.station_name.iloc[i] = np.nan\n",
    "    else:\n",
    "        temp = []\n",
    "        for j in filesinintervall:\n",
    "            temp.extend(pickle.load( open( j, \"rb\" )))\n",
    "        selected = np.asarray(temp)[~np.isnan(np.asarray(temp))]\n",
    "        datlen = len(selected)\n",
    "        try:\n",
    "            coefficients, residuals, _, _, _ = np.polyfit(range(datlen),selected,1,full=True)\n",
    "            stations.station_name.iloc[i] = coefficients[0]*(10/intervall*len(temp))\n",
    "        except:\n",
    "            stations.station_name.iloc[i] = np.nan\n",
    "pickle.dump( stations, open( \"IGRA_300hPa_1978_2018_Trend.p\", \"wb\" ))\n",
    "# pickle.dump( stations, open( \"IGRA_300hPa_1978_2018_Trend.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IGRA_300hPa_1978_2018_Trend.p',\n",
       " 'IGRA_100hPa_1978_2018_Trend.p',\n",
       " 'IGRA_H_300hPa_1978_2018_Trend.p',\n",
       " 'IGRA_H_300hPa_1978_2006_Trend.p',\n",
       " 'IGRA_300hPa_1978_2006_Trend.p',\n",
       " 'IGRA_100hPa_1978_2006_Trend.p',\n",
       " 'IGRA_H_50hPa_1978_2018_Trend.p',\n",
       " 'IGRA_50hPa_1978_2018_Trend.p',\n",
       " 'IGRA_50hPa_1978_2006_Trend.p',\n",
       " 'IGRA_H_50hPa_1978_2006_Trend.p',\n",
       " 'IGRA_H_100hPa_1978_2006_Trend.p',\n",
       " 'IGRA_H_100hPa_1978_2018_Trend.p']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trends = glob.glob('IGRA*Trend.p')\n",
    "trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_trends(i):\n",
    "    params = {'legend.fontsize': 'x-large',\n",
    "              'figure.figsize': (12, 8),\n",
    "             'axes.labelsize': 'x-large',\n",
    "             'axes.titlesize': 20,\n",
    "             'xtick.labelsize':'medium',\n",
    "             'ytick.labelsize':'medium'}\n",
    "    pylab.rcParams.update(params)\n",
    "\n",
    "    igra = pickle.load( open( i, \"rb\" ))\n",
    "\n",
    "    ax = plt.axes([0, 0, 1, 1], projection=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.OCEAN, zorder=0)\n",
    "    ax.coastlines()\n",
    "\n",
    "    da = igra.dropna()\n",
    "    reduced = np.asarray(da['station_name'])\n",
    "    longitudes = list(da['location_longitude'])\n",
    "    latitudes = list(da['location_latitude'])\n",
    "    plt.scatter(longitudes, latitudes, s=40, alpha=1,\n",
    "                c= da['station_name'],\n",
    "                cmap='seismic',\n",
    "                vmin=-2,\n",
    "                vmax=2)\n",
    "    plt.colorbar(orientation='horizontal', label='K/10a', shrink=0.9, pad=0.05)\n",
    "    plt.tight_layout()\n",
    "    plt.title(i.split('.')[0])\n",
    "    plt.savefig('plots/'+i+'ng', bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-d1049efc05a0>:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "<ipython-input-5-d1049efc05a0>:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "<ipython-input-5-d1049efc05a0>:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "<ipython-input-5-d1049efc05a0>:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "<ipython-input-5-d1049efc05a0>:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "<ipython-input-5-d1049efc05a0>:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "<ipython-input-5-d1049efc05a0>:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "<ipython-input-5-d1049efc05a0>:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "<ipython-input-5-d1049efc05a0>:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "<ipython-input-5-d1049efc05a0>:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "<ipython-input-5-d1049efc05a0>:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "<ipython-input-5-d1049efc05a0>:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "for i in trends:\n",
    "    plt_trends(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59      -319.228\n",
       "67      -759.201\n",
       "89      -555.898\n",
       "91      -81.1182\n",
       "99      -182.975\n",
       "          ...   \n",
       "4822     179.013\n",
       "4835     3765.76\n",
       "4838      218.52\n",
       "4839     28.4268\n",
       "5625   -0.268902\n",
       "Name: station_name, Length: 394, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da['station_name']*3650"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0927977002580942"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "# colors = np.array(colors, dtype=np.float)\n",
    "# col = [cm.tab20(x) for x in range(len(reduced))]\n",
    "# col = [cm.tab20(x/len(reduced)) for x in range(len(reduced))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'col' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5f23b1bbf015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'col' is not defined"
     ]
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savetoarray(file, dataset: str='IGRA', dest: str='./temp100/'):\n",
    "    yr = file.split('/')[5]\n",
    "    plev = 10000\n",
    "    chunk = pd.read_csv(file, header=12, index_col=False, usecols=['station_name', 'observed_value', 'air_pressure'])\n",
    "    stations = chunk.station_name.drop_duplicates()\n",
    "    for i in stations:\n",
    "        if not os.path.isfile( dest + dataset + '_' + i + '_' + yr + '_' + str(plev) + \".p\"):\n",
    "            da = chunk[chunk.station_name == i]\n",
    "            da = da[da.air_pressure == plev]\n",
    "            pickle.dump( np.asarray(da.observed_value), open( dest + dataset + '_' + i + '_' + yr + '_' + str(plev) + \".p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    pool = multiprocessing.Pool(processes=20)\n",
    "    result_list = pool.map(savetoarray, files[10:20])\n",
    "    print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon = igra.report_timestamp.drop_duplicates()\n",
    "lat = igra.location_longitude.drop_duplicates()\n",
    "print(len(lon))\n",
    "print(len(lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGRA and its harmonized version\n",
    "for i in range(len(files)):\n",
    "    print(i)\n",
    "    if i == 0:\n",
    "#         igra = pandas.read_csv(files[i], header=12)\n",
    "        igrah = pandas.read_csv(files_h[i], header=12)\n",
    "    else:\n",
    "#         igra = igra.append(pandas.read_csv(files[i], header=12))\n",
    "        igrah = igrah.append(pandas.read_csv(files_h[i], header=12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preslist = [10000, 20000, 50000, 85000,]\n",
    "for i in range(len(preslist)):\n",
    "    c = comp[comp.plev == preslist[i]]\n",
    "    c.time = pandas.to_datetime(c.time, utc=True)\n",
    "    xax = np.asarray(c.time)\n",
    "    \n",
    "    selected = c.ta\n",
    "    datlen = len(selected)\n",
    "    coefficients, residuals, _, _, _ = np.polyfit(range(datlen),selected,1,full=True)\n",
    "    mse = residuals[0]/(datlen)\n",
    "    nrmse = np.sqrt(mse)/(selected.max() - selected.min())\n",
    "\n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    ax1.plot(xax, np.asarray(selected), label = 'COMP', alpha=0.7)\n",
    "    ax1.plot(xax, [coefficients[0]*x + coefficients[1] for x in range(len(selected))], label = 'COMP trend')\n",
    "    ax1.set(xlabel ='time [multiples of 12h]', ylabel='temperature [K]', title='COMP Trend '+str(int(preslist[i]/100))+'hPa '+loc)\n",
    "    textstr = 'Slope ' + str(coefficients[0]) +'\\n'+'NRMSE: ' + str(nrmse)\n",
    "    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "    ax1.text(0.03, 0.95, textstr, transform=ax1.transAxes, fontsize=16, verticalalignment='top', bbox=props)\n",
    "\n",
    "\n",
    "    ax1.legend( loc='best')\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Miniconda3 (4.8.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
