{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged Station Analizer\n",
    "***\n",
    "#####     **module**     :: test_merged_CDM.py        \n",
    "#####     **author**     :: Federico Ambrogi , federico.ambrogi@univie.ac.at \n",
    "#####     **desciption** :: Analyzes the merged file produced by the utility merging_all_last.py   \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "import h5py\n",
    "import matplotlib.pylab as plt\n",
    "import numpy\n",
    "import glob\n",
    "import os,sys\n",
    "import matplotlib.gridspec as gridspec\n",
    "import xarray as xr \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "\n",
    "fn = '/raid8/srvx1/federico/GitHub/CEUAS_master_FEBRUARY2021/CEUAS/CEUAS/public/merge/PROVA/0-20000-0-94120_CEUAS_merged_v0_twohours.nc'\n",
    "f = h5py.File(fn,'r')\n",
    "nm = fn.split('/')[-1]\n",
    "SIZE = 1.5\n",
    "#print(list(f['observations_table'].keys()))\n",
    "fo=f['observations_table']\n",
    "\n",
    "\n",
    "os.system('mkdir Plots')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of the Input Files\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timeseries(data= '', variables= '' , p_levels= '' , station= '' , date_range= ['',''] , print_df = False , text = ''):\n",
    "    \"\"\" Function to plot time series \"\"\"\n",
    "\n",
    "    datasets_dic = Common.datasets_dic\n",
    "    style_dic    = Common.style_dic\n",
    "    fs           = Common.fontsize \n",
    "\n",
    "    date_min, date_max = date_range[0], date_range[1]\n",
    "    \n",
    "    for v in variables:\n",
    "\n",
    "        data_v = data.loc[ (data['observed_variable'] == v) ]\n",
    "        \n",
    "        \n",
    "        for p in p_levels:\n",
    "            \n",
    "            data_p = data_v.loc[ (data_v[\"z_coordinate\"] == p ) & ( data_v[\"z_coordinate_type\"] == 1)  ] # filtering on various pressure levels\n",
    "\n",
    "            #plt.figure(figsize=(20,10)) \n",
    "            fig, ax = plt.subplots(figsize=(16,9))\n",
    "            ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "            ax.tick_params(axis='both', which='minor', labelsize=8)\n",
    "        \n",
    "            plt.grid(ls =\":\" , color = \"lightgray\")\n",
    "            \n",
    "            if  date_min and date_max:\n",
    "                data_p = data_p.loc[ (data_p[\"date_time\"] >= date_min ) & (data_p[\"date_time\"] < date_max )  ] # option filtering on date range\n",
    "\n",
    "                plt.xlim(date_min, date_max)\n",
    "            \n",
    "            source_datasets = np.unique(data_p[\"source_id\"][:])\n",
    "            print(\"All sources::: \" , source_datasets )\n",
    "    \n",
    "            for s in [ b'era5_1759', b'igra2', b'ncar', b'era5_1' , b'era5_2']:\n",
    "            #for s in source_datasets:\n",
    "                d = data_p.loc[ (data_p['source_id'] == s) ]\n",
    "                x = d[\"date_time\"].values\n",
    "                y = d[\"observation_value\"].values\n",
    "                S = s.decode(\"utf-8\")\n",
    "                #S = s\n",
    "                #print(\"Length for \" , str(S) , \" is: \", len(x) ) \n",
    "            \n",
    "                num    = '[' + str(len(x)) + ']'\n",
    "                legend =  datasets_dic[S]['l'] + ' ' + num \n",
    "                color  = datasets_dic[S]['c']\n",
    "            \n",
    "                #plt.plot(x, y, label = legend , color = color )\n",
    "                plt.scatter(x, y, label = legend , color = color )\n",
    "                \n",
    "                \"\"\" Print here the dataframe \"\"\"\n",
    "                if print_df:\n",
    "                    dates = [datetime.datetime(1959,12,14) , datetime.datetime(1959,12,15)]\n",
    "                    df = d.loc [ (d[\"date_time\"] >= dates[0]) & (d[\"date_time\"] < dates[1])     ] \n",
    "                    pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "                    if not df.empty:\n",
    "                        print( '  ' + S + '--------------------------------------------------------------------------------' , '\\n', df)\n",
    "        \n",
    "            #plt.xlabel(\"Date Time\", fontsize = fs)\n",
    "            pressure = str(int(p/100) )\n",
    "            plt.ylabel( style_dic[v]['l'] , fontsize = fs + 2 )\n",
    "            \n",
    "            #levels    = [100000, 50000, 1000]    \n",
    "\n",
    "            #plt.text(0.73, 0.93, 'Plevel=' + pressure + ' [hPa]' , transform=ax.transAxes, color = 'red', fontsize = fs+5)\n",
    "            \n",
    "            plt.legend(loc = 'best', fontsize = fs)    \n",
    "\n",
    "            \n",
    "            plt.title(\"Station \" + station + ' - Plevel=' + pressure + ' [hPa]' , fontsize = fs + 4, y = 1.03 )\n",
    "            \n",
    "            plt.savefig(out_dir + '/' + station + \"_time_series_\" + \"_pressure_\" + pressure + \"_var_\" + str(v) + text + \".pdf\",\n",
    "                         bbox_inches = 'tight' , dpi = 250 )\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            print(\"*** Plot created for variable \", v , \"  at pressure level \" , str(p) )\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series for selected variables\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Select variable and a date_time range to plot \"\"\"\n",
    "\n",
    "#variables = [85,104,105,106,107,117]\n",
    "#levels    = [100000, 50000, 1000]    \n",
    "\n",
    "variables = [85,104,105,106,107,117]\n",
    "levels    = [100000, 90000, 50000, 1000]    \n",
    "\n",
    "\n",
    "variables = [85]\n",
    "levels    = [100000,1000]  \n",
    "\n",
    "variables = [85]\n",
    "levels    = [85000, 70000]  \n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "date_min = '1950-01-01 00:00:00.1'\n",
    "date_max = '2020-01-01 00:00:00.1'\n",
    "min_dt = datetime.datetime.strptime(date_min, '%Y-%m-%d %H:%M:%S.%f')\n",
    "max_dt = datetime.datetime.strptime(date_max, '%Y-%m-%d %H:%M:%S.%f')\n",
    "#do = plot_timeseries(data = ot, variables = variables , p_levels = levels , station = station,  date_range = [min_dt,max_dt] , text = '_all' ) \n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "date_min = '1900-01-01 00:00:00.1'\n",
    "date_max = '2020-01-01 00:00:00.1'\n",
    "min_dt = datetime.datetime.strptime(date_min, '%Y-%m-%d %H:%M:%S.%f')\n",
    "max_dt = datetime.datetime.strptime(date_max, '%Y-%m-%d %H:%M:%S.%f')\n",
    "#do = plot_timeseries(data = ot, variables = variables , p_levels = levels , station = station,  date_range = [min_dt,max_dt] , text = '1900_2020' ) \n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "date_min = '1959-12-11 00:00:00.1'\n",
    "date_max = '1959-12-15 00:00:00.1'\n",
    "min_dt = datetime.datetime.strptime(date_min, '%Y-%m-%d %H:%M:%S.%f')\n",
    "max_dt = datetime.datetime.strptime(date_max, '%Y-%m-%d %H:%M:%S.%f')\n",
    "#do = plot_timeseries(data = ot, variables = variables , p_levels = levels , station = station,  date_range = [min_dt,max_dt] , print_df = True) \n",
    "\n",
    "variables = [85,104,105,106,107,117]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dataset_hist(data= \"\" ,  variables= '' , p_levels= '' , station= '' , date_range= ['',''] , text='' , text_save = ''):\n",
    "    \"\"\" Function to plot the distributions of datasets used in the merged file.\n",
    "        Works with header_table or observations_table df (header is faster) \"\"\"\n",
    "    \n",
    "    os.system('mkdir output')\n",
    "    \n",
    "    all_sources = set(data[\"source_id\"])\n",
    "\n",
    "    #S = s.decode(\"utf-8\")\n",
    "    \n",
    "    if  date_min and date_max:\n",
    "        D = data.loc[ (data[\"date_time\"] >= date_min ) & \n",
    "                    (data[\"date_time\"] < date_max )  ] # option filtering on date range\n",
    "    \n",
    "    \n",
    "    \"\"\" Retrieving the style dictionaries \"\"\"\n",
    "    datasets_dic = Common.datasets_dic\n",
    "    style_dic    = Common.style_dic\n",
    "    fs = Common.fontsize - 2\n",
    "    \n",
    "    def count_data(data):\n",
    "        \"\"\" Counts data for the plot, make lables etc. \"\"\"\n",
    "        occ = dict(Counter(data[\"source_id\"]) ) # Counter returns a dic with keys= all the items in the list, values=number of occurences per each item \n",
    "        for s in all_sources: #  putting back the sources with zero entries for nicer plots \n",
    "            if s not in list(occ.keys()):\n",
    "                occ[s] = 0\n",
    "       \n",
    "        counts , labels, color = [], [] , []\n",
    "        \n",
    "        for source in Common.datasets:  # the double loops allows to plot the datasets always in the order defined in the list Common.all_sources\n",
    "\n",
    "            for k,v in occ.items():\n",
    "\n",
    "                l = k.decode(\"utf-8\")\n",
    "                if source == l:\n",
    "                    labels.append(datasets_dic[l][\"l\"])\n",
    "                    counts.append(v)\n",
    "                    color .append( datasets_dic[l][\"c\"] )\n",
    "                else:\n",
    "                    continue \n",
    "\n",
    "        x = np.arange(len(occ)) # np.arange(3) = array([0, 1, 2])\n",
    "\n",
    "        return counts, labels, color, x\n",
    "\n",
    "   \n",
    "    def plot_bar(data= '', ax = '', rotation = False , text = '' , station = ''):\n",
    "        \"\"\" Creates a simple bar plots \"\"\"\n",
    "        counts, labels, color, x = count_data(data)\n",
    "        \n",
    "        if not ax:\n",
    "            fig, ax = plt.subplots(figsize=(10,7))\n",
    "            \n",
    "        formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "        formatter.set_scientific(True) \n",
    "        formatter.set_powerlimits((-1,1)) \n",
    "        ax.yaxis.set_major_formatter(formatter) \n",
    "    \n",
    "        ax.grid(ls =\":\" , color = \"lightgray\")\n",
    "        ax.bar(x, counts, color = color )\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(labels, fontsize = fs )\n",
    "        if rotation:\n",
    "            ax.set_xticklabels(labels, rotation = 45, fontsize = fs )\n",
    "\n",
    "    \n",
    "    \"\"\" Global counts (all pressure levels) \"\"\"\n",
    "    #print(\"Plotting ::: Global counts (all pressure levels)\")\n",
    "    a = plot_bar(data=data , text= text, station = station)\n",
    "    plt.ylabel(\"Data Counts (all records)\", fontsize = fs )\n",
    "    plt.title('Record counts per data source for Station ' + str(station) + ' ' + text , y=1.02 , fontsize = fs )\n",
    "\n",
    "    plt.savefig( out_dir + '/' + station + \"_datasets_distribution_global.pdf\",\n",
    "                bbox_inches = 'tight' , dpi = 250 )    \n",
    "    plt.show()\n",
    "    plt.close()    \n",
    "        \n",
    "              \n",
    "    \"\"\" Global standard level counts (only available for observations_table ) \"\"\"\n",
    "    #std_plevs = [10, 20, 30, 50, 70, 100, 150, 200, 250, 300, 400, 500, 700, 850, 925, 1000]    \n",
    "    std_plevs = Common.std_plevs\n",
    "    \n",
    "    standard_lev_data  = data.loc[ (data['z_coordinate'] == 10   ) |  \n",
    "                                   (data['z_coordinate'] == 20   ) |\n",
    "                                   (data['z_coordinate'] == 30   ) |\n",
    "                                   (data['z_coordinate'] == 50   ) |\n",
    "                                   (data['z_coordinate'] == 70   ) |\n",
    "                                   (data['z_coordinate'] == 100  ) |\n",
    "                                   (data['z_coordinate'] == 150  ) |\n",
    "                                   (data['z_coordinate'] == 200  ) |\n",
    "                                   (data['z_coordinate'] == 250  ) |\n",
    "                                   (data['z_coordinate'] == 300  ) |\n",
    "                                   (data['z_coordinate'] == 400  ) |\n",
    "                                   (data['z_coordinate'] == 500  ) |\n",
    "                                   (data['z_coordinate'] == 700  ) |\n",
    "                                   (data['z_coordinate'] == 850  ) |\n",
    "                                   (data['z_coordinate'] == 925  ) |\n",
    "                                   (data['z_coordinate'] == 1000 )   ] \n",
    "    \n",
    "    print(\"Printing ::: Global standard level counts (only available for observations_table ) \")\n",
    "    a = plot_bar(data= standard_lev_data , station = station, text = text )\n",
    "    plt.title('Data counts per data source for Station ' + str(station) + ' ' + text , y=1.02 , fontsize = fs )\n",
    "\n",
    "    plt.ylabel(\"Counts (standard pressure levels)\", fontsize = fs )\n",
    "    plt.savefig(out_dir + '/'  + station + \"_data_datasets_distribution_standard\" + text_save + \".pdf\", bbox_inches = 'tight' , dpi = 250 )      \n",
    "    plt.show()\n",
    "\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "    \"\"\" Per-variable dataset distributions (all pressure levels) \"\"\"\n",
    "    print(\"Plotting ::: Per-variable dataset distributions (all pressure levels)\")\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=3, constrained_layout=True , figsize=(18,10) )\n",
    "    fig.suptitle('Data counts per variable and data source for Station ' + str(station) + ' ' + text , y=1.04 , fontsize = fs+3)\n",
    "\n",
    "    for ax,v in zip(axs.flat, variables):\n",
    "        ax.set_ylabel(\"Counts (all records) - \" + style_dic[v]['l'] , fontsize = fs )\n",
    "        data_v = data.loc[ (data['observed_variable'] == v) ]\n",
    "        plot_bar(data= data_v , ax = ax , rotation = True , station = station, text = text )\n",
    "\n",
    "    plt.savefig(out_dir + '/'  + station + \"_data_datasets_distribution_perVariable\" + text_save + \".pdf\", bbox_inches = 'tight' , dpi = 250 )   \n",
    "    plt.show()\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do = plot_dataset_hist(data= ot ,  variables= variables , station= station , date_range= ['',''] , text = station_name , text_save = '' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_headers(data= '', station = '', date_min='', date_max='', text = '' , text_save='' , recordtimestamp_false = '' ):\n",
    "        \n",
    "    \"\"\" Extracts some information from the header table \"\"\"\n",
    "    timestamps = data[\"record_timestamp\"]\n",
    "    #duplicates = data[\"duplicate\"]\n",
    "    sources = data[\"source_id\"]\n",
    "        \n",
    "    datasets_dic = Common.datasets_dic\n",
    "    style_dic    = Common.style_dic\n",
    "    fs = Common.fontsize\n",
    "    \n",
    "    def get_datasets_datetime(ts, report):\n",
    "        results = {}\n",
    "        for datetime, dataset in zip(timestamps, sources):\n",
    "            #print(datetime, ' ' , dataset )\n",
    "            try:\n",
    "                datetime = np.datetime64(datetime)\n",
    "            except:\n",
    "                print(datetime)\n",
    "            if dataset not in results.keys():\n",
    "                results[dataset] = []\n",
    "            try:\n",
    "                results[dataset].append(dictionary_dates[datetime] )\n",
    "            except:\n",
    "                if type(datetime) != np.datetime64:\n",
    "    \n",
    "                    results[dataset].append(dictionary_dates[datetime] )\n",
    "                else:\n",
    "                    results[dataset].append(datetime)\n",
    "\n",
    "        return results\n",
    "    \n",
    "    results = get_datasets_datetime(timestamps, sources)\n",
    "\n",
    "    def plot_timeshifts_distribution(timestamps):\n",
    "        \n",
    "        diff = []\n",
    "        for dt,dtp in zip(timestamps, timestamps[1:]):\n",
    "            try:\n",
    "                d = (dtp - dt) / 3600.\n",
    "                if d > 6:\n",
    "                    continue\n",
    "                diff.append(d)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    \n",
    "        fig, ax = plt.subplots(figsize=(12,10) ) #    fig, axs = plt.subplots(nrows=2, ncols=3, constrained_layout=True , figsize=(15,10) )\n",
    "\n",
    "        nbins = 24\n",
    "        plt.hist(diff, nbins, histtype='bar', color = 'magenta')\n",
    "        plt.xlim(0, 6)\n",
    "        ax.grid(ls =\":\" , color = \"lightgray\")\n",
    "\n",
    "        plt.xticks( fontsize = fs  )\n",
    "        plt.ylabel(\"Record Counts\", fontsize = fs )\n",
    "        plt.xlabel(\"Time interval [bin = 1/4 hour]\", fontsize = fs )\n",
    "\n",
    "\n",
    "        plt.savefig(out_dir + '/'  + station + \"_timeshifts_distribution_\" + text_save + \".png\", bbox_inches = 'tight' , dpi = 250 )     \n",
    "\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "    def plot_dataset_range(results, date_min='', date_max='' , text= '', station='' , text_save='' ):\n",
    "        \"\"\" Make a plot for the range of date time availabe for each dataset \"\"\"\n",
    "        num_sources = len(results.keys() )\n",
    "    \n",
    "        if date_min:\n",
    "            fig, ax = plt.subplots(figsize=(20,6) ) #    fig, axs = plt.subplots(nrows=2, ncols=3, constrained_layout=True , figsize=(15,10) )\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=(12,10) ) \n",
    "            \n",
    "        fig.suptitle(\"Time Interval per Data Source for Station \" + station + ' ' + text, y = 0.94, fontsize = fs )\n",
    "\n",
    "        ticks, labels = [], [] \n",
    "        for r,i in zip(results.keys() , range(num_sources)):\n",
    "            rs = r.decode('utf-8')\n",
    "            index = i+1\n",
    "            ticks.append(index)\n",
    "            label = Common.datasets_dic[rs]['l']\n",
    "            labels.append(label)\n",
    "            y = np.empty( len(results[r]) ) \n",
    "            y.fill(index)\n",
    "            plt.scatter(results[r] , y, color = datasets_dic[rs]['c'] , label = label )\n",
    "\n",
    "        ax.grid(ls =\":\" , color = \"lightgray\")\n",
    "\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.set_yticklabels(labels, fontsize = fs ,)\n",
    "        plt.xticks( rotation = 45, fontsize = fs  )\n",
    "        \n",
    "        text = ''\n",
    "        if date_min and date_max:\n",
    "            plt.xlim(date_min, date_max)\n",
    "            text = '_zoom_'\n",
    "            \n",
    "        \n",
    "        plt.savefig(out_dir + '/'  + station + \"_dataset_series_\" + text_save + \".png\", bbox_inches = 'tight' , dpi = 250 )     \n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def plot_bar( counts = '', labels = '', rotation = False , text = '' , station = '' , colors = ''):\n",
    "        \"\"\" Creates a simple bar plots \"\"\"\n",
    "\n",
    "        formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "        formatter.set_scientific(True) \n",
    "        formatter.set_powerlimits((-1,1)) \n",
    "        fig, ax = plt.subplots(figsize=(12,10) )\n",
    "        ax.yaxis.set_major_formatter(formatter) \n",
    "        ax.grid(ls =\":\" , color = \"lightgray\")\n",
    "        X = np.arange(len(counts))\n",
    "        ax.bar(X, counts, color = colors )\n",
    "        ax.set_xticks(X)\n",
    "        ax.set_xticklabels(labels, fontsize = fs )\n",
    "        if rotation:\n",
    "            ax.set_xticklabels(labels, rotation = 45, fontsize = fs )\n",
    "\n",
    "        plt.ylabel(\"Record Counts\", fontsize = fs )\n",
    "        plt.title('Record counts per data source for Station ' + str(station) + ' ' + text , y=1.02 , fontsize = fs )\n",
    "\n",
    "        plt.savefig(out_dir + '/'  + station + \"_recordcounts_datasets_distribution_global.pdf\",\n",
    "                bbox_inches = 'tight' , dpi = 250 )    \n",
    "        plt.show()\n",
    "        plt.close()  \n",
    "    \n",
    "\n",
    "    def plot_dataset_distribution(results, date_min='', date_max='', station='', text='' , text_save = 'zoom' ):\n",
    "        \"\"\" Make a histogram for the distribution of date time availabe for each dataset \"\"\"\n",
    "        num_sources = len(results.keys() )\n",
    "    \n",
    "\n",
    "            \n",
    "        \"\"\" Creating the list for the stacked histogram \"\"\"\n",
    "        ticks, labels, X, colors, counts = [], [], [], [], [] \n",
    "        Min, Max = [], [] \n",
    "        for r, dt in results.items() :\n",
    "            rs = r.decode('utf-8')\n",
    "            label = datasets_dic[rs]['l'] + \"[\" + str(len(dt)) + \"]\"\n",
    "            counts.append(len(dt))\n",
    "            \n",
    "            labels.append(label)\n",
    "            colors.append(datasets_dic[rs]['c'] )\n",
    "            X.append(dt)\n",
    "            Min.append(min(dt))\n",
    "            Max.append(max(dt))\n",
    "            \n",
    "     \n",
    "        a = plot_bar( counts = counts, labels = labels, rotation = False , text = '' , station = station , colors = colors)     \n",
    "\n",
    "        \n",
    "        if date_min:\n",
    "            fig, ax = plt.subplots(figsize=(20,6) ) #    fig, axs = plt.subplots(nrows=2, ncols=3, constrained_layout=True , figsize=(15,10) )\n",
    "        else:\n",
    "            fig, ax = plt.subplots(figsize=(15,10) ) \n",
    "            \n",
    "        \"\"\" Extracting hte min and Max years in the range. Needs panda to deal with numpy datetime64 objects\"\"\"\n",
    "        mm = np.array ( [min(Min)] , dtype = np.datetime64 )\n",
    "        y_min = str(pd.to_datetime(mm).year[0])\n",
    "        MM = np.array ( [max(Max)] , dtype = np.datetime64 )\n",
    "        y_max = str(pd.to_datetime(MM).year[0])\n",
    "        \n",
    "        #print(\"min, Max\" , y_min[0], y_max[0] )\n",
    "        \n",
    "        nbins = int(y_max) - int(y_min)\n",
    "        plt.hist(X, nbins, histtype='bar', stacked=True, label=labels, color = colors )\n",
    "    \n",
    "        ax.grid(ls =\":\" , color = \"lightgray\")\n",
    "\n",
    "\n",
    "        plt.xticks(rotation = 45 , fontsize = fs  )\n",
    "        plt.yticks(fontsize = fs  )\n",
    "\n",
    "        \n",
    "        if date_min and date_max:\n",
    "            plt.xlim(date_min, date_max)\n",
    "    \n",
    "        plt.ylim(0,4600)\n",
    "        plt.ylabel(\"Record counts \" , fontsize = fs)\n",
    "        plt.legend(fontsize = fs  , loc = 'best' )\n",
    "        plt.title(\"Records Distribution for station \" + station + ' ' + text , y = 1.03, fontsize = fs  )\n",
    "        plt.savefig(out_dir + '/'  + station + \"_record_distribution_\" + text_save + \".png\", bbox_inches = 'tight' , dpi = 250 )     \n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    p = plot_dataset_range(results , station=station , text = text)\n",
    "    p = plot_timeshifts_distribution(recordtimestamp_false )\n",
    "    p = plot_dataset_range(results, date_min= date_min, date_max= date_max , station=station , text = text , text_save = 'zoom' )\n",
    "    p = plot_dataset_distribution(results, date_min='', date_max='',  station=station , text = text )\n",
    "    \n",
    "    p = plot_dataset_distribution(results, date_min=datetime.datetime(1990,1,1,0,0), \n",
    "                                  date_max=datetime.datetime(2000,1,1,0,0),  station=station , text = text )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Common' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-aedc76720efb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdm\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mDM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2015\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2015\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mht\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstation_name\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mtext_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mrecordtimestamp_false\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecordtimestamp_false\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-1223b7a6c272>\u001b[0m in \u001b[0;36manalyze_headers\u001b[0;34m(data, station, date_min, date_max, text, text_save, recordtimestamp_false)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"source_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdatasets_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets_dic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mstyle_dic\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mCommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle_dic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Common' is not defined"
     ]
    }
   ],
   "source": [
    "dm , DM = datetime.datetime(2015,5,16,0,0) , datetime.datetime(2015,5,18,0,0)\n",
    "do = analyze_headers(data= ht, station = station, date_min = dm, date_max = DM, text= station_name , text_save = '' , recordtimestamp_false = recordtimestamp_false )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
