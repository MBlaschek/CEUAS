{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76a119a6-4239-4b13-8d0d-30fb2cb2faed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "import h5py as h5\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly as plotly\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import json\n",
    "\n",
    "import urllib.request\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "781a4df6-80bf-4120-a8f8-6046e72caf4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IgraMetaData():\n",
    "    \"\"\" Class holfing the basic functionality to produce extract IGRA2 metadata information \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        \"\"\" Convert the IGRA2 metadata from plain txt into a dataframe,\n",
    "        for the select station WMO id \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        IGRAID         1- 11   Character\n",
    "        WMOID         13- 17   Integer\n",
    "        NAME          19- 48   Character\n",
    "        NAMFLAG       50- 50   Character\n",
    "        LATITUDE      52- 60   Real\n",
    "        LATFLAG       62- 62   Character\n",
    "        LONGITUDE     64- 72   Real\n",
    "        LONFLAG       74- 74   Character\n",
    "        ELEVATION     76- 81   Real\n",
    "        ELVFLAG       83- 83   Character\n",
    "        YEAR          85- 88   Integer\n",
    "        MONTH         90- 91   Integer\n",
    "        DAY           93- 94   Integer\n",
    "        HOUR          96- 97   Integer\n",
    "        DATEIND       99- 99   Integer\n",
    "        EVENT        101-119   Character\n",
    "        ALTIND       121-122   Character\n",
    "        BEFINFO      124-163   Character\n",
    "        BEFFLAG      164-164   Character\n",
    "        LINK         166-167   Character\n",
    "        AFTINFO      169-208   Character\n",
    "        AFTFLAG      209-209   Character\n",
    "        REFERENCE    211-235   Character\n",
    "        COMMENT      236-315   Character\n",
    "        UPDCOM       316-346   Character\n",
    "        UPDDATE      348-354   Character\n",
    "        \"\"\"\n",
    "        \n",
    "        # obtain the metadata file \n",
    "        if not os.path.isdir('data/igra2-metadata.txt'):\n",
    "            url = 'https://www.ncei.noaa.gov/pub/data/igra/history/igra2-metadata.txt'\n",
    "            urllib.request.urlretrieve(url, 'data/igra2-metadata.txt')\n",
    "\n",
    "\n",
    "        names = ['IGRAID', 'WMOID', \"NAME\", \"NAMFLAG\" , \"LATITUDE\", \"LATFLAG\" , \"LONGITUDE\", \"LONFLAG\", \"ELEVATION\", \"ELVFLAG\", \"YEAR\",\n",
    "                   \"MONTH\", \"DAY\", \"HOUR\",\"DATEIND\",\"EVENT\",\"ALTIND\",\"BEFINFO\",\"BEFFLAG\",\"LINK\",\"AFTINFO\",\"AFTFLAG\",\"REFERENCE\",\"COMMENT\",\"UPDCOM\",\"UPDATE\"] \n",
    "\n",
    "        colspecs = [(0,11),(12,17),(18,48),(49,50),(50,60),(61,62),(63,72),(73,74),(75,81),(82,83),(84,88),\n",
    "                   (89,91),(92,94),(95,97),(98,99),(100,119),(120,122),(123,162),(163,164),(165,167),(168,207),(208,209),(210,234),(235,314),(315,346),(347,354)]\n",
    "\n",
    "\n",
    "        self.igra2_meta_df = pd.read_fwf('data/igra2-metadata.txt', \n",
    "                            colspecs=colspecs, names=names,\n",
    "                            ).astype(str)\n",
    "\n",
    "    def get_igra_metadata(self,station):\n",
    "        \"\"\" Extract the metadata from the igra df for the given station \"\"\" \n",
    "        df = self.igra2_meta_df\n",
    "        \n",
    "        # extracting all WMO ids\n",
    "        wmos = [i if len(i) == 5 else '0'+i for i in df.WMOID]\n",
    "\n",
    "        df['WMOID'] = wmos\n",
    "        wmoid = station.split('-')[-1]\n",
    "        stat = df.loc[df.WMOID == wmoid]\n",
    "\n",
    "        # Extracting and converting dates \n",
    "        month = [i if len(i) == 2 else '0'+i for i in stat.MONTH]\n",
    "        month = [m if int(m) <=12 else '01' for m in month]\n",
    "        stat[\"MONTH\"] = month\n",
    "        stat[\"DATE\"] = stat[\"YEAR\"].astype(str) + stat[\"MONTH\"].astype(str)\n",
    "        stat[\"DATE\"] = pd.to_datetime(stat['DATE'] , format='%Y%m' )\n",
    "\n",
    "        \n",
    "        # create a combined string with the most relevant information \n",
    "        update = stat[[ \"EVENT\",\"ALTIND\",\"BEFINFO\",\"BEFFLAG\",\"LINK\",\"AFTINFO\",\"AFTFLAG\" ]].agg(' , '.join, axis=1)\n",
    "\n",
    "        u = [ ','.join(  [ v for v in c.split(',') if 'nan' not in v ]) for c in update  ]\n",
    "        stat['UPDATE'] = u\n",
    "        stat = stat[ [\"DATE\", \"WMOID\", \"UPDATE\", \"REFERENCE\", \"COMMENT\"] ]  # complete data for the station\n",
    "        \n",
    "        \n",
    "        # cleaning the station dataframe\n",
    "        stat_igra2 = stat[[\"DATE\",\"UPDATE\"] ]\n",
    "        stat_igra2['value'] = 3\n",
    "        stat_igra2['date_time'] = stat_igra2['DATE']\n",
    "        stat_igra2['comment'] = stat_igra2['UPDATE']\n",
    "\n",
    "        stat_igra2['sensor_id'] = 'IGRA2 METADATA'\n",
    "        stat_igra2['source'] = 'IGRA2'\n",
    "\n",
    "        # Select only IGRA2 metadata relative to \"SONDE\" events \n",
    "\n",
    "        updates = list(stat_igra2.comment.values)\n",
    "        ind = [ updates.index(i) for i in updates if 'SONDE' in i ]\n",
    "        stat_igra2_sonde = stat_igra2.iloc[ind]\n",
    "\n",
    "        return stat, stat_igra2_sonde \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Sensor():\n",
    "    \"\"\" Hold mehtods to extract the sensor_configuration table \"\"\" \n",
    "    \n",
    "    def __init__(self):\n",
    "        # sensor configuration\n",
    "        sensor_conf = pd.read_csv(os.getcwd()+'/data/sensor_configuration_all.csv', sep='\\t',  index_col=0)\n",
    "\n",
    "        # add a converted column (to strings)\n",
    "        sensor_id_s = []\n",
    "        for s in sensor_conf.sensor_id.values:\n",
    "            try:\n",
    "                s = eval(s).decode('utf-8').replace(' ','')\n",
    "            except:\n",
    "                pass\n",
    "            s = str(s)\n",
    "            sensor_id_s.append(s)\n",
    "\n",
    "        sensor_conf['sensor_id'] = sensor_id_s\n",
    "        \n",
    "        self.sensor_conf = sensor_conf\n",
    "        \n",
    "        \n",
    "    def get_sensor_id_comments(self,sensor_id):\n",
    "        \"\"\" Extracts the metadata realtive to a given sensor id from the sensor_configuration table \"\"\"\n",
    "\n",
    "        sensor_conf = self.sensor_conf\n",
    "        s = sensor_id\n",
    "\n",
    "        if s == 'NA':\n",
    "            return 'NA'\n",
    "        # list placeholders\n",
    "\n",
    "        d = sensor_conf[sensor_conf['sensor_id'] == s ]\n",
    "        if d.empty:\n",
    "            s = s.replace('.0', '').replace('.', '')\n",
    "            if len(s) == 2 and int(s) != 80:\n",
    "                s = '1' + s\n",
    "            elif len(s) ==2 and int(s) == 80:\n",
    "                s = '80'\n",
    "            d = sensor_conf[sensor_conf['sensor_id'] == s ]\n",
    "\n",
    "        try:\n",
    "            com = d.comments.values[0]\n",
    "        except:\n",
    "            com = 'NA'        \n",
    "\n",
    "        try:\n",
    "            com = eval(com).decode('utf-8')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return com\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21b94bb4-bdfc-47b0-aea4-f3870f152d30",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Analyze():\n",
    "    \n",
    "    def __init__(self,Sensor, merged, station):\n",
    "        \n",
    "        self.station = station\n",
    "        self.Sensor = Sensor  # Sensor is a class \n",
    "        self.merged = merged\n",
    "    \n",
    "    def load_data(self):\n",
    "        \"\"\" Load the data if existing or tries to read it from merged files \"\"\"\n",
    "        station = self.station\n",
    "        \n",
    "        lista = [f for f in os.listdir('data/') if station in f ]\n",
    "        print('LISTA ::: ' , lista)\n",
    "        if not (len(lista)>0):\n",
    "            \n",
    "            print(\"Retrieving data from merged file\")\n",
    "            merged = self.merged\n",
    "            file = [f for f in os.listdir(merged) if station in f][0]\n",
    "\n",
    "            station = file.split('/')[-1].split('_')[0]\n",
    "            file = merged + '/' + file \n",
    "\n",
    "            f = h5.File(file, 'r')\n",
    "            ts = f['recordtimestamp'][:]\n",
    "            tsd = pd.to_datetime( ts, unit='s',  origin=pd.Timestamp('1900-01-01') )\n",
    "\n",
    "            #index_minus = np.where(tsd <=  pd.Timestamp('1994-01-01')  )[0][-1]\n",
    "            index_minus = 0   # change to start from a certain date onwards \n",
    "\n",
    "            #index_plus = np.where(tsd >  pd.Timestamp('1997-01-01')  )[0][0]\n",
    "            index_plus = np.where(tsd <  pd.Timestamp('2013-01-01')  )[0][-1]\n",
    "\n",
    "\n",
    "            ### Extracting Schroeder \n",
    "            ind_obs_sch = list(f['recordindex'][:]) [index_minus:index_plus]\n",
    "            i = np.take( f['observations_table']['sensor_id'][:].view('|S4') , ind_obs_sch) \n",
    "            ids_s = [s.decode('utf-8').replace('.0','').replace('.','') for s in i ]\n",
    "            dic = {'date_time': tsd[index_minus:index_plus] , 'sensor_id': ids_s }\n",
    "\n",
    "            data_sch = pd.DataFrame(dic)\n",
    "            data_sch['value'] = 1\n",
    "\n",
    "            ### Extracting WMO\n",
    "            ind_obs_wmo     = list(f['recordindex'][:]) [index_plus+1:]\n",
    "            ind_obs_wmo_all = list(f['recordindex'][:]) # taking all WMOs\n",
    "\n",
    "\n",
    "            wmoids = np.take(  f['observations_table']['sensor_id'][:].view('|S4') , ind_obs_wmo)\n",
    "            wmoids = [s.decode('utf-8') for s in wmoids ]\n",
    "\n",
    "            dic_wmo = {'date_time':tsd[index_plus+1:] , 'sensor_id':wmoids }\n",
    "            data_wmo = pd.DataFrame (dic_wmo)\n",
    "            data_wmo['value'] = 2\n",
    "\n",
    "            data_wmo.to_csv('data/' + station + '_wmo.csv' , sep = '\\t') \n",
    "            data_sch.to_csv('data/' + station + '_sch.csv' , sep = '\\t') \n",
    "\n",
    "            f.close()\n",
    "\n",
    "        else:\n",
    "            print(\"Loading existing data\")\n",
    "            \n",
    "            data_wmo = pd.read_csv( 'data/' + [f for f in lista if 'wmo' in f][0] , sep = '\\t')\n",
    "            data_wmo['date_time'] = pd.to_datetime(data_wmo['date_time'] )\n",
    "\n",
    "            data_sch = pd.read_csv('data/' + [f for f in lista if 'sch' in f][0]  , sep = '\\t') \n",
    "            data_sch['date_time'] = pd.to_datetime(data_sch['date_time'] )\n",
    "        \n",
    "    \n",
    "        data_wmo['source'] = 'WMO'\n",
    "        data_sch['source'] = 'SCH'\n",
    "    \n",
    "        self.data_sch = data_sch\n",
    "        self.data_wmo = data_wmo \n",
    "        \n",
    "        \n",
    "    def get_indices(self, data):\n",
    "        \"\"\"         # find the indices where the sensor was replaced \n",
    "        i.e. spots the change in the sensor ina  time series \"\"\"\n",
    "\n",
    "        data = data.reset_index()\n",
    "        indices = []\n",
    "        last = ''\n",
    "        for index, row in data.iterrows():\n",
    "            sid = row.sensor_id\n",
    "            #if sid =='nan':\n",
    "            #    continue\n",
    "            #print(index)\n",
    "            if index ==0:\n",
    "                indices.append(index)\n",
    "                last = sid\n",
    "            else:\n",
    "                if sid == last:\n",
    "                    continue\n",
    "                else:\n",
    "                    last = sid\n",
    "                    indices.append(index)\n",
    "        return indices\n",
    " \n",
    "\n",
    "    def clean_df(self, df):\n",
    "        \"\"\" Clean the WMO dataframe from all nans \"\"\"\n",
    "        \n",
    "    \n",
    "        # cleaning WMO data from nans \n",
    "        data_wmo_clean = df.loc[ (self.data_wmo.sensor_id != 'nan') & (self.data_wmo.sensor_id != '-922')].dropna( subset=['sensor_id'])\n",
    "        data_wmo_clean.reset_index()\n",
    "\n",
    "        #print(data_wmo_clean[data_wmo_clean.date_time >=  pd.Timestamp('1994-11-02') ][:20])\n",
    "\n",
    "        indices_wmo_clean = self.get_indices(data_wmo_clean)\n",
    "        #print(indices_wmo_clean)\n",
    "\n",
    "        data_wmo_clean = data_wmo_clean.iloc[indices_wmo_clean]\n",
    "\n",
    "        return data_wmo_clean\n",
    "    \n",
    "    \n",
    "    \n",
    "    def analyze(self):\n",
    "        \"\"\" Extract ifnormation from the station file dataframe \"\"\"\n",
    "        \n",
    "        self.load_data()\n",
    "        \n",
    "        data_wmo = self.data_wmo\n",
    "        data_sch = self.data_sch\n",
    "        \n",
    "        data_wmo_clean = self.clean_df(data_wmo)\n",
    "            \n",
    "            \n",
    "        # getting only variation in the sensor_id indices \n",
    "        indices_sch = self.get_indices(data_sch)\n",
    "        indices_wmo = self.get_indices(data_wmo)\n",
    "        indices_wmo_clean = self.get_indices(data_wmo_clean)\n",
    "\n",
    "        # all data, no cleaning \n",
    "        data_df = pd.concat( [data_sch.iloc[ list(indices_sch)], data_wmo. iloc[ list(indices_wmo)] ] ) \n",
    "                    \n",
    "        comments = [ str( self.Sensor.get_sensor_id_comments(str(i).replace(' ','').replace('.0',''))) for i in data_df.sensor_id]\n",
    "\n",
    "        data_df['comment'] = comments\n",
    "        sid_clean = [str(i).replace('.0','')  for i in data_df.sensor_id]\n",
    "        data_df['sensor_id'] = sid_clean    \n",
    "\n",
    "        \n",
    "        # only cleaned WMO data \n",
    "        data_df_clean = pd.concat( [data_sch.iloc[ list(indices_sch)], data_wmo_clean. iloc[ list(indices_wmo_clean)] ] ) \n",
    "        comments = [ str( self.Sensor.get_sensor_id_comments(str(i).replace(' ','').replace('.0',''))) for i in data_df_clean.sensor_id]\n",
    "\n",
    "        data_df_clean['comment'] = comments\n",
    "        sid_clean = [str(i).replace('.0','')  for i in data_df_clean.sensor_id]\n",
    "        data_df_clean['sensor_id'] = sid_clean   \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        return data_sch, data_wmo, data_df, data_wmo_clean, data_df_clean \n",
    "\n",
    "    \n",
    "\n",
    "    def get_all_sensors(self, df):\n",
    "        \"\"\" Extract a small table with unqiue sensors and description \"\"\"\n",
    "        \n",
    "        igra2 = df.loc[df['source'] == 'IGRA2']\n",
    "        \n",
    "        rest = df.loc[df['source'] != 'IGRA2']\n",
    "        sensors,ind = np.unique( rest.sensor_id, return_index= True)\n",
    "        df_sensor = rest.iloc[list(ind)] [['sensor_id', 'source', 'comment']]\n",
    "        \n",
    "        df_sensor = pd.concat([df_sensor, igra2])\n",
    "        return df_sensor\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85400706-2bbe-4ba6-a855-d1bb742a3e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Plot():\n",
    "    \"\"\" Main class to hold plotting utilities \"\"\"\n",
    "    \n",
    "    def __init__(self,station, save=False):\n",
    "        if not os.path.isdir('plots'):\n",
    "            os.mkdir('plots')\n",
    "            \n",
    "            \n",
    "        self.station=station\n",
    "        self.save = save\n",
    "        \n",
    "    def time_series(self, data_df, label = ''):\n",
    "        \"\"\" Creates a time series using also SNHT \"\"\"\n",
    "        #filter date\n",
    "        #data_df = data_df.loc[data_df.date_time <= pd.Timestamp('1995-01-01')]\n",
    "\n",
    "        station = self.station.split('-')[-1] if '-' in self.station else self.station \n",
    "        try:\n",
    "            with open('/mnt/users/staff/leo/python/CEUAS/CEUAS/public/adjust/feedbackmerged0' + station + '_breakanalysis.json') as f:\n",
    "                d=json.load(f)\n",
    "                time = pd.to_datetime(d['days_since_1900'] , unit='d', origin=pd.Timestamp('1900-01-01') )\n",
    "                snht = pd.DataFrame( {'time': [data_df.date_time[0], data_df.date_time[1] ] , 'snht':d['tsasum'] } )\n",
    "\n",
    "        except:\n",
    "            snht = pd.DataFrame( {'time': [pd.Timestamp('1995-01-01'),pd.Timestamp('1995-01-02')] , 'snht':[0,0] } )\n",
    "\n",
    "        symbols = {\"IGRA2\":'star', \"WMO\":'circle', \"SCH\":'square'}\n",
    "\n",
    "        # Create figure with secondary y-axis\n",
    "        subfig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "        fig1 = px.line(snht, x=\"time\", y=\"snht\")\n",
    "        fig2 = px.scatter(data_df, x=\"date_time\", y=\"value\", color=\"sensor_id\",\n",
    "                        hover_name=\"sensor_id\", hover_data=[\"comment\"],\n",
    "                        symbol=\"source\",\n",
    "                        symbol_map= symbols )\n",
    "\n",
    "        fig2.update_traces(yaxis=\"y2\")\n",
    "\n",
    "        subfig.add_traces(fig1.data + fig2.data)\n",
    "        subfig.layout.xaxis.title=\"\"\n",
    "        subfig.layout.yaxis.title=\"SNHT\"\n",
    "        subfig.layout.yaxis2.title=\"Metadata Source\"\n",
    "        \n",
    "\n",
    "        subfig.for_each_trace(lambda t: t.update(line=dict(color=t.marker.color)))\n",
    "\n",
    "        subfig.update_layout(title='Sensors Time Series - ' + self.station + ' ' + label)\n",
    "        subfig.update_layout(width= 2000, height = 800)\n",
    "\n",
    "\n",
    "        subfig.update_traces(marker=dict(size=14,\n",
    "                                      line=dict(width=2,\n",
    "                                                color='DarkSlateGrey')),\n",
    "                          selector=dict(mode='markers'))\n",
    "\n",
    "\n",
    "\n",
    "        igra2 = data_df.loc[data_df.source == 'IGRA2']\n",
    "        for d in igra2.date_time:\n",
    "            subfig.add_vline(x=d, line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "\n",
    "\n",
    "\n",
    "        subfig.update_layout(hovermode=\"x unified\")\n",
    "\n",
    "        subfig.update_layout(\n",
    "        yaxis = dict(\n",
    "        tickfont = dict(size=16)),\n",
    "        font=dict(\n",
    "            size=16,\n",
    "            color=\"black\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        subfig.update_yaxes( ticktext= ['Schroeder', 'WMO', 'IGRA2'],\n",
    "                          tickvals= [1,2,3], secondary_y=True )\n",
    "\n",
    "        \n",
    "        \n",
    "        if self.save:\n",
    "            plotly.offline.plot(subfig, filename=  'plots/' + self.station + \"_time_series.html\" )\n",
    "            pio.write_image(subfig, \"plots/\" + self.station + \"_timeSeries_ku.png\")\n",
    "            \n",
    "\n",
    "        return subfig\n",
    "\n",
    "    def sensor_table(self, data):\n",
    "        \n",
    "        print(data)\n",
    "        fig = go.Figure(data=[go.Table(\n",
    "        header=dict(values=list(['Sensor','Source', 'Comment']),\n",
    "                    fill_color='gold',\n",
    "                    align='left',\n",
    "                    font_size=20),\n",
    "        columnwidth = [40,40,300],\n",
    "        cells=dict(values=[data.sensor_id, data.source, data.comment],\n",
    "                   fill_color='aliceblue',\n",
    "                   align='left',\n",
    "                   font_size=16,\n",
    "                   height=30\n",
    "                  )),\n",
    "        ])\n",
    "\n",
    "        fig.update_layout(width=1900, height= 65*len(data))\n",
    "\n",
    "        if self.save:\n",
    "            plotly.offline.plot(fig, filename=  'plots/' + self.station + \"_sensor_table.html\" )\n",
    "            pio.write_image(fig, \"plots/\" + self.station + \"_sensor_table.png\")\n",
    "\n",
    "        return fig\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "086050be-2e18-49ca-bd95-5459bedb1372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "def run_wrapper(merged, save, station):\n",
    "    \"\"\" Wrapper to full run of a station file \"\"\"\n",
    "\n",
    "    #station_name = 'Vienna'\n",
    "\n",
    "    # IGRA2 \n",
    "    ig = IgraMetaData()\n",
    "    igra2_metadata = ig.igra2_meta_df\n",
    "    stat_igra2, stat_igra2_sonde = ig.get_igra_metadata(station)\n",
    "\n",
    "    # sensor configuration\n",
    "    sensor = Sensor()\n",
    "    \n",
    "    # Analyze data\n",
    "    print(\" --- ANALYZING --- data file: \")\n",
    "    analyze = Analyze(sensor,merged,station)\n",
    "    data_sch, data_wmo, data_df, data_wmo_clean, data_df_clean = analyze.analyze()\n",
    "\n",
    "    data_df_clean_all = pd.concat([data_df_clean, stat_igra2_sonde])\n",
    "    data_df = pd.concat([data_df, stat_igra2])\n",
    "\n",
    "    # extract unique sensor id table for the station\n",
    "    all_sensor_station_df = analyze.get_all_sensors(data_df_clean_all)\n",
    "\n",
    "    # Plotting\n",
    "    # Analyze data\n",
    "\n",
    "    plot = Plot(station.split('_')[-1], save=False)\n",
    "\n",
    "    series = plot.time_series( data_df_clean_all, label='')\n",
    "    table = plot.sensor_table( all_sensor_station_df)\n",
    "\n",
    "    print(data_df_clean)\n",
    "    return series, table\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79762dd-25de-4f31-bb3e-827885308392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "722fc84c-1414-4604-8965-404e5c3aa014",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-226e159f95ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/scratch/das/federico/MERGED_APRIL2022'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'70414'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "merged = '/scratch/das/federico/MERGED_APRIL2022'\n",
    "    \n",
    "stations = [s.split('_')[0].split('-')[-1] for s in os.listdir(merged) ]\n",
    "\n",
    "stations = ['70414']\n",
    "stations = ['71403']\n",
    "\n",
    "for stat in stations:\n",
    "    s,t = run_wrapper(merged, False, stat)  ### to debug\n",
    "        \n",
    "    \"\"\"\n",
    "    try:\n",
    "        s,t = run_wrapper(merged, False, stat)\n",
    "    except:\n",
    "        print('Failed +++ ' , stat )\n",
    "        pass\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8941fae6-f1be-4c1d-b86b-fe1a09c03f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa5c856-a854-4562-b6e6-504d685f2a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37127fe-5669-4337-aa43-9e76cbfaa8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
