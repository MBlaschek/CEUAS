{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cds_eua3' has no attribute 'logging_set_level'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-76119e47b3dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mharvest_convert_to_netCDF\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrite_dict_h5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcds_eua3\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0meua\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0meua\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_set_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cds_eua3' has no attribute 'logging_set_level'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "import sys,glob\n",
    "import zipfile, os, time\n",
    "import urllib3\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "import h5py\n",
    "sys.path.append(os.getcwd()+'/../cds-backend/code/')\n",
    "sys.path.append(os.getcwd()+'/../harvest/code/')\n",
    "from harvest_convert_to_netCDF import write_dict_h5\n",
    "import cds_eua3 as eua\n",
    "#eua.logging_set_level(30) # FIX\n",
    "import xarray as xr\n",
    "\n",
    "import cdsapi, zipfile, os, time\n",
    "#import schedule\n",
    "import copy\n",
    "from shutil import copyfile\n",
    "import multiprocessing\n",
    "sys.path.append(os.getcwd()+'/rasotools-master/')\n",
    "import rasotools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    34\thumidity\tatmospheric\tsurface; upper-air\tdew point depression\tK\tDew point depression is also called dew point deficit. It is the amount by which the air temperature exceeds its dew point temperature. Dew point temperature is the temperature at which a parcel of air reaches saturation upon being cooled at constant pressure and specific humidity.\n",
    "\n",
    "    36\thumidity\tatmospheric\tsurface; upper-air\tdew point temperature\tK\tDew point temperature is the temperature at which a parcel of air reaches saturation upon being cooled at constant pressure and specific humidity.\n",
    "\n",
    "    38\thumidity\tatmospheric\tsurface; upper-air\trelative humidity\tpercent\tTBD\n",
    "\n",
    "    39\thumidity\tatmospheric\tsurface; upper-air\tspecific humidity\tg kg-1\tspecific means per unit mass. Specific humidity is the mass fraction of water vapor in (moist) air.\n",
    "\n",
    "\n",
    "\n",
    "    104\twind\tatmospheric\tsurface; upper-air\teastward wind speed\tm s-1\tEastward indicates a vector component which is positive when directed eastward (negative westward). Wind is defined as a two-dimensional (horizontal) air velocity vector,  with no vertical component. (Vertical motion in the atmosphere has the standard name upward air velocity.)\n",
    "\n",
    "    105\twind\tatmospheric\tsurface; upper-air\tnorthward wind speed\tm s-1\tNorthward indicates a vector component which is positive when directed northward (negative southward). Wind is defined as a two-dimensional (horizontal) air velocity vector,  with no vertical component. (Vertical motion in the atmosphere has the standard name upward air velocity.)\n",
    "\n",
    "    106\twind\tatmospheric\tsurface; upper-air\twind from direction\tdegree\tdirection from which the wind is blowing Lot 1 uses dd  - WMO abbrev.\n",
    "\n",
    "    107\twind\tatmospheric\tsurface; upper-air\twind speed\tm s-1\tSpeed is the magnitude of velocity. Wind is defined as a two-dimensional (horizontal) air velocity vector,  with no vertical component. (Vertical motion in the atmosphere has the standard name upward air velocity.) The wind speed is the magnitude of the wind velocity. Lot 1 uses ff  - WMO abbrev.\n",
    "\n",
    "    137\thumidity\tatmospheric\tsurface; upper air\tair dewpoint\tK\tDewpoint measurement (from profile measurement)\n",
    "\n",
    "    138\thumidity\tatmospheric\tsurface; upper air\trelative humidity\t1\tRelative humidity (from profile measurement)\n",
    "\n",
    "    139\twind\tatmospheric\tsurface; upper air\teastward wind speed\tm s-1\tEastward wind speed (from profile measurement)\n",
    "\n",
    "    140\twind\tatmospheric\tsurface; upper air\tnorthward wind speed\tm s-1\tNorthward wind speed (from profile measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/raid60/scratch/uli/resorted_files_correct/*.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_missing(file, checkvars: list = [85, 38, 106, 107], convert: bool = False):\n",
    "    missing = []\n",
    "    with eua.CDMDataset(file) as data:\n",
    "        for i in checkvars:\n",
    "            if not str(i) in data.recordindices.keys():\n",
    "                missing.append(i)\n",
    "        if not convert:\n",
    "            return missing\n",
    "        else: \n",
    "            convert_missing(file, missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_missing_or_short(file, checkvars: list = [34, 36, 38, 39, 104, 105, 106, 107], convert: bool = False):\n",
    "    missing = []\n",
    "    cleanedvars = checkvars.copy()\n",
    "    with eua.CDMDataset(file) as data:\n",
    "        lenlist = []\n",
    "        for i in checkvars:\n",
    "            try:\n",
    "                lenlist.append(len(data.recordindices[str(i)])) # if not readable - variable is missing\n",
    "            except:\n",
    "                missing.append(i)\n",
    "                print(cleanedvars, i)\n",
    "                cleanedvars.remove(i)\n",
    "        if len(lenlist) != 0:\n",
    "            lenmax = max(lenlist)\n",
    "            for i in range(len(cleanedvars)):\n",
    "                if lenlist[i] < lenmax: # if one of the variables is shorter than the others\n",
    "                    missing.append(cleanedvars[i])\n",
    "        if not convert:\n",
    "            return missing\n",
    "        else: \n",
    "            convert_missing(file, missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# einfach dazu schreiben und dann neu sortieren? wäre eine option\n",
    "# schreiben, era5fb und recordinidce anpassen\n",
    "# flags setzten - siehe rückgabe convert\n",
    "# vermerken, wenn etwas nicht passt - siehe rückgabe convert\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "def convert_missing(file, missing, destination: str = './converted/'):\n",
    "    towrite = []\n",
    "    with eua.CDMDataset(file) as data:\n",
    "        convertible = ['104', '105', '106', '107', '34', '36', '38', '39']\n",
    "        missingrecids = []\n",
    "        for i in convertible:\n",
    "            if not i in data.recordindices.keys():\n",
    "                missingrecids.append(i)\n",
    "        print('loading data')\n",
    "#         df = data.to_dataframe(groups='observations_table', variables=['observed_variable', 'observation_value', 'z_coordinate', 'report_id'])\n",
    "        keys = data.observations_table.keys()\n",
    "        keys = [x for x in keys if not x.startswith('string')]\n",
    "        keys.remove('index')\n",
    "        keys.remove('shape')\n",
    "        df = data.to_dataframe(groups='observations_table', variables=keys)\n",
    "\n",
    "        print('loading complete')\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    if 38 in missing: # rh is missing -> calculate it from \n",
    "        print('converting to 38')\n",
    "        hums = [34, 36, 39]\n",
    "        missing_hum_vars = check_for_missing(file, checkvars = hums)\n",
    "        for i in missing_hum_vars: hums.remove(i)\n",
    "        print(hums)\n",
    "        rhall = []\n",
    "        if 34 in hums: # dew point depression\n",
    "            print('with 34')\n",
    "            t = df[df.observed_variable == 85]\n",
    "            hum = df[df.observed_variable == 34]\n",
    "            \n",
    "            cleaned_t = t[0:0]\n",
    "            cleaned_hum = hum[0:0]\n",
    "            for i in hum.report_id.drop_duplicates():\n",
    "                inter_t = t[t.report_id == i]\n",
    "                inter_hum = hum[hum.report_id == i]\n",
    "                cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "                cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "        \n",
    "            t = cleaned_t.observation_value.to_xarray()\n",
    "            dpd = cleaned_hum.observation_value.to_xarray()\n",
    "            \n",
    "            rh = rasotools.met.convert.to_rh(t, dpd=dpd)\n",
    "            out = cleaned_t.copy()\n",
    "            out['observed_variable'] =  38 \n",
    "            out['observation_value'] =  rh\n",
    "            rhall.append(out)\n",
    "            #add\n",
    "            #set conversion flag\n",
    "        if 36 in hums: # dew point\n",
    "            print('with 36')\n",
    "            t = df[df.observed_variable == 85]\n",
    "            hum = df[df.observed_variable == 36]\n",
    "\n",
    "            cleaned_t = t[0:0]\n",
    "            cleaned_hum = hum[0:0]\n",
    "            for i in hum.report_id.drop_duplicates():\n",
    "                inter_t = t[t.report_id == i]\n",
    "                inter_hum = hum[hum.report_id == i]\n",
    "                cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "                cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "            dpd = cleaned_t.observation_value.subtract(np.asarray(cleaned_hum.observation_value))\n",
    "            t = cleaned_t.observation_value.to_xarray()\n",
    "            dpd = dpd.to_xarray()\n",
    "\n",
    "            rh = rasotools.met.convert.to_rh(t,dpd=dpd)  \n",
    "            out = cleaned_t.copy()\n",
    "            out['observed_variable'] =  38 \n",
    "            out['observation_value'] =  rh\n",
    "            rhall.append(out)\n",
    "            #add\n",
    "            #set conversion flag\n",
    "        if 39 in hums: # specific humidity\n",
    "            print('with 39')\n",
    "            t = df[df.observed_variable == 85]\n",
    "            hum = df[df.observed_variable == 39]\n",
    "\n",
    "            cleaned_t = t[0:0]\n",
    "            cleaned_hum = hum[0:0]\n",
    "            for i in hum.report_id.drop_duplicates():\n",
    "                inter_t = t[t.report_id == i]\n",
    "                inter_hum = hum[hum.report_id == i]\n",
    "                cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "                cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "            p = cleaned_t.z_coordinate.to_xarray()\n",
    "            t = cleaned_t.observation_value.to_xarray()\n",
    "            sh = cleaned_hum.observation_value.to_xarray()\n",
    "\n",
    "            rh = rasotools.met.convert.to_rh(temp=t, spec_humi=sh, press=p)\n",
    "            out = cleaned_t.copy()\n",
    "            out['observed_variable'] =  38 \n",
    "            out['observation_value'] =  rh\n",
    "            rhall.append(out)\n",
    "\n",
    "            #add\n",
    "            #set conversion flag\n",
    "        else:\n",
    "            print('-')\n",
    "            print('NO HUMIDITY VARIABLE AVAILABLE - COULD NOT CONVERT')\n",
    "            print('-')\n",
    "            \n",
    "        comb = rhall[0][0:0]\n",
    "        for i in range(len(rhall)):\n",
    "            comb = comb.append(rhall[i], ignore_index=True)\n",
    "        comb = df[df.observed_variable == 38].append(comb)\n",
    "        # drop_duplicates with keep='first' -> values, which were already available stay the same\n",
    "        comb = comb.drop_duplicates(('report_id', 'z_coordinate'))\n",
    "        towrite.append(comb)   \n",
    "        \n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    if 34 in missing: # dew point depression is missing -> calculate it from\n",
    "        print('converting to 34')\n",
    "        hums = [38, 36, 39]\n",
    "        missing_hum_vars = check_for_missing(file, checkvars = hums)\n",
    "        for i in missing_hum_vars: hums.remove(i)\n",
    "        print(hums)\n",
    "        dpdall = []\n",
    "        if 38 in hums and not 85 in missing: # relative humidity\n",
    "            print('with 38')\n",
    "            t = df[df.observed_variable == 85]\n",
    "            hum = df[df.observed_variable == 38]\n",
    "\n",
    "            cleaned_t = t[0:0]\n",
    "            cleaned_hum = hum[0:0]\n",
    "            for i in hum.report_id.drop_duplicates():\n",
    "                inter_t = t[t.report_id == i]\n",
    "                inter_hum = hum[hum.report_id == i]\n",
    "                cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "                cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "            t = cleaned_t.observation_value.to_xarray()\n",
    "            p = cleaned_t.z_coordinate.to_xarray()\n",
    "            rh = cleaned_hum.observation_value.to_xarray()\n",
    "\n",
    "            dpd = rasotools.met.convert.to_dpd(temp=t,press=p,rel_humi=rh)\n",
    "            out = cleaned_t.copy()\n",
    "            out['observed_variable'] =  34\n",
    "            out['observation_value'] =  dpd\n",
    "            dpdall.append(out)\n",
    "            #add\n",
    "            #set conversion flag\n",
    "        if 36 in hums: # dew point\n",
    "            print('with 36')\n",
    "            t = df[df.observed_variable == 85]\n",
    "            hum = df[df.observed_variable == 36]\n",
    "\n",
    "            cleaned_t = t[0:0]\n",
    "            cleaned_hum = hum[0:0]\n",
    "            for i in hum.report_id.drop_duplicates():\n",
    "                inter_t = t[t.report_id == i]\n",
    "                inter_hum = hum[hum.report_id == i]\n",
    "                cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "                cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "\n",
    "            dpd = cleaned_t.observation_value.subtract(np.asarray(cleaned_hum.observation_value))\n",
    "            dpd = dpd.to_xarray()\n",
    "            out = cleaned_t.copy()\n",
    "            out['observed_variable'] =  34\n",
    "            out['observation_value'] =  dpd\n",
    "            dpdall.append(out)\n",
    "            #add\n",
    "            #set conversion flag\n",
    "        if 39 in hums: # specific humidity\n",
    "            print('with 39')\n",
    "            t = df[df.observed_variable == 85]\n",
    "            hum = df[df.observed_variable == 39]\n",
    "\n",
    "            cleaned_t = t[0:0]\n",
    "            cleaned_hum = hum[0:0]\n",
    "            for i in hum.report_id.drop_duplicates():\n",
    "                inter_t = t[t.report_id == i]\n",
    "                inter_hum = hum[hum.report_id == i]\n",
    "                cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "                cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "                \n",
    "            p = cleaned_t.z_coordinate.to_xarray()\n",
    "            t = cleaned_t.observation_value.to_xarray()\n",
    "            sh = cleaned_hum.observation_value.to_xarray()\n",
    "            print(p.values)\n",
    "\n",
    "            dpd = rasotools.met.convert.to_dpd(spec_humi=sh,press=p,temp=t)\n",
    "            out = cleaned_t.copy()\n",
    "            out['observed_variable'] =  34\n",
    "            out['observation_value'] =  dpd\n",
    "            dpdall.append(out)\n",
    "            #add\n",
    "            #set conversion flag\n",
    "        else:\n",
    "            print('-')\n",
    "            print('NO HUMIDITY VARIABLE AVAILABLE - COULD NOT CONVERT')\n",
    "            print('-')\n",
    "        comb = dpdall[0][0:0]\n",
    "        for i in range(len(dpdall)):\n",
    "            comb = comb.append(dpdall[i], ignore_index=True)\n",
    "        comb = comb.drop_duplicates(('report_id', 'z_coordinate'))\n",
    "        towrite.append(comb)\n",
    "            \n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    if 36 in missing: # dew point is missing -> calculate it from\n",
    "        print('converting to 36')\n",
    "        hums = [34, 38, 39]\n",
    "        missing_hum_vars = check_for_missing(file, checkvars = hums)\n",
    "        for i in missing_hum_vars: hums.remove(i)\n",
    "        print(hums)\n",
    "        dpall = []\n",
    "        if 38 in hums and not 85 in missing: # relative humidity\n",
    "            print('with 38')\n",
    "            t = df[df.observed_variable == 85]\n",
    "            hum = df[df.observed_variable == 38]\n",
    "\n",
    "            cleaned_t = t[0:0]\n",
    "            cleaned_hum = hum[0:0]\n",
    "            for i in hum.report_id.drop_duplicates():\n",
    "                inter_t = t[t.report_id == i]\n",
    "                inter_hum = hum[hum.report_id == i]\n",
    "                cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "                cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "            t = cleaned_t.observation_value.to_xarray()\n",
    "            p = cleaned_t.z_coordinate.to_xarray()\n",
    "            rh = cleaned_hum.observation_value.to_xarray()\n",
    "\n",
    "            dp = rasotools.met.convert.to_dewpoint(temp=t,press=p,rel_humi=rh)\n",
    "            out = cleaned_t.copy()\n",
    "            out['observed_variable'] =  36\n",
    "            out['observation_value'] =  dp\n",
    "            dpall.append(out)\n",
    "            #add\n",
    "            #set conversion flag\n",
    "        if 34 in hums: # dew point depression\n",
    "            print('with 34')\n",
    "            t = df[df.observed_variable == 85]\n",
    "            hum = df[df.observed_variable == 34]\n",
    "\n",
    "            cleaned_t = t[0:0]\n",
    "            cleaned_hum = hum[0:0]\n",
    "            for i in hum.report_id.drop_duplicates():\n",
    "                inter_t = t[t.report_id == i]\n",
    "                inter_hum = hum[hum.report_id == i]\n",
    "                cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "                cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "            dp = cleaned_t.observation_value.subtract(np.asarray(cleaned_hum.observation_value))\n",
    "            dp = dp.to_xarray()\n",
    "            out = cleaned_t.copy()\n",
    "            out['observed_variable'] =  36\n",
    "            out['observation_value'] =  dp\n",
    "            dpall.append(out)\n",
    "            #add\n",
    "            #set conversion flag\n",
    "        if 39 in hums: # specific humidity\n",
    "            print('with 39')\n",
    "            t = df[df.observed_variable == 85]\n",
    "            hum = df[df.observed_variable == 39]\n",
    "\n",
    "            cleaned_t = t[0:0]\n",
    "            cleaned_hum = hum[0:0]\n",
    "            for i in hum.report_id.drop_duplicates():\n",
    "                inter_t = t[t.report_id == i]\n",
    "                inter_hum = hum[hum.report_id == i]\n",
    "                cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "                cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "            p = cleaned_t.z_coordinate.to_xarray()\n",
    "            sh = cleaned_hum.observation_value.to_xarray()\n",
    "            dp = rasotools.met.convert.to_dewpoint(spec_humi=sh,press=p)\n",
    "            out = cleaned_t.copy()\n",
    "            out['observed_variable'] =  36\n",
    "            out['observation_value'] =  dp\n",
    "            dpall.append(out)\n",
    "            #add\n",
    "            #set conversion flag\n",
    "        else:\n",
    "            print('-')\n",
    "            print('NO HUMIDITY VARIABLE AVAILABLE - COULD NOT CONVERT')\n",
    "            print('-')\n",
    "        comb = dpall[0][0:0]\n",
    "        for i in range(len(dpall)):\n",
    "            comb = comb.append(dpall[i], ignore_index=True)\n",
    "        comb = comb.drop_duplicates(('report_id', 'z_coordinate'))\n",
    "        towrite.append(comb)\n",
    "            \n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    if 39 in missing: # specific humidity is missing -> calculate it from\n",
    "        print('converting to 39')\n",
    "        hums = [34, 38, 36]\n",
    "        missing_hum_vars = check_for_missing(file, checkvars = hums)\n",
    "        for i in missing_hum_vars: hums.remove(i)\n",
    "        print(hums)\n",
    "        shall = []\n",
    "        if 38 in hums and not 85 in missing: # relative humidity\n",
    "            print('with 38')\n",
    "            t = df[df.observed_variable == 85]\n",
    "            hum = df[df.observed_variable == 38]\n",
    "\n",
    "            cleaned_t = t[0:0]\n",
    "            cleaned_hum = hum[0:0]\n",
    "            for i in hum.report_id.drop_duplicates():\n",
    "                inter_t = t[t.report_id == i]\n",
    "                inter_hum = hum[hum.report_id == i]\n",
    "                cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "                cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "            t = cleaned_t.observation_value.to_xarray()\n",
    "            p = cleaned_t.z_coordinate.to_xarray()\n",
    "            rh = cleaned_hum.observation_value.to_xarray()\n",
    "\n",
    "            sh = rasotools.met.convert.to_sh(temp=t, press=p, rel_humi=rh)\n",
    "            out = cleaned_t.copy()\n",
    "            out['observed_variable'] =  39\n",
    "            out['observation_value'] =  sh\n",
    "            shall.append(out)\n",
    "            #add\n",
    "            #set conversion flag\n",
    "        if 34 in hums: # dew point depression\n",
    "            print('with 34')\n",
    "            t = df[df.observed_variable == 85]\n",
    "            hum = df[df.observed_variable == 34]\n",
    "\n",
    "            cleaned_t = t[0:0]\n",
    "            cleaned_hum = hum[0:0]\n",
    "            for i in hum.report_id.drop_duplicates():\n",
    "                inter_t = t[t.report_id == i]\n",
    "                inter_hum = hum[hum.report_id == i]\n",
    "                cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "                cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "            t = cleaned_t.observation_value.to_xarray()\n",
    "            p = cleaned_t.z_coordinate.to_xarray()\n",
    "            dpd = cleaned_hum.observation_value.to_xarray()\n",
    "\n",
    "            sh = rasotools.met.convert.to_sh(dpd=dpd, press=p, temp=t)\n",
    "            out = cleaned_t.copy()\n",
    "            out['observed_variable'] =  39\n",
    "            out['observation_value'] =  sh\n",
    "            shall.append(out)\n",
    "            #add\n",
    "            #set conversion flag\n",
    "        if 36 in hums: # dew point\n",
    "            print('with 36')\n",
    "            t = df[df.observed_variable == 85]\n",
    "            hum = df[df.observed_variable == 36]\n",
    "\n",
    "            cleaned_t = t[0:0]\n",
    "            cleaned_hum = hum[0:0]\n",
    "            for i in hum.report_id.drop_duplicates():\n",
    "                inter_t = t[t.report_id == i]\n",
    "                inter_hum = hum[hum.report_id == i]\n",
    "                cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "                cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "            dpd = cleaned_t.observation_value.subtract(np.asarray(cleaned_hum.observation_value))\n",
    "\n",
    "            t = cleaned_t.observation_value.to_xarray()\n",
    "            p = cleaned_t.z_coordinate.to_xarray()\n",
    "            dpd = dpd.to_xarray()\n",
    "            sh = rasotools.met.convert.to_sh(dpd=dpd, press=p, temp=t)\n",
    "            out = cleaned_t.copy()\n",
    "            out['observed_variable'] =  39\n",
    "            out['observation_value'] =  sh\n",
    "            shall.append(out)\n",
    "            #add\n",
    "            #set conversion flag\n",
    "        else:\n",
    "            print('-')\n",
    "            print('NO HUMIDITY VARIABLE AVAILABLE - COULD NOT CONVERT')\n",
    "            print('-')\n",
    "        comb = shall[0][0:0]\n",
    "        for i in range(len(shall)):\n",
    "            comb = comb.append(shall[i], ignore_index=True)\n",
    "        comb = comb.drop_duplicates(('report_id', 'z_coordinate'))\n",
    "        towrite.append(comb)\n",
    "    \n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    if 104 in missing or 105 in missing: # u and/or v is missing -> calculate it from wd and ws\n",
    "        wd = df[df.observed_variable == 106]\n",
    "        ws = df[df.observed_variable == 107]\n",
    "        \n",
    "        if(len(wd) != len(ws)):\n",
    "            print('not of equal length')\n",
    "            cleaned_wd = wd[0:0]\n",
    "            cleaned_ws = ws[0:0]\n",
    "            for i in ws.report_id.drop_duplicates():\n",
    "                inter_wd = wd[wd.report_id == i]\n",
    "                inter_ws = ws[ws.report_id == i]\n",
    "                cleaned_wd = cleaned_wd.append(inter_wd[inter_wd.z_coordinate.isin(inter_ws.z_coordinate)])\n",
    "                cleaned_ws = cleaned_ws.append(inter_ws[inter_ws.z_coordinate.isin(inter_wd.z_coordinate)])\n",
    "            print('equal length - start processing')\n",
    "            wd = np.asarray(cleaned_wd.observation_value)\n",
    "            ws = np.asarray(cleaned_ws.observation_value)\n",
    "            out_u = cleaned_wd.copy()\n",
    "            out_v = cleaned_wd.copy()\n",
    "\n",
    "        else:\n",
    "            print('equal length - start processing')\n",
    "            out_u = wd.copy()\n",
    "            out_v = wd.copy()\n",
    "            wd = np.asarray(wd.observation_value)\n",
    "            ws = np.asarray(ws.observation_value)\n",
    "\n",
    "\n",
    "        u = ws * np.cos(np.radians(wd))\n",
    "        v = ws * np.sin(np.radians(wd))\n",
    "        out_u['observed_variable'] =  104 \n",
    "        out_u['observation_value'] =  u\n",
    "        out_v['observed_variable'] =  105 \n",
    "        out_v['observation_value'] =  v\n",
    "        comb = df[df.observed_variable == 104].append(out_u)\n",
    "        # drop_duplicates with keep='first' -> values, which were already available stay the same\n",
    "        comb = comb.drop_duplicates(('report_id', 'z_coordinate'))\n",
    "        towrite.append(comb)\n",
    "        comb = df[df.observed_variable == 105].append(out_v)\n",
    "        # drop_duplicates with keep='first' -> values, which were already available stay the same\n",
    "        comb = comb.drop_duplicates(('report_id', 'z_coordinate'))\n",
    "        towrite.append(comb)\n",
    "        #add\n",
    "        #set conversion flag\n",
    "        \n",
    "    if 106 in missing or 107 in missing: # wd and/or ws is missing -> calculate it from u/v\n",
    "        u = df[df.observed_variable == 104]\n",
    "        v = df[df.observed_variable == 105]\n",
    "        \n",
    "        if(len(u) != len(v)):\n",
    "            print('not of equal length')\n",
    "            cleaned_u = u[0:0]\n",
    "            cleaned_v = v[0:0]\n",
    "            for i in v.report_id.drop_duplicates():\n",
    "                inter_u = u[u.report_id == i]\n",
    "                inter_v = v[v.report_id == i]\n",
    "                cleaned_u = cleaned_u.append(inter_u[inter_u.z_coordinate.isin(inter_v.z_coordinate)])\n",
    "                cleaned_v = cleaned_v.append(inter_v[inter_v.z_coordinate.isin(inter_u.z_coordinate)]) \n",
    "            print('equal length - start processing')\n",
    "            u = np.asarray(cleaned_u.observation_value)\n",
    "            v = np.asarray(cleaned_v.observation_value)\n",
    "            out_wd = cleaned_u.copy()\n",
    "            out_ws = cleaned_u.copy()\n",
    "        else:\n",
    "            print('equal length - start processing')\n",
    "            out_wd = u.copy()\n",
    "            out_ws = u.copy()\n",
    "            u = np.asarray(u.observation_value)\n",
    "            v = np.asarray(v.observation_value)\n",
    "\n",
    "        ws = np.sqrt(u ** 2 + v ** 2)\n",
    "        wd = 90 - np.arctan2(-v, -u) * 180 / np.pi - 180.\n",
    "        wd = np.where(wd > 0., wd, 360.+wd)\n",
    "        \n",
    "        out_wd['observed_variable'] =  106 \n",
    "        out_wd['observation_value'] =  wd\n",
    "        out_ws['observed_variable'] =  107 \n",
    "        out_ws['observation_value'] =  ws\n",
    "        comb = df[df.observed_variable == 106].append(out_wd)\n",
    "        # drop_duplicates with keep='first' -> values, which were already available stay the same\n",
    "        comb = comb.drop_duplicates(('report_id', 'z_coordinate'))\n",
    "        towrite.append(comb)\n",
    "        comb = df[df.observed_variable == 107].append(out_ws)\n",
    "        # drop_duplicates with keep='first' -> values, which were already available stay the same\n",
    "        comb = comb.drop_duplicates(('report_id', 'z_coordinate'))\n",
    "        towrite.append(comb)\n",
    "        #add\n",
    "        #set conversion flag\n",
    "        \n",
    "# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "   \n",
    "    return towrite\n",
    "#     print('creating new file')\n",
    "#     targetfile = destination + file.split('/')[-1]\n",
    "#     with h5py.File(file, 'r') as origin:\n",
    "#         with h5py.File(targetfile, 'w') as newfile:\n",
    "#             groups = []\n",
    "#             for i in origin.keys():\n",
    "#                 if type(origin[i]) == h5py._hl.group.Group:\n",
    "#                     newfile.create_group(i)\n",
    "#                     groups.append(i)\n",
    "#                 else:\n",
    "#                     newfile.create_dataset(i, data=origin[i][:])\n",
    "#             for i in groups:\n",
    "#                 if(i == 'recordindices' or i == 'observations_table' or i == 'era5fb'):\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     for j in origin[i].keys():\n",
    "#                         newfile[i].create_dataset(j, data=origin[i][j][:])\n",
    "                        \n",
    "#     print('writing converted data to file')\n",
    "#     with h5py.File(file, 'r') as origin:\n",
    "#         obs = []\n",
    "#         for o in towrite:\n",
    "#             if o.observed_variable.iloc[0] in missingrecids:\n",
    "#                 # writing observations_table\n",
    "#                 for i in o.keys():\n",
    "#                     testvar = pandas.DataFrame({i:origin.observations_table[i][:].append(o[i])}) # puts it right on the end, and not in a numericaly sorted way\n",
    "#                     write_dict_h5(targetfile, testvar, 'observations_table', {i: { 'compression': 'gzip' } }, [i])\n",
    "                    \n",
    "#                 # writing recordindices\n",
    "#                 # o.observed_variable.iloc[0] is the new recordindex - the number not already in the group\n",
    "#                 # has to be fitting for recordtimestamp too, \n",
    "#                 # iterate over recordtimestamp and check for the frist index, where it occures in the data, if not, select the last/next? one\n",
    "                \n",
    "                \n",
    "#                 np.where(v[:-1] != v[1:])[0]\n",
    "#                 testvar = pandas.DataFrame({str(o.observed_variable.iloc[0]):recordindices[i]})\n",
    "#                 write_dict_h5(targetfile, testvar, 'recordindices', {str(o.observed_variable.iloc[0]): { 'compression': 'gzip' } }, [str(o.observed_variable.iloc[0])])\n",
    "                \n",
    "                \n",
    "#                 # writing era5fb\n",
    "\n",
    "#             else:\n",
    "                \n",
    "\n",
    "#         for i in origin.era5fb.keys():\n",
    "            \n",
    "#         for i in origin.recordindices.keys():\n",
    "#             testvar = pandas.DataFrame({str(allvars[i]):recordindices[i]})\n",
    "#             write_dict_h5(targetfile, testvar, 'recordindices', {str(allvars[i]): { 'compression': 'gzip' } }, [str(allvars[i])])\n",
    "#         origin \n",
    "#     with h5py.File(targetfile, 'w') as newfile:\n",
    "#         for i in origin['observations_table'].keys():\n",
    "#             if(i == 'recordindices' or i == 'observations_table' or i == 'era5fb'):\n",
    "#                 pass\n",
    "#             else:\n",
    "#                 for j in origin[i].keys():\n",
    "#                     newfile[i].create_dataset(j, data=origin[i][j][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "loading complete\n",
      "converting to 38\n",
      "[36, 39]\n",
      "with 36\n",
      "with 39\n",
      "Time elapsed:  11.041162967681885 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "out = convert_missing('/raid60/scratch/uli/resorted_files_correct/0-20000-0-11019_CEUAS_merged_v0.nc', missing=[38])\n",
    "print(\"Time elapsed: \", time.time()-t0, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjustment_id</th>\n",
       "      <th>advanced_assimilation_feedback</th>\n",
       "      <th>advanced_homogenisation</th>\n",
       "      <th>advanced_qc</th>\n",
       "      <th>advanced_uncertainty</th>\n",
       "      <th>bbox_max_latitude</th>\n",
       "      <th>bbox_max_longitude</th>\n",
       "      <th>bbox_min_latitude</th>\n",
       "      <th>bbox_min_longitude</th>\n",
       "      <th>code_table</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_automation_status</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>spatial_representativeness</th>\n",
       "      <th>traceability</th>\n",
       "      <th>units</th>\n",
       "      <th>value_significance</th>\n",
       "      <th>z_coordinate</th>\n",
       "      <th>z_coordinate_method</th>\n",
       "      <th>z_coordinate_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5124</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5125</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>70900.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5126</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>74600.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5128</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>79600.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10245</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>101100.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>5</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>5</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5124 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adjustment_id  advanced_assimilation_feedback  advanced_homogenisation  \\\n",
       "5124             NaN                               1              -2147483648   \n",
       "5125             NaN                               1              -2147483648   \n",
       "5126             NaN                               1              -2147483648   \n",
       "5127             NaN                               1              -2147483648   \n",
       "5128             NaN                               1              -2147483648   \n",
       "...              ...                             ...                      ...   \n",
       "10243            NaN                               1              -2147483648   \n",
       "10244            NaN                               1              -2147483648   \n",
       "10245            NaN                               1              -2147483648   \n",
       "4310             NaN                               1              -2147483648   \n",
       "4311             NaN                               1              -2147483648   \n",
       "\n",
       "       advanced_qc  advanced_uncertainty  bbox_max_latitude  \\\n",
       "5124   -2147483648           -2147483648                NaN   \n",
       "5125   -2147483648           -2147483648                NaN   \n",
       "5126   -2147483648           -2147483648                NaN   \n",
       "5127   -2147483648           -2147483648                NaN   \n",
       "5128   -2147483648           -2147483648                NaN   \n",
       "...            ...                   ...                ...   \n",
       "10243  -2147483648           -2147483648                NaN   \n",
       "10244  -2147483648           -2147483648                NaN   \n",
       "10245  -2147483648           -2147483648                NaN   \n",
       "4310   -2147483648           -2147483648                NaN   \n",
       "4311   -2147483648           -2147483648                NaN   \n",
       "\n",
       "       bbox_max_longitude  bbox_min_latitude  bbox_min_longitude  code_table  \\\n",
       "5124                  NaN                NaN                 NaN -2147483648   \n",
       "5125                  NaN                NaN                 NaN -2147483648   \n",
       "5126                  NaN                NaN                 NaN -2147483648   \n",
       "5127                  NaN                NaN                 NaN -2147483648   \n",
       "5128                  NaN                NaN                 NaN -2147483648   \n",
       "...                   ...                ...                 ...         ...   \n",
       "10243                 NaN                NaN                 NaN -2147483648   \n",
       "10244                 NaN                NaN                 NaN -2147483648   \n",
       "10245                 NaN                NaN                 NaN -2147483648   \n",
       "4310                  NaN                NaN                 NaN -2147483648   \n",
       "4311                  NaN                NaN                 NaN -2147483648   \n",
       "\n",
       "       ...  sensor_automation_status  sensor_id  source_id  \\\n",
       "5124   ...               -2147483648        NA      era5_2   \n",
       "5125   ...               -2147483648        NA      era5_2   \n",
       "5126   ...               -2147483648        NA      era5_2   \n",
       "5127   ...               -2147483648        NA      era5_2   \n",
       "5128   ...               -2147483648        NA      era5_2   \n",
       "...    ...                       ...        ...        ...   \n",
       "10243  ...               -2147483648        NA      era5_2   \n",
       "10244  ...               -2147483648        NA      era5_2   \n",
       "10245  ...               -2147483648        NA      era5_2   \n",
       "4310   ...               -2147483648        NA      era5_2   \n",
       "4311   ...               -2147483648        NA      era5_2   \n",
       "\n",
       "       spatial_representativeness traceability  units  value_significance  \\\n",
       "5124                  -2147483648  -2147483648      0         -2147483648   \n",
       "5125                  -2147483648  -2147483648      0         -2147483648   \n",
       "5126                  -2147483648  -2147483648      0         -2147483648   \n",
       "5127                  -2147483648  -2147483648      0         -2147483648   \n",
       "5128                  -2147483648  -2147483648      0         -2147483648   \n",
       "...                           ...          ...    ...                 ...   \n",
       "10243                 -2147483648  -2147483648      0         -2147483648   \n",
       "10244                 -2147483648  -2147483648      0         -2147483648   \n",
       "10245                 -2147483648  -2147483648      0         -2147483648   \n",
       "4310                  -2147483648  -2147483648      5         -2147483648   \n",
       "4311                  -2147483648  -2147483648      5         -2147483648   \n",
       "\n",
       "       z_coordinate  z_coordinate_method  z_coordinate_type  \n",
       "5124        70000.0          -2147483648                  1  \n",
       "5125        70900.0          -2147483648                  1  \n",
       "5126        74600.0          -2147483648                  1  \n",
       "5127        75000.0          -2147483648                  1  \n",
       "5128        79600.0          -2147483648                  1  \n",
       "...             ...                  ...                ...  \n",
       "10243       95000.0          -2147483648                  1  \n",
       "10244      100000.0          -2147483648                  1  \n",
       "10245      101100.0          -2147483648                  1  \n",
       "4310        80000.0          -2147483648                  1  \n",
       "4311        85000.0          -2147483648                  1  \n",
       "\n",
       "[5124 rows x 46 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5124     38\n",
       "5125     38\n",
       "5126     38\n",
       "5127     38\n",
       "5128     38\n",
       "         ..\n",
       "10243    38\n",
       "10244    38\n",
       "10245    38\n",
       "4310     38\n",
       "4311     38\n",
       "Name: observed_variable, Length: 5124, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].observed_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5124     0.152794\n",
       "5125     0.151932\n",
       "5126     0.141759\n",
       "5127     0.152478\n",
       "5128     0.152282\n",
       "           ...   \n",
       "10243    0.574890\n",
       "10244    0.484368\n",
       "10245    0.435136\n",
       "4310     0.234856\n",
       "4311     0.225538\n",
       "Name: observation_value, Length: 5124, dtype: float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].observation_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort it, so the recordindex will be correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjustment_id</th>\n",
       "      <th>advanced_assimilation_feedback</th>\n",
       "      <th>advanced_homogenisation</th>\n",
       "      <th>advanced_qc</th>\n",
       "      <th>advanced_uncertainty</th>\n",
       "      <th>bbox_max_latitude</th>\n",
       "      <th>bbox_max_longitude</th>\n",
       "      <th>bbox_min_latitude</th>\n",
       "      <th>bbox_min_longitude</th>\n",
       "      <th>code_table</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_automation_status</th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>spatial_representativeness</th>\n",
       "      <th>traceability</th>\n",
       "      <th>units</th>\n",
       "      <th>value_significance</th>\n",
       "      <th>z_coordinate</th>\n",
       "      <th>z_coordinate_method</th>\n",
       "      <th>z_coordinate_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5124</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5125</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>70900.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5126</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>74600.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5128</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>79600.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10241</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>89400.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10242</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10243</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10245</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>...</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>NA</td>\n",
       "      <td>era5_2</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>101100.0</td>\n",
       "      <td>-2147483648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5124 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       adjustment_id  advanced_assimilation_feedback  advanced_homogenisation  \\\n",
       "5124             NaN                               1              -2147483648   \n",
       "5125             NaN                               1              -2147483648   \n",
       "5126             NaN                               1              -2147483648   \n",
       "5127             NaN                               1              -2147483648   \n",
       "5128             NaN                               1              -2147483648   \n",
       "...              ...                             ...                      ...   \n",
       "10241            NaN                               1              -2147483648   \n",
       "10242            NaN                               1              -2147483648   \n",
       "10243            NaN                               1              -2147483648   \n",
       "10244            NaN                               1              -2147483648   \n",
       "10245            NaN                               1              -2147483648   \n",
       "\n",
       "       advanced_qc  advanced_uncertainty  bbox_max_latitude  \\\n",
       "5124   -2147483648           -2147483648                NaN   \n",
       "5125   -2147483648           -2147483648                NaN   \n",
       "5126   -2147483648           -2147483648                NaN   \n",
       "5127   -2147483648           -2147483648                NaN   \n",
       "5128   -2147483648           -2147483648                NaN   \n",
       "...            ...                   ...                ...   \n",
       "10241  -2147483648           -2147483648                NaN   \n",
       "10242  -2147483648           -2147483648                NaN   \n",
       "10243  -2147483648           -2147483648                NaN   \n",
       "10244  -2147483648           -2147483648                NaN   \n",
       "10245  -2147483648           -2147483648                NaN   \n",
       "\n",
       "       bbox_max_longitude  bbox_min_latitude  bbox_min_longitude  code_table  \\\n",
       "5124                  NaN                NaN                 NaN -2147483648   \n",
       "5125                  NaN                NaN                 NaN -2147483648   \n",
       "5126                  NaN                NaN                 NaN -2147483648   \n",
       "5127                  NaN                NaN                 NaN -2147483648   \n",
       "5128                  NaN                NaN                 NaN -2147483648   \n",
       "...                   ...                ...                 ...         ...   \n",
       "10241                 NaN                NaN                 NaN -2147483648   \n",
       "10242                 NaN                NaN                 NaN -2147483648   \n",
       "10243                 NaN                NaN                 NaN -2147483648   \n",
       "10244                 NaN                NaN                 NaN -2147483648   \n",
       "10245                 NaN                NaN                 NaN -2147483648   \n",
       "\n",
       "       ...  sensor_automation_status  sensor_id  source_id  \\\n",
       "5124   ...               -2147483648        NA      era5_2   \n",
       "5125   ...               -2147483648        NA      era5_2   \n",
       "5126   ...               -2147483648        NA      era5_2   \n",
       "5127   ...               -2147483648        NA      era5_2   \n",
       "5128   ...               -2147483648        NA      era5_2   \n",
       "...    ...                       ...        ...        ...   \n",
       "10241  ...               -2147483648        NA      era5_2   \n",
       "10242  ...               -2147483648        NA      era5_2   \n",
       "10243  ...               -2147483648        NA      era5_2   \n",
       "10244  ...               -2147483648        NA      era5_2   \n",
       "10245  ...               -2147483648        NA      era5_2   \n",
       "\n",
       "       spatial_representativeness traceability  units  value_significance  \\\n",
       "5124                  -2147483648  -2147483648      0         -2147483648   \n",
       "5125                  -2147483648  -2147483648      0         -2147483648   \n",
       "5126                  -2147483648  -2147483648      0         -2147483648   \n",
       "5127                  -2147483648  -2147483648      0         -2147483648   \n",
       "5128                  -2147483648  -2147483648      0         -2147483648   \n",
       "...                           ...          ...    ...                 ...   \n",
       "10241                 -2147483648  -2147483648      0         -2147483648   \n",
       "10242                 -2147483648  -2147483648      0         -2147483648   \n",
       "10243                 -2147483648  -2147483648      0         -2147483648   \n",
       "10244                 -2147483648  -2147483648      0         -2147483648   \n",
       "10245                 -2147483648  -2147483648      0         -2147483648   \n",
       "\n",
       "       z_coordinate  z_coordinate_method  z_coordinate_type  \n",
       "5124        70000.0          -2147483648                  1  \n",
       "5125        70900.0          -2147483648                  1  \n",
       "5126        74600.0          -2147483648                  1  \n",
       "5127        75000.0          -2147483648                  1  \n",
       "5128        79600.0          -2147483648                  1  \n",
       "...             ...                  ...                ...  \n",
       "10241       89400.0          -2147483648                  1  \n",
       "10242       90000.0          -2147483648                  1  \n",
       "10243       95000.0          -2147483648                  1  \n",
       "10244      100000.0          -2147483648                  1  \n",
       "10245      101100.0          -2147483648                  1  \n",
       "\n",
       "[5124 rows x 46 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].sort_values(by=['report_id','z_coordinate'], inplace=True)\n",
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5122\n",
      "[0.1527943  0.15193212 0.14175875 ... 0.5748903  0.48436815 0.43513632]\n"
     ]
    }
   ],
   "source": [
    "with eua.CDMDataset('/raid60/scratch/uli/resorted_files_correct/0-20000-0-11019_CEUAS_merged_v0.nc') as data:\n",
    "    rh = data.observations_table.observation_value[data.recordindices['38'][0]:data.recordindices['38'][-1]]\n",
    "    print(len(rh))\n",
    "    print(rh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'netCDF4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-bdc153df2aa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/jetfs/home/uvoggenberger/CEUAS/CEUAS/public/resort/converted/0-20000-0-11019_CEUAS_merged_v0.nc'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecordinidces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'netCDF4' is not defined"
     ]
    }
   ],
   "source": [
    "with netCDF4.Dataset('/jetfs/home/uvoggenberger/CEUAS/CEUAS/public/resort/converted/0-20000-0-11019_CEUAS_merged_v0.nc') as test:\n",
    "    print(test.recordinidces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['104', '105', '106', '107', '117', '136', '137', '138', '139', '140', '36', '38', '39', '85', 'index', 'recordtimestamp', 'shape']\n",
      "[   0   18   36   57   66   84   98  112  123  134  151  163  180  194\n",
      "  205  221  240  261  266  277  295  308  327  341  354  367  381  401\n",
      "  418  435  448  461  484  505  523  542  557  576  588  603  623  642\n",
      "  658  676  691  711  733  749  767  781  795  812  826  841  859  876\n",
      "  893  911  932  952  972  993 1010 1031 1050 1068 1075 1084 1097 1115\n",
      " 1125 1137 1151 1165 1176 1188 1198 1211 1228 1246 1266 1279 1294 1307\n",
      " 1330 1344 1364 1378 1396 1416 1440 1456 1474 1495 1513 1529 1547 1555\n",
      " 1573 1589 1600 1607 1615 1633 1647 1653 1669 1687 1709 1727 1745 1766\n",
      " 1772 1783 1796 1817 1833 1850 1867 1880 1895 1910 1933 1953 1972 1994\n",
      " 2014 2032 2050 2068 2083 2100 2114 2129 2144 2158 2174 2189 2209 2223\n",
      " 2237 2256 2275 2290 2308 2328 2344 2363 2378 2395 2410 2436 2451 2463\n",
      " 2478 2498 2514 2526 2542 2549 2563 2580 2597 2617 2635 2653 2670 2685\n",
      " 2702 2719 2733 2749 2763 2781 2795 2812 2831 2854 2869 2890 2911 2926\n",
      " 2939 2949 2963 2978 2996 3013 3027 3045 3059 3081 3094 3109 3129 3144\n",
      " 3157 3172 3191 3211 3229 3243 3264 3280 3298 3314 3332 3346 3360 3378\n",
      " 3399 3414 3427 3444 3459 3477 3492 3509 3522 3538 3552 3568 3585 3596\n",
      " 3605 3620 3640 3652 3667 3685 3702 3721 3738 3754 3774 3794 3814 3834\n",
      " 3854 3876 3899 3916 3933 3954 3972 3989 4003 4030 4056 4073 4094 4110\n",
      " 4127 4148 4167 4185 4204 4220 4238 4257 4273 4293 4306 4320 4335 4356\n",
      " 4377 4397 4413 4432 4446 4469 4484 4501 4520 4539 4552 4571 4582 4597\n",
      " 4608 4623 4637 4649 4663 4681 4704 4723 4739 4755 4772 4790 4805 4806\n",
      " 4819 4839 4857 4875 4892 4907 4927 4944 4957 4975 4992 5009 5027 5043\n",
      " 5055 5071 5089 5124]\n"
     ]
    }
   ],
   "source": [
    "with eua.CDMDataset('/raid60/scratch/uli/resorted_files_correct/0-20000-0-11019_CEUAS_merged_v0.nc') as data:\n",
    "    print(data.recordindices.keys())\n",
    "    print(data.recordindices['36'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "loading complete\n",
      "converting to 38\n",
      "[36, 39]\n",
      "with 36\n",
      "with 39\n",
      "Time elapsed:  5.298582077026367 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "out = convert_missing('/raid60/scratch/uli/resorted_files_correct/0-20000-0-11019_CEUAS_merged_v0.nc', missing=[38])\n",
    "print(\"Time elapsed: \", time.time()-t0, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85, 38, 106, 107] 85\n",
      "[38, 106, 107] 38\n",
      "[106, 107] 106\n",
      "[107] 107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[85, 38, 106, 107]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_for_missing('/raid60/scratch/uli/resorted_files_correct/0-20000-0-11019_CEUAS_merged_v0.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34, 38, 37, 36] 34\n",
      "[38, 37, 36] 38\n",
      "[37, 36] 37\n",
      "[36] 36\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "hums = [34, 38, 37, 36]\n",
    "missing_hum_vars = check_for_missing('/raid60/scratch/uli/resorted_files_correct/0-20000-0-11019_CEUAS_merged_v0.nc', checkvars = hums)\n",
    "for i in missing_hum_vars: hums.remove(i)\n",
    "print(hums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34, 38, 37, 36]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_hum_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed_variable</th>\n",
       "      <th>observation_value</th>\n",
       "      <th>date_time</th>\n",
       "      <th>z_coordinate</th>\n",
       "      <th>report_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20817</th>\n",
       "      <td>107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1972-10-31 15:00:00</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>20000000001</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20818</th>\n",
       "      <td>107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1972-10-31 15:00:00</td>\n",
       "      <td>79700.0</td>\n",
       "      <td>20000000001</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20819</th>\n",
       "      <td>107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1972-10-31 15:00:00</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>20000000001</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20820</th>\n",
       "      <td>107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1972-10-31 15:00:00</td>\n",
       "      <td>83500.0</td>\n",
       "      <td>20000000001</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20821</th>\n",
       "      <td>107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1972-10-31 15:00:00</td>\n",
       "      <td>84400.0</td>\n",
       "      <td>20000000001</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23985</th>\n",
       "      <td>107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>89400.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23986</th>\n",
       "      <td>107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23987</th>\n",
       "      <td>107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23988</th>\n",
       "      <td>107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23989</th>\n",
       "      <td>107</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>101100.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3173 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       observed_variable  observation_value           date_time  z_coordinate  \\\n",
       "20817                107                2.0 1972-10-31 15:00:00       75000.0   \n",
       "20818                107                2.0 1972-10-31 15:00:00       79700.0   \n",
       "20819                107                2.0 1972-10-31 15:00:00       80000.0   \n",
       "20820                107                2.0 1972-10-31 15:00:00       83500.0   \n",
       "20821                107                1.0 1972-10-31 15:00:00       84400.0   \n",
       "...                  ...                ...                 ...           ...   \n",
       "23985                107                2.0 1973-06-18 19:00:00       89400.0   \n",
       "23986                107                2.0 1973-06-18 19:00:00       90000.0   \n",
       "23987                107                2.0 1973-06-18 19:00:00       95000.0   \n",
       "23988                107                2.0 1973-06-18 19:00:00      100000.0   \n",
       "23989                107                3.0 1973-06-18 19:00:00      101100.0   \n",
       "\n",
       "         report_id   latitude  longitude  \n",
       "20817  20000000001  45.529999    -122.68  \n",
       "20818  20000000001  45.529999    -122.68  \n",
       "20819  20000000001  45.529999    -122.68  \n",
       "20820  20000000001  45.529999    -122.68  \n",
       "20821  20000000001  45.529999    -122.68  \n",
       "...            ...        ...        ...  \n",
       "23985  20000000311  45.529999    -122.68  \n",
       "23986  20000000311  45.529999    -122.68  \n",
       "23987  20000000311  45.529999    -122.68  \n",
       "23988  20000000311  45.529999    -122.68  \n",
       "23989  20000000311  45.529999    -122.68  \n",
       "\n",
       "[3173 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed_variable</th>\n",
       "      <th>observation_value</th>\n",
       "      <th>date_time</th>\n",
       "      <th>z_coordinate</th>\n",
       "      <th>report_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>0.153335</td>\n",
       "      <td>1972-10-30 14:00:00</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>0.152464</td>\n",
       "      <td>1972-10-30 14:00:00</td>\n",
       "      <td>70900.0</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>0.142243</td>\n",
       "      <td>1972-10-30 14:00:00</td>\n",
       "      <td>74600.0</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>0.152946</td>\n",
       "      <td>1972-10-30 14:00:00</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>0.152703</td>\n",
       "      <td>1972-10-30 14:00:00</td>\n",
       "      <td>79600.0</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5119</th>\n",
       "      <td>38</td>\n",
       "      <td>0.680769</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>89400.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>38</td>\n",
       "      <td>0.662534</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5121</th>\n",
       "      <td>38</td>\n",
       "      <td>0.574755</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5122</th>\n",
       "      <td>38</td>\n",
       "      <td>0.484200</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5123</th>\n",
       "      <td>38</td>\n",
       "      <td>0.434967</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>101100.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5124 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      observed_variable  observation_value           date_time  z_coordinate  \\\n",
       "0                    38           0.153335 1972-10-30 14:00:00       70000.0   \n",
       "1                    38           0.152464 1972-10-30 14:00:00       70900.0   \n",
       "2                    38           0.142243 1972-10-30 14:00:00       74600.0   \n",
       "3                    38           0.152946 1972-10-30 14:00:00       75000.0   \n",
       "4                    38           0.152703 1972-10-30 14:00:00       79600.0   \n",
       "...                 ...                ...                 ...           ...   \n",
       "5119                 38           0.680769 1973-06-18 19:00:00       89400.0   \n",
       "5120                 38           0.662534 1973-06-18 19:00:00       90000.0   \n",
       "5121                 38           0.574755 1973-06-18 19:00:00       95000.0   \n",
       "5122                 38           0.484200 1973-06-18 19:00:00      100000.0   \n",
       "5123                 38           0.434967 1973-06-18 19:00:00      101100.0   \n",
       "\n",
       "        report_id   latitude  longitude  \n",
       "0     20000000000  45.529999    -122.68  \n",
       "1     20000000000  45.529999    -122.68  \n",
       "2     20000000000  45.529999    -122.68  \n",
       "3     20000000000  45.529999    -122.68  \n",
       "4     20000000000  45.529999    -122.68  \n",
       "...           ...        ...        ...  \n",
       "5119  20000000311  45.529999    -122.68  \n",
       "5120  20000000311  45.529999    -122.68  \n",
       "5121  20000000311  45.529999    -122.68  \n",
       "5122  20000000311  45.529999    -122.68  \n",
       "5123  20000000311  45.529999    -122.68  \n",
       "\n",
       "[5124 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb = out[0].append(out[1], ignore_index=True)\n",
    "comb.drop_duplicates(('report_id', 'z_coordinate'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['brand', 'style'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5136\n",
      "observations_table:\n",
      "\n",
      "adjustment_id_____________________________________ : : (41144,)\n",
      "advanced_assimilation_feedback____________________ : : (41144,)\n",
      "advanced_homogenisation___________________________ : : (41144,)\n",
      "advanced_qc_______________________________________ : : (41144,)\n",
      "advanced_uncertainty______________________________ : : (41144,)\n",
      "bbox_max_latitude_________________________________ : : (41144,)\n",
      "bbox_max_longitude________________________________ : : (41144,)\n",
      "bbox_min_latitude_________________________________ : : (41144,)\n",
      "bbox_min_longitude________________________________ : : (41144,)\n",
      "code_table________________________________________ : : (41144,)\n",
      "conversion_flag___________________________________ : : (41144,)\n",
      "conversion_method_________________________________ : : (41144,)\n",
      "crs_______________________________________________ : : (41144,)\n",
      "data_policy_licence_______________________________ : : (41144,)\n",
      "date_time_________________________________________ : : (41144,)\n",
      "date_time_meaning_________________________________ : : (41144,)\n",
      "exposure_of_sensor________________________________ : : (41144,)\n",
      "index_____________________________________________ : : (41144,)\n",
      "latitude__________________________________________ : : (41144,)\n",
      "location_method___________________________________ : : (41144,)\n",
      "location_precision________________________________ : : (41144,)\n",
      "longitude_________________________________________ : : (41144,)\n",
      "numerical_precision_______________________________ : : (41144,)\n",
      "observation_duration______________________________ : : (41144,)\n",
      "observation_height_above_station_surface__________ : : (41144,)\n",
      "observation_id____________________________________ : : (41144, 11)\n",
      "observation_value_________________________________ : : (41144,)\n",
      "observed_variable_________________________________ : : (41144,)\n",
      "original_code_table_______________________________ : : (41144,)\n",
      "original_precision________________________________ : : (41144,)\n",
      "original_units____________________________________ : : (41144,)\n",
      "original_value____________________________________ : : (41144,)\n",
      "processing_level__________________________________ : : (41144,)\n",
      "quality_flag______________________________________ : : (41144,)\n",
      "report_id_________________________________________ : : (41144, 11)\n",
      "secondary_value___________________________________ : : (41144,)\n",
      "secondary_variable________________________________ : : (41144,)\n",
      "sensor_automation_status__________________________ : : (41144,)\n",
      "sensor_id_________________________________________ : : (41144, 3)\n",
      "source_id_________________________________________ : : (41144, 6)\n",
      "spatial_representativeness________________________ : : (41144,)\n",
      "string11__________________________________________ : : (11,)\n",
      "string3___________________________________________ : : (3,)\n",
      "string6___________________________________________ : : (6,)\n",
      "traceability______________________________________ : : (41144,)\n",
      "units_____________________________________________ : : (41144,)\n",
      "value_significance________________________________ : : (41144,)\n",
      "z_coordinate______________________________________ : : (41144,)\n",
      "z_coordinate_method_______________________________ : : (41144,)\n",
      "z_coordinate_type_________________________________ : : (41144,)\n"
     ]
    }
   ],
   "source": [
    "with eua.CDMDataset('/raid60/scratch/uli/resorted_files_correct/0-20000-0-11019_CEUAS_merged_v0.nc') as data:\n",
    "    print(data.recordindices['85'][-1]-1 - data.recordindices['85'][0])\n",
    "    print(data.observations_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5137\n",
      "5122\n",
      "3173\n",
      "3173\n",
      "       observed_variable  observation_value           date_time  z_coordinate  \\\n",
      "15680                 38           0.000783 1972-10-30 14:00:00       70000.0   \n",
      "15681                 38           0.000780 1972-10-30 14:00:00       70900.0   \n",
      "15682                 38           0.000755 1972-10-30 14:00:00       74600.0   \n",
      "15683                 38           0.000813 1972-10-30 14:00:00       75000.0   \n",
      "15684                 38           0.000822 1972-10-30 14:00:00       79600.0   \n",
      "...                  ...                ...                 ...           ...   \n",
      "20812                 38           0.004203 1973-06-18 19:00:00       89400.0   \n",
      "20813                 38           0.004236 1973-06-18 19:00:00       90000.0   \n",
      "20814                 38           0.004638 1973-06-18 19:00:00       95000.0   \n",
      "20815                 38           0.004835 1973-06-18 19:00:00      100000.0   \n",
      "20816                 38           0.004583 1973-06-18 19:00:00      101100.0   \n",
      "\n",
      "         report_id   latitude  longitude  \n",
      "15680  20000000000  45.529999    -122.68  \n",
      "15681  20000000000  45.529999    -122.68  \n",
      "15682  20000000000  45.529999    -122.68  \n",
      "15683  20000000000  45.529999    -122.68  \n",
      "15684  20000000000  45.529999    -122.68  \n",
      "...            ...        ...        ...  \n",
      "20812  20000000311  45.529999    -122.68  \n",
      "20813  20000000311  45.529999    -122.68  \n",
      "20814  20000000311  45.529999    -122.68  \n",
      "20815  20000000311  45.529999    -122.68  \n",
      "20816  20000000311  45.529999    -122.68  \n",
      "\n",
      "[5122 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "with eua.CDMDataset('/raid60/scratch/uli/resorted_files_correct/0-20000-0-11019_CEUAS_merged_v0.nc') as data:\n",
    "    df = data.to_dataframe(groups='observations_table', variables=['observed_variable', 'observation_value', 'date_time', 'z_coordinate', 'report_id', 'latitude', 'longitude'])\n",
    "    print(data.recordindices['85'][-1] - data.recordindices['85'][0])\n",
    "    print(data.recordindices['38'][-1] - data.recordindices['38'][0])\n",
    "    print(data.recordindices['104'][-1] - data.recordindices['104'][0])\n",
    "    print(data.recordindices['105'][-1] - data.recordindices['105'][0])\n",
    "    \n",
    "t = df[df.observed_variable == 85]\n",
    "hum = df[df.observed_variable == 38]\n",
    "\n",
    "cleaned_t = t[0:0]\n",
    "cleaned_hum = hum[0:0]\n",
    "for i in hum.report_id.drop_duplicates():\n",
    "    inter_t = t[t.report_id == i]\n",
    "    inter_hum = hum[hum.report_id == i]\n",
    "    cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "    cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "t = cleaned_t.observation_value.to_xarray()\n",
    "p = cleaned_t.z_coordinate.to_xarray()\n",
    "rh = cleaned_hum.observation_value.to_xarray()\n",
    "\n",
    "rh = rasotools.met.convert.to_sh(temp=t, press=p, rel_humi=rh)\n",
    "out = cleaned_t.copy()\n",
    "out['observed_variable'] =  38 \n",
    "out['observation_value'] =  rh\n",
    "print(out)\n",
    "#             out['observation_value'] = np.asarray(rh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with eua.CDMDataset('/raid60/scratch/uli/resorted_files_correct/0-20000-0-11035_CEUAS_merged_v0.nc') as data:\n",
    "    df = data.to_dataframe(groups='observations_table', variables=['observed_variable', 'observation_value', 'date_time', 'z_coordinate', 'report_id', 'latitude', 'longitude'])\n",
    "wind = df[df.observed_variable == 106]\n",
    "wind = wind.append(df[df.observed_variable == 107])\n",
    "errorrep = []\n",
    "errorlev = []\n",
    "for i in wind.report_id:\n",
    "    dat1 = wind[wind.report_id == i] \n",
    "    for j in dat1.z_coordinate:\n",
    "        dat2 = dat1[dat1.z_coordinate == j]\n",
    "        wdir = df[df.observed_variable == 106]\n",
    "        wspe = df[df.observed_variable == 107]\n",
    "        if len(wdir) != len(wspe):\n",
    "            errorrep.append(i)\n",
    "            errorlev.append(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with eua.CDMDataset('/raid60/scratch/uli/resorted_files_correct/0-20000-0-11019_CEUAS_merged_v0.nc') as data:\n",
    "    ri_t = data.recordindices['85'][:]\n",
    "#     ri_34 = data.recordindices['34'][:]\n",
    "    ri_36 = data.recordindices['36'][:]\n",
    "    ri_38 = data.recordindices['38'][:]\n",
    "    ri_39 = data.recordindices['39'][:]\n",
    "    obsvar = data.observations_table.observed_variable[:]\n",
    "    obsval = data.observations_table.observation_value[:]\n",
    "    pres = data.observations_table.z_coordinate[:]\n",
    "    repid = data.observations_table.report_id[:]\n",
    "    \n",
    "t = obsval[ri_t[0]:ri_t[-1]-1]\n",
    "trep = repid[ri_t[0]:ri_t[-1]-1]\n",
    "p_t = pres[ri_t[0]:ri_t[-1]-1]\n",
    "hum39 = obsval[ri_39[0]:ri_39[-1]-1]\n",
    "hum39rep = repid[ri_39[0]:ri_39[-1]-1]\n",
    "p_hum39 = pres[ri_39[0]:ri_39[-1]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import jit\n",
    "# @jit(nopython=True) \n",
    "def get_to_same_len(a, b, repa, repb, pa, pb):\n",
    "#     anew = a[np.in1d(repa, np.unique(repb))]\n",
    "#     panew = pa[np.in1d(repa, np.unique(repb))]\n",
    "#     bnew = b[np.in1d(repb, np.unique(repa))]\n",
    "#     pbnew = pb[np.in1d(repb, np.unique(repa))]\n",
    "    bout = np.empty(0)\n",
    "    pbout = np.empty(0)\n",
    "    for i in np.unique(repa[np.in1d(repa, np.unique(repb))]):\n",
    "        bout = np.concatenate((bout, bnew[np.in1d(repb, i)]))\n",
    "        pbout = np.concatenate((pbout, pbnew[np.in1d(repb, i)]))\n",
    "    aout = np.empty(0)\n",
    "    paout = np.empty(0)\n",
    "    for i in np.unique(repb[np.in1d(repb, np.unique(repa))]):\n",
    "        aout = np.concatenate((aout, anew[np.in1d(repa, i)]))\n",
    "        paout = np.concatenate((paout, panew[np.in1d(repa, i)]))\n",
    "    return aout, bout, paout, pbout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "trep_dc = np.empty(len(trep))\n",
    "for i in range(len(trep)):\n",
    "    trep_dc[i] = (int(b\"\".join(trep[i]).decode()))\n",
    "hum39rep_dc = np.empty(len(hum39rep))\n",
    "for i in range(len(hum39rep)):\n",
    "    hum39rep_dc[i] = (int(b\"\".join(hum39rep[i]).decode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, pa, pb = get_to_same_len(t, hum39, trep_dc, hum39rep_dc, p_t, p_hum39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5168\n",
      "0\n",
      "5168\n"
     ]
    }
   ],
   "source": [
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(pa))\n",
    "print(len(pb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tneu = t[np.in1d(trep_dc, np.unique(hum39rep_dc))]\n",
    "p_tneu = p_t[np.in1d(trep_dc, np.unique(hum39rep_dc))]\n",
    "hum39neu = hum39[np.in1d(hum39rep_dc, np.unique(trep_dc))]\n",
    "p_hum39neu = p_hum39[np.in1d(hum39rep_dc, np.unique(trep_dc))]\n",
    "hum39out = []\n",
    "p_hum39out = []\n",
    "for i in np.unique(trep_dc[np.in1d(trep_dc, np.unique(hum39rep_dc))]):\n",
    "    hum39out = hum39out + (list(hum39neu[np.in1d(hum39rep_dc, i)]))\n",
    "    p_hum39out = p_hum39out + (list(p_hum39neu[np.in1d(hum39rep_dc, i)]))\n",
    "tout = []\n",
    "p_tout = []\n",
    "for i in np.unique(hum39rep_dc[np.in1d(hum39rep_dc, np.unique(trep_dc))]):\n",
    "    tout = tout + (list(tneu[np.in1d(trep_dc, i)]))\n",
    "    p_tout = p_tout + (list(p_tneu[np.in1d(trep_dc, i)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5136"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p_tout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5433"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p_hum39out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3321027"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2819680"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hum39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([0, 1, 2, 5, 0])\n",
    "\n",
    "states = [0, 2]\n",
    "\n",
    "mask = np.in1d(test, states)\n",
    "\n",
    "mask\n",
    "array([ True, False,  True, False,  True])\n",
    "\n",
    "test[mask]\n",
    "array([0, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "trep_dc = []\n",
    "for i in trep:\n",
    "    trep_dc.append(b\"\".join(i).decode())\n",
    "hum39rep_dc = []\n",
    "for i in hum39rep:\n",
    "    hum39rep_dc.append(b\"\".join(i).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50552"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(trep_dc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "hum39rep_dc = []\n",
    "for i in hum39rep:\n",
    "    hum39rep_dc.append(b\"\".join(i).decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38442"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(hum39rep_dc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'isin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-cf7377adc2d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhum39rep_dc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrep_dc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'isin'"
     ]
    }
   ],
   "source": [
    "np.where(np.asarray(hum39rep_dc).isin(np.unique(trep_dc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt, dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;rh&#x27; (index: 5122)&gt;\n",
       "array([0.152205, 0.151341, 0.141188, ..., 0.572029, 0.481809, 0.432807],\n",
       "      dtype=float32)\n",
       "Coordinates:\n",
       "  * index    (index) int64 15680 15681 15682 15683 ... 20813 20814 20815 20816\n",
       "Attributes:\n",
       "    units:               1\n",
       "    standard_name:       relativ_humidity\n",
       "    long_name:           relative humidity\n",
       "    esat:                HylandWexler\n",
       "    origin:              t,q,p\n",
       "    enhancement_factor:  yes\n",
       "    precision:           6</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'rh'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>index</span>: 5122</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-50a0cb58-9d76-4991-9d1f-692cd55b8982' class='xr-array-in' type='checkbox' checked><label for='section-50a0cb58-9d76-4991-9d1f-692cd55b8982' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.152205 0.151341 0.141188 0.151863 ... 0.572029 0.481809 0.432807</span></div><div class='xr-array-data'><pre>array([0.152205, 0.151341, 0.141188, ..., 0.572029, 0.481809, 0.432807],\n",
       "      dtype=float32)</pre></div></div></li><li class='xr-section-item'><input id='section-e5d29e40-0aa0-4e85-97f1-3058e3c05af1' class='xr-section-summary-in' type='checkbox'  checked><label for='section-e5d29e40-0aa0-4e85-97f1-3058e3c05af1' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>index</span></div><div class='xr-var-dims'>(index)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>15680 15681 15682 ... 20815 20816</div><input id='attrs-bfbeed54-22b5-4edf-b4d0-c943c98f0e22' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-bfbeed54-22b5-4edf-b4d0-c943c98f0e22' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-e1d51ae1-b19f-4057-8f3f-375fca4532ba' class='xr-var-data-in' type='checkbox'><label for='data-e1d51ae1-b19f-4057-8f3f-375fca4532ba' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([15680, 15681, 15682, ..., 20814, 20815, 20816])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-901d199b-6f1b-401e-8951-67f0c2389990' class='xr-section-summary-in' type='checkbox'  checked><label for='section-901d199b-6f1b-401e-8951-67f0c2389990' class='xr-section-summary' >Attributes: <span>(7)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>units :</span></dt><dd>1</dd><dt><span>standard_name :</span></dt><dd>relativ_humidity</dd><dt><span>long_name :</span></dt><dd>relative humidity</dd><dt><span>esat :</span></dt><dd>HylandWexler</dd><dt><span>origin :</span></dt><dd>t,q,p</dd><dt><span>enhancement_factor :</span></dt><dd>yes</dd><dt><span>precision :</span></dt><dd>6</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'rh' (index: 5122)>\n",
       "array([0.152205, 0.151341, 0.141188, ..., 0.572029, 0.481809, 0.432807],\n",
       "      dtype=float32)\n",
       "Coordinates:\n",
       "  * index    (index) int64 15680 15681 15682 15683 ... 20813 20814 20815 20816\n",
       "Attributes:\n",
       "    units:               1\n",
       "    standard_name:       relativ_humidity\n",
       "    long_name:           relative humidity\n",
       "    esat:                HylandWexler\n",
       "    origin:              t,q,p\n",
       "    enhancement_factor:  yes\n",
       "    precision:           6"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observed_variable</th>\n",
       "      <th>observation_value</th>\n",
       "      <th>date_time</th>\n",
       "      <th>z_coordinate</th>\n",
       "      <th>report_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10246</th>\n",
       "      <td>39</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>1972-10-30 14:00:00</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10247</th>\n",
       "      <td>39</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>1972-10-30 14:00:00</td>\n",
       "      <td>70900.0</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10248</th>\n",
       "      <td>39</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>1972-10-30 14:00:00</td>\n",
       "      <td>74600.0</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10249</th>\n",
       "      <td>39</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>1972-10-30 14:00:00</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10250</th>\n",
       "      <td>39</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>1972-10-30 14:00:00</td>\n",
       "      <td>79600.0</td>\n",
       "      <td>20000000000</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15674</th>\n",
       "      <td>39</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>89400.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15675</th>\n",
       "      <td>39</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15676</th>\n",
       "      <td>39</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15677</th>\n",
       "      <td>39</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15678</th>\n",
       "      <td>39</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>1973-06-18 19:00:00</td>\n",
       "      <td>101100.0</td>\n",
       "      <td>20000000311</td>\n",
       "      <td>45.529999</td>\n",
       "      <td>-122.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5122 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       observed_variable  observation_value           date_time  z_coordinate  \\\n",
       "10246                 39           0.000780 1972-10-30 14:00:00       70000.0   \n",
       "10247                 39           0.000777 1972-10-30 14:00:00       70900.0   \n",
       "10248                 39           0.000752 1972-10-30 14:00:00       74600.0   \n",
       "10249                 39           0.000810 1972-10-30 14:00:00       75000.0   \n",
       "10250                 39           0.000819 1972-10-30 14:00:00       79600.0   \n",
       "...                  ...                ...                 ...           ...   \n",
       "15674                 39           0.004183 1973-06-18 19:00:00       89400.0   \n",
       "15675                 39           0.004216 1973-06-18 19:00:00       90000.0   \n",
       "15676                 39           0.004615 1973-06-18 19:00:00       95000.0   \n",
       "15677                 39           0.004809 1973-06-18 19:00:00      100000.0   \n",
       "15678                 39           0.004558 1973-06-18 19:00:00      101100.0   \n",
       "\n",
       "         report_id   latitude  longitude  \n",
       "10246  20000000000  45.529999    -122.68  \n",
       "10247  20000000000  45.529999    -122.68  \n",
       "10248  20000000000  45.529999    -122.68  \n",
       "10249  20000000000  45.529999    -122.68  \n",
       "10250  20000000000  45.529999    -122.68  \n",
       "...            ...        ...        ...  \n",
       "15674  20000000311  45.529999    -122.68  \n",
       "15675  20000000311  45.529999    -122.68  \n",
       "15676  20000000311  45.529999    -122.68  \n",
       "15677  20000000311  45.529999    -122.68  \n",
       "15678  20000000311  45.529999    -122.68  \n",
       "\n",
       "[5122 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# # todo: \n",
    "# # variablen nur einmal lesen, und nicht für jedern convertierweg nochmal\n",
    "# # für alle methoden sammeln und dann das, was mehrfach da ist, aussortieren\n",
    "# # das übrige dann mit dem vergleichen, was schon im Datensatz steht -> auffüllen \n",
    "# # fertig\n",
    "# #\n",
    "\n",
    "\n",
    "\n",
    "# def convert_missing(file, missing, destination: str = './converted'):\n",
    "#     with eua.CDMDataset(file) as data:\n",
    "#         df = data.to_dataframe(groups='observations_table', variables=['observed_variable', 'observation_value', 'date_time', 'z_coordinate', 'report_id', 'latitude', 'longitude'])\n",
    "        \n",
    "# # --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#     if 106 in missing or 107 in missing: # wd and/or ws is missing -> calculate it from u/v\n",
    "#         u = np.asarray(df[df.observed_variable == 104].observation_value)\n",
    "#         v = np.asarray(df[df.observed_variable == 105].observation_value)\n",
    "#         ws = np.sqrt(u ** 2 + v ** 2)\n",
    "#         wd = 90 - np.arctan2(-v, -u) * 180 / np.pi - 180.\n",
    "#         wd = np.where(wd > 0., wd, 360.+wd)\n",
    "#         return wd, ws\n",
    "#         #add\n",
    "#         #set conversion flag\n",
    "#     if 104 in missing or 105 in missing: # u and/or v is missing -> calculate it from wd and ws\n",
    "#         wd = np.asarray(df[df.observed_variable == 106].observation_value)\n",
    "#         ws = np.asarray(df[df.observed_variable == 107].observation_value)\n",
    "#         u = ws * np.cos(np.radians(wd))\n",
    "#         v = ws * np.sin(np.radians(wd)) \n",
    "#         return u, v\n",
    "#         #add\n",
    "#         #set conversion flag\n",
    "            \n",
    "# # --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#     #\n",
    "#     # convert from every source and merge the rh outputs? maximize the searched variable -> removed elif and made if everywher\n",
    "#     #\n",
    "#     if 38 in missing: # rh is missing -> calculate it from \n",
    "#         hums = [34, 36, 37, 39]\n",
    "#         missing_hum_vars = check_for_missing(file, checkvars = hums)\n",
    "#         for i in missing_hum_vars: hums.remove(i)\n",
    "#         print(hums)\n",
    "# #         if 34 in hums: # dew point depression\n",
    "# #             print('with 34')\n",
    "# #             t = df[df.observed_variable == 85]\n",
    "# #             hum = df[df.observed_variable == 34]\n",
    "            \n",
    "# #             cleaned_t = t[0:0]\n",
    "# #             cleaned_hum = hum[0:0]\n",
    "# #             for i in hum.report_id.drop_duplicates():\n",
    "# #                 inter_t = t[t.report_id == i]\n",
    "# #                 inter_hum = hum[hum.report_id == i]\n",
    "# #                 cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "# #                 cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "        \n",
    "# #             t = cleaned_t.observation_value.to_xarray()\n",
    "# #             dpd = cleaned_hum.observation_value.to_xarray()\n",
    "\n",
    "# #             rh = rasotools.met.convert.to_rh(t, dpd=dpd)\n",
    "# #             return rh\n",
    "# #             #add\n",
    "# #             #set conversion flag\n",
    "#         if 36 in hums: # dew point\n",
    "#             print('with 36')\n",
    "#             t = df[df.observed_variable == 85]\n",
    "#             hum = df[df.observed_variable == 36]\n",
    "\n",
    "#             cleaned_t = t[0:0]\n",
    "#             cleaned_hum = hum[0:0]\n",
    "#             for i in hum.report_id.drop_duplicates():\n",
    "#                 inter_t = t[t.report_id == i]\n",
    "#                 inter_hum = hum[hum.report_id == i]\n",
    "#                 cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "#                 cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "#             dpd = cleaned_t.observation_value.subtract(np.asarray(cleaned_hum.observation_value))\n",
    "#             t = cleaned_t.observation_value.to_xarray()\n",
    "#             dpd = dpd.to_xarray()\n",
    "\n",
    "#             rh = rasotools.met.convert.to_rh(t,dpd=dpd)\n",
    "#             return rh\n",
    "#             #add\n",
    "#             #set conversion flag\n",
    "#         if 39 in hums: # specific humidity\n",
    "#             print('with 39')\n",
    "#             t = df[df.observed_variable == 85]\n",
    "#             hum = df[df.observed_variable == 39]\n",
    "\n",
    "#             cleaned_t = t[0:0]\n",
    "#             cleaned_hum = hum[0:0]\n",
    "#             for i in hum.report_id.drop_duplicates():\n",
    "#                 inter_t = t[t.report_id == i]\n",
    "#                 inter_hum = hum[hum.report_id == i]\n",
    "#                 cleaned_t = cleaned_t.append(inter_t[inter_t.z_coordinate.isin(inter_hum.z_coordinate)])\n",
    "#                 cleaned_hum = cleaned_hum.append(inter_hum[inter_hum.z_coordinate.isin(inter_t.z_coordinate)])\n",
    "\n",
    "#             p = cleaned_t.z_coordinate.to_xarray()\n",
    "#             t = cleaned_t.observation_value.to_xarray()\n",
    "#             sh = cleaned_hum.observation_value.to_xarray()\n",
    "\n",
    "#             rh = rasotools.met.convert.to_rh(temp=t, spec_humi=sh, press=p)\n",
    "#             return rh\n",
    "#             #add\n",
    "#             #set conversion flag\n",
    "#         else:\n",
    "#             print('-')\n",
    "#             print('NO HUMIDITY VARIABLE AVAILABLE - COULD NOT CONVERT')\n",
    "#             print('-')\n",
    "            \n",
    "# # --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#     #\n",
    "#     # convert from every source and merge the rh outputs? maximize the searched variable -> removed elif and made if everywher\n",
    "#     #\n",
    "#     if 34 in missing: # dew point depression is missing -> calculate it from\n",
    "#         hums = [38, 36, 37, 39]\n",
    "#         missing_hum_vars = check_for_missing(file, checkvars = hums)\n",
    "#         for i in missing_hum_vars: hums.remove(i)\n",
    "            \n",
    "#         if 38 in hums and not 85 in missing: # relative humidity\n",
    "#             t = df[df.observed_variable == 85]\n",
    "#             rh = df[df.observed_variable == 38]\n",
    "\n",
    "#             cleaned = t[0:0]\n",
    "#             for i in rh.report_id.drop_duplicates():\n",
    "#                 inter = t[t.report_id == i]\n",
    "#                 for j in rh[rh.report_id == i].z_coordinate:\n",
    "#                     cleaned = cleaned.append(inter[inter.z_coordinate == j])\n",
    "\n",
    "#             t = cleaned.observation_value.to_xarray()\n",
    "#             p = cleaned.z_coordinate.to_xarray()\n",
    "#             rh = rh.observation_value.to_xarray()\n",
    "\n",
    "#             dpd = rasotools.met.convert.to_dpd(temp=t,press=p,rel_humi=rh)\n",
    "#             return dpd\n",
    "#             #add\n",
    "#             #set conversion flag\n",
    "#         if 36 in hums: # dew point\n",
    "#             t = df[df.observed_variable == 85]\n",
    "#             dp = df[df.observed_variable == 36]\n",
    "\n",
    "#             cleaned = t[0:0]\n",
    "#             for i in dp.report_id.drop_duplicates():\n",
    "#                 inter = t[t.report_id == i]\n",
    "#                 for j in dp[dp.report_id == i].z_coordinate:\n",
    "#                     cleaned = cleaned.append(inter[inter.z_coordinate == j])\n",
    "\n",
    "#             dpd = cleaned.observation_value.subtract(np.asarray(dp.observation_value))\n",
    "#             dpd = dpd.to_xarray()\n",
    "#             return dpd\n",
    "#             #add\n",
    "#             #set conversion flag\n",
    "#         if 39 in hums: # specific humidity\n",
    "#             t = df[df.observed_variable == 85]\n",
    "#             sh = df[df.observed_variable == 39]\n",
    "\n",
    "#             cleaned = t[0:0]\n",
    "#             for i in sh.report_id.drop_duplicates():\n",
    "#                 inter = t[t.report_id == i]\n",
    "#                 for j in sh[sh.report_id == i].z_coordinate:\n",
    "#                     cleaned = cleaned.append(inter[inter.z_coordinate == j])\n",
    "\n",
    "#             p = cleaned.z_coordinate.to_xarray()\n",
    "#             t = cleaned.observation_value.to_xarray()\n",
    "#             sh = sh.observation_value.to_xarray()\n",
    "\n",
    "#             dpd = rasotools.met.convert.to_dpd(spec_humi=sh,press=p,temp=t)\n",
    "#             return dpd\n",
    "#             #add\n",
    "#             #set conversion flag\n",
    "#         else:\n",
    "#             print('-')\n",
    "#             print('NO HUMIDITY VARIABLE AVAILABLE - COULD NOT CONVERT')\n",
    "#             print('-')\n",
    "            \n",
    "# # --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#     #\n",
    "#     # convert from every source and merge the rh outputs? maximize the searched variable -> removed elif and made if everywher\n",
    "#     #\n",
    "#     if 36 in missing: # dew point is missing -> calculate it from\n",
    "#         hums = [34, 38, 37, 39]\n",
    "#         missing_hum_vars = check_for_missing(file, checkvars = hums)\n",
    "#         for i in missing_hum_vars: hums.remove(i)\n",
    "            \n",
    "#         if 38 in hums and not 85 in missing: # relative humidity\n",
    "#             t = df[df.observed_variable == 85]\n",
    "#             rh = df[df.observed_variable == 38]\n",
    "\n",
    "#             cleaned = t[0:0]\n",
    "#             for i in rh.report_id.drop_duplicates():\n",
    "#                 inter = t[t.report_id == i]\n",
    "#                 for j in rh[rh.report_id == i].z_coordinate:\n",
    "#                     cleaned = cleaned.append(inter[inter.z_coordinate == j])\n",
    "\n",
    "#             t = cleaned.observation_value.to_xarray()\n",
    "#             p = cleaned.z_coordinate.to_xarray()\n",
    "#             rh = rh.observation_value.to_xarray()\n",
    "\n",
    "#             dp = rasotools.met.convert.to_dewpoint(temp=t,press=p,rel_humi=rh)\n",
    "#             return dp\n",
    "#             #add\n",
    "#             #set conversion flag\n",
    "#         if 34 in hums: # dew point depression\n",
    "#             t = df[df.observed_variable == 85]\n",
    "#             dpd = df[df.observed_variable == 34]\n",
    "\n",
    "#             cleaned = t[0:0]\n",
    "#             for i in dpd.report_id.drop_duplicates():\n",
    "#                 inter = t[t.report_id == i]\n",
    "#                 cleaned.append(inter)\n",
    "# #                 for j in dpd[dpd.report_id == i].z_coordinate:\n",
    "# #                     cleaned = cleaned.append(inter[inter.z_coordinate == j])\n",
    "\n",
    "#             dp = cleaned.observation_value.subtract(np.asarray(dpd.observation_value))\n",
    "#             dp = dp.to_xarray()\n",
    "#             return dp\n",
    "#             #add\n",
    "#             #set conversion flag\n",
    "#         if 39 in hums: # specific humidity\n",
    "#             t = df[df.observed_variable == 85]\n",
    "#             sh = df[df.observed_variable == 39]\n",
    "\n",
    "#             cleaned = t[0:0]\n",
    "#             for i in sh.report_id.drop_duplicates():\n",
    "#                 inter = t[t.report_id == i]\n",
    "#                 for j in sh[sh.report_id == i].z_coordinate:\n",
    "#                     cleaned = cleaned.append(inter[inter.z_coordinate == j])\n",
    "\n",
    "#             p = cleaned.z_coordinate.to_xarray()\n",
    "#             sh = sh.observation_value.to_xarray()\n",
    "#             dp = rasotools.met.convert.to_dewpoint(spec_humi=sh,press=p)\n",
    "#             return dp\n",
    "#             #add\n",
    "#             #set conversion flag\n",
    "#         else:\n",
    "#             print('-')\n",
    "#             print('NO HUMIDITY VARIABLE AVAILABLE - COULD NOT CONVERT')\n",
    "#             print('-')\n",
    "            \n",
    "# # --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "#     #\n",
    "#     # convert from every source and merge the rh outputs? maximize the searched variable -> removed elif and made if everywher\n",
    "#     #\n",
    "#     if 39 in missing: # specific humidity is missing -> calculate it from\n",
    "#         hums = [34, 38, 37, 36]\n",
    "#         missing_hum_vars = check_for_missing(file, checkvars = hums)\n",
    "#         for i in missing_hum_vars: hums.remove(i)\n",
    "            \n",
    "#         if 38 in hums and not 85 in missing: # relative humidity\n",
    "#             t = df[df.observed_variable == 85]\n",
    "#             rh = df[df.observed_variable == 38]\n",
    "\n",
    "#             cleaned = t[0:0]\n",
    "#             for i in rh.report_id.drop_duplicates():\n",
    "#                 inter = t[t.report_id == i]\n",
    "#                 for j in rh[rh.report_id == i].z_coordinate:\n",
    "#                     cleaned = cleaned.append(inter[inter.z_coordinate == j])\n",
    "\n",
    "#             t = cleaned.observation_value.to_xarray()\n",
    "#             p = cleaned.z_coordinate.to_xarray()\n",
    "#             rh = rh.observation_value.to_xarray()\n",
    "\n",
    "#             sh = rasotools.met.convert.to_sh(temp=t, press=p, rel_humi=rh)\n",
    "#             return sh\n",
    "#             #add\n",
    "#             #set conversion flag\n",
    "#         if 34 in hums: # dew point depression\n",
    "#             t = df[df.observed_variable == 85]\n",
    "#             dpd = df[df.observed_variable == 34]\n",
    "\n",
    "#             cleaned = t[0:0]\n",
    "#             for i in dpd.report_id.drop_duplicates():\n",
    "#                 inter = t[t.report_id == i]\n",
    "#                 for j in dpd[dpd.report_id == i].z_coordinate:\n",
    "#                     cleaned = cleaned.append(inter[inter.z_coordinate == j])\n",
    "\n",
    "#             t = cleaned.observation_value.to_xarray()\n",
    "#             p = cleaned.z_coordinate.to_xarray()\n",
    "#             dpd = dpd.observation_value.to_xarray()\n",
    "\n",
    "#             sh = rasotools.met.convert.to_sh(dpd=dpd, press=p, temp=t)\n",
    "#             return sh\n",
    "#             #add\n",
    "#             #set conversion flag\n",
    "#         if 36 in hums: # dew point\n",
    "#             t = df[df.observed_variable == 85]\n",
    "#             dp = df[df.observed_variable == 36]\n",
    "\n",
    "#             cleaned = t[0:0]\n",
    "#             for i in dp.report_id.drop_duplicates():\n",
    "#                 inter = t[t.report_id == i]\n",
    "#                 for j in dp[dp.report_id == i].z_coordinate:\n",
    "#                     cleaned = cleaned.append(inter[inter.z_coordinate == j])\n",
    "\n",
    "#             dpd = cleaned.observation_value.subtract(np.asarray(dp.observation_value))\n",
    "\n",
    "#             t = cleaned.observation_value.to_xarray()\n",
    "#             p = cleaned.z_coordinate.to_xarray()\n",
    "#             dpd = dpd.to_xarray()\n",
    "#             sh = rasotools.met.convert.to_sh(dpd=dpd, press=p, temp=t)\n",
    "#             return sh\n",
    "#             #add\n",
    "#             #set conversion flag\n",
    "#         else:\n",
    "#             print('-')\n",
    "#             print('NO HUMIDITY VARIABLE AVAILABLE - COULD NOT CONVERT')\n",
    "#             print('-')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
