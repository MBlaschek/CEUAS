{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import sys\n",
    "import zipfile, os, time\n",
    "import urllib3\n",
    "from datetime import datetime, timedelta\n",
    "import glob\n",
    "import h5py\n",
    "import plotly.express as px\n",
    "fs = open('path.txt', 'r')\n",
    "path = fs.read()  \n",
    "fs.close()\n",
    "sys.path.append(path)\n",
    "\n",
    "import cds_eua3 as eua\n",
    "eua.logging_set_level(30)\n",
    "import xarray as xr\n",
    "\n",
    "import cdsapi, zipfile, os, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "def write_dict_h5(dfile, f, k, fbencodings, var_selection=[], mode='a', attrs={}): \n",
    "    \"\"\" Writes each separate variable from the observation or feedback tables inot netcdf using h5py.\n",
    "          f is a pandas dataframe with one column, one for each variable\n",
    "          k is either 'era5fb' or 'observations_table'\n",
    "          fbencodings is the encodings of variable types, e.g. {'observations_id': { 'compression': 'gzip' } }\n",
    "    \"\"\"\n",
    "\n",
    "    #attrs=  {'date_time':('units','seconds since 1900-01-01 00:00:00')}\n",
    "    #attrs = {'observation_id': ('description', 'unique ID for observation'), 'report_id': ('description', 'Link to header information') , 'date_time':('units','seconds since 1900-01-01 00:00:00') }\n",
    "    \n",
    "    with h5py.File(dfile,mode) as fd:\n",
    "        if k == '':\n",
    "            v = var_selection[0]\n",
    "            fd.create_dataset(v,f[v].shape,f[v].dtype,compression=fbencodings[v]['compression'], chunks=True)\n",
    "            fd[v][:]=f[v].values[:]\n",
    "        else:\n",
    "            try:\n",
    "                fd.create_group(k)\n",
    "                index=numpy.zeros (f[list(f.keys())[0]].shape[0], dtype='S1')\n",
    "                fd[k].create_dataset('index', data=index)\n",
    "            except:\n",
    "                pass\n",
    "            if not var_selection:\n",
    "                var_selection=list(f.keys())\n",
    "            fixed_string_len = 20\n",
    "            string10=numpy.zeros(fixed_string_len,dtype='S1')\n",
    "            sdict={}\n",
    "            slist=[]\n",
    "\n",
    "            #groupencodings     \n",
    "\n",
    "            for v in var_selection:          \n",
    "                #variables_dic[v] = ''\n",
    "                if type(f[v]) == pd.core.series.Series:\n",
    "                    fvv=f[v].values\n",
    "                else:\n",
    "                    fvv=f[v]\n",
    "\n",
    "                if type(fvv[0]) not in [str,bytes,numpy.bytes_]:\n",
    "\n",
    "                    if fvv.dtype !='S1':\n",
    "\n",
    "                        fd[k].create_dataset(v,fvv.shape,fvv.dtype,compression=fbencodings[v]['compression'], chunks=True)\n",
    "                        fd[k][v][:]=fvv[:]\n",
    "                        if attrs:    #  attrs={'date_time':('units','seconds since 1900-01-01 00:00:00')}\n",
    "                            if v in attrs.keys():\n",
    "                                for kk,vv in attrs[v].items():\n",
    "                                    if type(vv) is str:  \n",
    "                                        fd[k][v].attrs[kk]=numpy.bytes_(vv)\n",
    "                                    else:\n",
    "                                        fd[k][v].attrs[kk]=vv\n",
    "\n",
    "                        if v in ['date_time','report_timestamp','record_timestamp']:\n",
    "                            fd[k][v].attrs['units']=numpy.bytes_('seconds since 1900-01-01 00:00:00')                            #print (  fk, ' ' , v , ' ' ,   ) \n",
    "\n",
    "                    else:\n",
    "                        fd[k].create_dataset(v,fvv.shape,fvv.dtype,compression=fbencodings[v]['compression'], chunks=True)\n",
    "                        fd[k][v][:]=fvv[:]\n",
    "                        slen=fvv.shape[1]\n",
    "                        sdict[v]=slen\n",
    "                        if slen not in slist:\n",
    "                            slist.append(slen)\n",
    "                            try:\n",
    "                                fd[k].create_dataset( 'string{}'.format(slen),  data=string10[:slen]  )\n",
    "                            except:\n",
    "                                pass               \n",
    "                        if v in attrs.keys():\n",
    "                            fd[k][v].attrs['description']=numpy.bytes_(attrs[v]['description'])\n",
    "                            fd[k][v].attrs['external_table']=numpy.bytes_(attrs[v]['external_table'])\n",
    "\n",
    "                else:\n",
    "                    sleno=len(fvv[0])\n",
    "                    slen=sleno\n",
    "                    try:\n",
    "                        slen=int(fvv.dtype.descr[0][1].split('S')[1])\n",
    "                    except:  \n",
    "                        pass\n",
    "\n",
    "                    sdict[v]=slen\n",
    "                    if slen not in slist:\n",
    "                        slist.append(slen)\n",
    "                        try:\n",
    "                            print('trying to cread dim')\n",
    "                            fd[k].create_dataset( 'string{}'.format(slen),  data=string10[:slen]  )\n",
    "                            print('dim created')\n",
    "                        except:\n",
    "                            print('dim creation failed')\n",
    "                            pass               \n",
    "\n",
    "                    #x=x.reshape(fvv.shape[0],slen)\n",
    "                    fd[k].create_dataset(v,data=fvv.view('S1').reshape(fvv.shape[0],slen),compression=fbencodings[v]['compression'],chunks=True)\n",
    "                    if v in attrs.keys():\n",
    "                        fd[k][v].attrs['description']     =numpy.bytes_(attrs[v]['description'])\n",
    "                        fd[k][v].attrs['external_table']=numpy.bytes_(attrs[v]['external_table'])                \n",
    "\n",
    "                #variables_dic[v] = f[v].values.dtype\n",
    "\n",
    "            for v in fd[k].keys(): #var_selection:\n",
    "                l=0      \n",
    "\n",
    "                '''\n",
    "                if v == 'primary_station_id':\n",
    "                    try:\n",
    "                        fd[k][v].dims[l].attach_scale(fd[k]['index'])\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        slen =  len( fd[k][v][0] )\n",
    "                        stringa=numpy.zeros( slen , dtype='S1')\n",
    "                        fd[k].create_dataset( 'string{}'.format(slen),  data= stringa  )                                        \n",
    "                        fd[k][v].dims[1].attach_scale(   fd[k]['string{}'.format(slen)]  )                                        \n",
    "                    except:\n",
    "                        fd[k][v].dims[1].attach_scale(   fd[k]['string{}'.format(slen)]  )                    \n",
    "\n",
    "\n",
    "                if v == 'station_name':\n",
    "                    try:\n",
    "                        fd[k][v].dims[l].attach_scale(fd[k]['index'])\n",
    "                        slen =  len( fd[k][v][0][0])\n",
    "                        stringa=numpy.zeros( slen , dtype='S1')\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        fd[k].create_dataset( 'string{}'.format(slen),  data= stringa  )\n",
    "                        fd[k][v].dims[1].attach_scale(   fd[k]['string{}'.format(slen)]  )                    \n",
    "                        print('done attaching')\n",
    "                    except:\n",
    "                        print('not working')\n",
    "\n",
    "                '''             \n",
    "                try:\n",
    "                    if type(f[v]) == pd.core.series.Series:\n",
    "                        fvv=f[v].values\n",
    "                    else:\n",
    "                        fvv=f[v]\n",
    "                    if 'string' not in v and v!='index':                    \n",
    "                        fd[k][v].dims[l].attach_scale(fd[k]['index'])\n",
    "                        #print(v,fvv.ndim,type(fvv[0]))\n",
    "                        if fvv.ndim==2 or type(fvv[0]) in [str,bytes,numpy.bytes_]:\n",
    "                            slen=sdict[v]\n",
    "                            #slen=10\n",
    "                            fd[k][v].dims[1].attach_scale(fd[k]['string{}'.format(slen)])\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "\n",
    "\n",
    "            i=4        \n",
    "            for v in slist:\n",
    "                s='string{}'.format(v)\n",
    "                for a in ['NAME']:\n",
    "                    fd[k][s].attrs[a]=numpy.bytes_('This is a netCDF dimension but not a netCDF variable.')\n",
    "\n",
    "                i+=1\n",
    "\n",
    "    return\n",
    "#variables_dic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid60/scratch/uli/0-20000-0-93062_CEUAS_merged_v0.nc'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# files = glob.glob('/raid60/scratch/federico/MERGED_DATABASE_OCTOBER2020_sensor/0-20000-0-11035*.nc')\n",
    "files = glob.glob('/raid60/scratch/uli/0*.nc')\n",
    "files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File: <HDF5 file \"0-20000-0-93062_CEUAS_merged_v0.nc\" (mode r)>\n",
       "Filename: /raid60/scratch/uli/0-20000-0-93062_CEUAS_merged_v0.nc\n",
       "(G)roups/(V)ariables: \n",
       "\n",
       " - G | crs__________________________________________ : : 4\n",
       " - V | dateindex____________________________________ : : (112,)\n",
       " - G | era5fb_______________________________________ : : 72\n",
       " - G | header_table_________________________________ : : 56\n",
       " - G | observations_table___________________________ : : 50\n",
       " - G | observed_variable____________________________ : : 9\n",
       " - V | recordindex__________________________________ : : (167,)\n",
       " - V | recordtimestamp______________________________ : : (167,)\n",
       " - G | sensor_configuration_________________________ : : 12\n",
       " - G | source_configuration_________________________ : : 2\n",
       " - G | station_configuration________________________ : : 47\n",
       " - G | station_configuration_codes__________________ : : 7\n",
       " - G | station_type_________________________________ : : 4\n",
       " - G | units________________________________________ : : 6\n",
       " - G | z_coordinate_type____________________________ : : 4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = eua.CDMDataset(files[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  36,  38,  39,  85, 104, 105, 106, 107, 117, 136, 137, 138,\n",
       "       139, 140])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allvars = data.observations_table.observed_variable[()]\n",
    "np.unique(allvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "allvars = data.observations_table.observed_variable[()]\n",
    "allvars.sort()\n",
    "allvars = np.unique(allvars)\n",
    "#\n",
    "ri = data.recordindex[()]\n",
    "rt = data.recordtimestamp[()]\n",
    "keys = data.observations_table.keys()[:-1]\n",
    "# dropping all keys, where dimensions won't work - just help variabels for dimensions\n",
    "keys.pop(43)\n",
    "keys.pop(42)\n",
    "keys.pop(41)\n",
    "recordindices = [[] for i in range(len(np.unique(allvars)))]\n",
    "recordtimestamps = [[] for i in range(len(np.unique(allvars)))]\n",
    "\n",
    "# output variables (from observations_table)\n",
    "ov = []\n",
    "for o in keys:\n",
    "    ov.append([[] for i in range(len(np.unique(allvars)))])\n",
    "    \n",
    "for i in range(len(ri)):\n",
    "    try:\n",
    "        start = ri[i]\n",
    "        end = ri[i+1]\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "    a = data.observations_table.observed_variable[()][start:end]\n",
    "    helpvar = []\n",
    "    for o in range(len(keys)):\n",
    "        if keys[o] == 'observation_id' or keys[o] == 'report_id' or keys[o] == 'sensor_id' or keys[o] == 'source_id':\n",
    "            b = []\n",
    "            for n in data.observations_table[keys[o]][()][start:end]:\n",
    "                c = ''\n",
    "                for bb in n:\n",
    "                    c = c + bb.decode()\n",
    "                b.append(c)\n",
    "        else:\n",
    "            b = data.observations_table[keys[o]][()][start:end]\n",
    "        sa, sb = zip(*sorted(zip(a, b)))\n",
    "        helpvar.append(sb)\n",
    "\n",
    "    for j in range(len(allvars)):\n",
    "        for k in range(len(sa)):\n",
    "            if sa[k] == allvars[j]:\n",
    "                for m in range(len(helpvar)):\n",
    "                    ov[m][j].append(helpvar[m][k])\n",
    "        recordindices[j].append(len(ov[0][j]))\n",
    "        recordtimestamps[j].append(rt[i])\n",
    "        \n",
    "#\n",
    "# setting record_indices to the right value\n",
    "#\n",
    "lenadd = 0.\n",
    "for i in range(len(recordindices)):\n",
    "    recordindices[i] = np.asarray(np.append([0], recordindices[i][:-1])) + lenadd\n",
    "    lenadd += len(ov[0][i])\n",
    "\n",
    "#\n",
    "# shaping record_indices -> setting every missing value to nan\n",
    "#\n",
    "old = -1\n",
    "for i in range(len(recordindices)):\n",
    "    for j in range(len(recordindices[i])):\n",
    "        if recordindices[i][j] != 0 and recordindices[i][j] == recordindices[i][j-1]:\n",
    "            old = recordindices[i][j]\n",
    "            recordindices[i][j] = np.nan\n",
    "        elif recordindices[i][j] == old:\n",
    "            recordindices[i][j] = np.nan\n",
    "\n",
    "#\n",
    "# recordtimestamps are only necessary once\n",
    "#\n",
    "recordtimestamps = recordtimestamps[0]\n",
    "\n",
    "# \n",
    "# stacking all output variables\n",
    "#\n",
    "out = []\n",
    "for j in ov:\n",
    "    finalvar = []\n",
    "    for i in j:\n",
    "        finalvar = finalvar + i\n",
    "    out.append(finalvar)\n",
    "    \n",
    "#\n",
    "# restoring byte arrays:\n",
    "#\n",
    "for o in range(len(keys)):\n",
    "    if keys[o] == 'observation_id' or keys[o] == 'report_id' or keys[o] == 'sensor_id' or keys[o] == 'source_id':\n",
    "        b = []\n",
    "        for n in range(len(out[o])):\n",
    "            c = []\n",
    "            for bb in out[o][n]:\n",
    "                c.append(bb.encode())\n",
    "            out[o][n] = c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# writing data into observations_table\n",
    "#\n",
    "\n",
    "file = h5py.File('/raid60/scratch/uli/testoutputfile.nc', 'r+')\n",
    "\n",
    "for i in range(len(keys)):\n",
    "    try:\n",
    "        del file['observations_table'][keys[i]]\n",
    "    except:\n",
    "        pass\n",
    "    if keys[i] == 'index':\n",
    "        pass\n",
    "    elif keys[i] == 'observation_id' or keys[i] == 'report_id' or keys[i] == 'sensor_id' or keys[i] == 'source_id':\n",
    "        slen = len(out[i][0])\n",
    "        alldict = {keys[i]:np.asarray(out[i], dtype='S{}'.format(slen))}\n",
    "        write_dict_h5('/raid60/scratch/uli/testoutputfile.nc', alldict, 'observations_table', {keys[i]: { 'compression': 'gzip' } }, [keys[i]])\n",
    "    else:\n",
    "        alldict = pandas.DataFrame({keys[i]:out[i]})\n",
    "        write_dict_h5('/raid60/scratch/uli/testoutputfile.nc', alldict, 'observations_table', {keys[i]: { 'compression': 'gzip' } }, [keys[i]])  \n",
    "#\n",
    "# writing the recordindices and recordtimestamp.\n",
    "#       \n",
    "for i in range(len(recordindices)):\n",
    "    file = h5py.File('/raid60/scratch/uli/testoutputfile.nc', 'r+')\n",
    "    try:\n",
    "        del file['recordindices'][str(allvars[i])]\n",
    "    except:\n",
    "        pass\n",
    "    testvar = pandas.DataFrame({str(allvars[i]):recordindices[i]})\n",
    "    write_dict_h5('/raid60/scratch/uli/testoutputfile.nc', testvar, 'recordindices', {str(allvars[i]): { 'compression': 'gzip' } }, [str(allvars[i])]) \n",
    "\n",
    "try:\n",
    "    del file['recordindex']\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    del file['recordtimestamp']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "testvar = pandas.DataFrame({'recordtimestamp':recordtimestamps})\n",
    "write_dict_h5('/raid60/scratch/uli/testoutputfile.nc', testvar, '', {'recordtimestamp': { 'compression': 'gzip' } }, ['recordtimestamp']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File: <HDF5 file \"testoutputfile.nc\" (mode r+)>\n",
       "Filename: /raid60/scratch/uli/testoutputfile.nc\n",
       "(G)roups/(V)ariables: \n",
       "\n",
       " - G | crs__________________________________________ : : 4\n",
       " - V | dateindex____________________________________ : : (112,)\n",
       " - G | era5fb_______________________________________ : : 72\n",
       " - G | header_table_________________________________ : : 56\n",
       " - G | observations_table___________________________ : : 49\n",
       " - G | observed_variable____________________________ : : 9\n",
       " - G | recordindices________________________________ : : 16\n",
       " - V | recordtimestamp______________________________ : : (166,)\n",
       " - G | sensor_configuration_________________________ : : 12\n",
       " - G | source_configuration_________________________ : : 2\n",
       " - G | station_configuration________________________ : : 47\n",
       " - G | station_configuration_codes__________________ : : 7\n",
       " - G | station_type_________________________________ : : 4\n",
       " - G | units________________________________________ : : 6\n",
       " - G | z_coordinate_type____________________________ : : 4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = eua.CDMDataset('/raid60/scratch/uli/testoutputfile.nc')\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan, 2393., 2419., 2432., 2457., 2481., 2495., 2512., 2527.,\n",
       "       2555., 2568., 2578., 2588., 2601., 2619., 2637., 2651., 2668.,\n",
       "       2685., 2703., 2720., 2732., 2759., 2772., 2784., 2793., 2811.,\n",
       "       2829., 2843., 2857., 2873., 2890., 2905., 2919., 2931., 2946.,\n",
       "       2962., 2978., 2995., 3008., 3021., 3038., 3061., 3088., 3105.,\n",
       "       3122., 3135., 3152., 3165., 3180., 3197., 3211., 3223., 3237.,\n",
       "       3262., 3272.,   nan, 3300., 3312., 3326., 3339., 3357., 3371.,\n",
       "       3383., 3396., 3411., 3429., 3441., 3454., 3466., 3484., 3494.,\n",
       "       3507., 3519., 3532., 3545., 3572., 3585., 3597., 3615., 3628.,\n",
       "       3641., 3659., 3687., 3700., 3713., 3739., 3752., 3770., 3783.,\n",
       "       3796., 3809., 3822., 3839., 3852., 3865., 3878., 3890., 3908.,\n",
       "       3921., 3934., 3947., 3961., 3975., 3988., 4001., 4014., 4032.,\n",
       "       4045., 4059., 4073., 4086., 4099., 4112., 4130., 4144., 4161.,\n",
       "       4178., 4191., 4204., 4217., 4230., 4243., 4260., 4274., 4287.,\n",
       "       4300., 4328., 4339., 4353., 4366., 4384., 4412., 4428., 4444.,\n",
       "       4460., 4487., 4500., 4514., 4531., 4544., 4557., 4571., 4599.,\n",
       "       4627., 4640., 4668., 4696., 4720., 4747., 4764., 4778., 4795.,\n",
       "       4823., 4837., 4852., 4870., 4887., 4904., 4922., 4947., 4964.,\n",
       "       4990., 5003., 5031., 5044.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: temperature\n",
    "data_test.recordindices['85'][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recordindices:\n",
       "\n",
       "0_________________________________________________ : : (166,)\n",
       "104_______________________________________________ : : (166,)\n",
       "105_______________________________________________ : : (166,)\n",
       "106_______________________________________________ : : (166,)\n",
       "107_______________________________________________ : : (166,)\n",
       "117_______________________________________________ : : (166,)\n",
       "136_______________________________________________ : : (166,)\n",
       "137_______________________________________________ : : (166,)\n",
       "138_______________________________________________ : : (166,)\n",
       "139_______________________________________________ : : (166,)\n",
       "140_______________________________________________ : : (166,)\n",
       "36________________________________________________ : : (166,)\n",
       "38________________________________________________ : : (166,)\n",
       "39________________________________________________ : : (166,)\n",
       "85________________________________________________ : : (166,)\n",
       "index_____________________________________________ : : (166,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.recordindices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "observations_table:\n",
       "\n",
       "adjustment_id_____________________________________ : : (30269,)\n",
       "advanced_assimilation_feedback____________________ : : (30269,)\n",
       "advanced_homogenisation___________________________ : : (30269,)\n",
       "advanced_qc_______________________________________ : : (30269,)\n",
       "advanced_uncertainty______________________________ : : (30269,)\n",
       "bbox_max_latitude_________________________________ : : (30269,)\n",
       "bbox_max_longitude________________________________ : : (30269,)\n",
       "bbox_min_latitude_________________________________ : : (30269,)\n",
       "bbox_min_longitude________________________________ : : (30269,)\n",
       "code_table________________________________________ : : (30269,)\n",
       "conversion_flag___________________________________ : : (30269,)\n",
       "conversion_method_________________________________ : : (30269,)\n",
       "crs_______________________________________________ : : (30269,)\n",
       "data_policy_licence_______________________________ : : (30269,)\n",
       "date_time_________________________________________ : : (30269,)\n",
       "date_time_meaning_________________________________ : : (30269,)\n",
       "exposure_of_sensor________________________________ : : (30269,)\n",
       "latitude__________________________________________ : : (30269,)\n",
       "location_method___________________________________ : : (30269,)\n",
       "location_precision________________________________ : : (30269,)\n",
       "longitude_________________________________________ : : (30269,)\n",
       "numerical_precision_______________________________ : : (30269,)\n",
       "observation_duration______________________________ : : (30269,)\n",
       "observation_height_above_station_surface__________ : : (30269,)\n",
       "observation_id____________________________________ : : (30269, 11)\n",
       "observation_value_________________________________ : : (30269,)\n",
       "observed_variable_________________________________ : : (30269,)\n",
       "original_code_table_______________________________ : : (30269,)\n",
       "original_precision________________________________ : : (30269,)\n",
       "original_units____________________________________ : : (30269,)\n",
       "original_value____________________________________ : : (30269,)\n",
       "processing_level__________________________________ : : (30269,)\n",
       "quality_flag______________________________________ : : (30269,)\n",
       "report_id_________________________________________ : : (30269, 11)\n",
       "secondary_value___________________________________ : : (30269,)\n",
       "secondary_variable________________________________ : : (30269,)\n",
       "sensor_automation_status__________________________ : : (30269,)\n",
       "sensor_id_________________________________________ : : (30269, 3)\n",
       "source_id_________________________________________ : : (30269, 6)\n",
       "spatial_representativeness________________________ : : (30269,)\n",
       "string11__________________________________________ : : (11,)\n",
       "string3___________________________________________ : : (3,)\n",
       "string6___________________________________________ : : (6,)\n",
       "traceability______________________________________ : : (30269,)\n",
       "units_____________________________________________ : : (30269,)\n",
       "value_significance________________________________ : : (30269,)\n",
       "z_coordinate______________________________________ : : (30269,)\n",
       "z_coordinate_method_______________________________ : : (30269,)\n",
       "z_coordinate_type_________________________________ : : (30269,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.observations_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1897480800, 1897502400, 1897592400, 1899385200, 1899406800,\n",
       "       1899493200, 1900098000, 1900360800, 1900368000, 1900447200,\n",
       "       1900533600, 1900684800, 1900702800, 1901545200, 1901631600,\n",
       "       1901829600, 1902430800, 1902528000, 1902776400, 1902949200,\n",
       "       1903024800, 1903449600, 1903464000, 1903640400, 1904076000,\n",
       "       1904133600, 1904569200, 1904587200, 1904745600, 1904760000,\n",
       "       1905379200, 1905796800, 1905804000, 1905969600, 1906048800,\n",
       "       1906059600, 1906070400, 1906495200, 1906567200, 1906578000,\n",
       "       1906750800, 1907096400, 1907107200, 1907179200, 1907186400,\n",
       "       1907258400, 1908554400, 1908878400, 1908892800, 1908972000,\n",
       "       1909000800, 1909051200, 1909065600, 1909159200, 1909173600,\n",
       "       1909494000, 1909519200, 1909584000, 1909605600, 1910088000,\n",
       "       1910098800, 1910260800, 1910358000, 1910606400, 1910613600,\n",
       "       1910620800, 1910725200, 1910865600, 1910952000, 1910962800,\n",
       "       1910988000, 1911391200, 1911398400, 1911470400, 1911477600,\n",
       "       1911592800, 1911823200, 1911902400, 1911913200, 1911988800,\n",
       "       1911996000, 1912003200, 1912089600, 1912428000, 1912514400,\n",
       "       1912615200, 1912690800, 1912701600, 1912712400, 1912788000,\n",
       "       1913025600, 1913198400, 1913205600, 1913385600, 1913630400,\n",
       "       1913644800, 1913716800, 1913731200, 1913803200, 1913810400,\n",
       "       1913922000, 1913976000, 1913986800, 1914235200, 1914242400,\n",
       "       1914321600, 1914328800, 1914336000, 1914408000, 1914415200,\n",
       "       1914526800, 1914580800, 1914588000, 1914940800, 1914962400,\n",
       "       1915056000, 1915113600, 1915185600, 1915192800, 1915740000,\n",
       "       1916168400, 1916236800, 1916323200, 1916341200, 1916427600,\n",
       "       1916848800, 1917446400, 1917550800, 1917982800, 1918155600,\n",
       "       1918576800, 1918663200, 1918742400, 1918760400, 1918836000,\n",
       "       1919451600, 1919937600, 1919948400, 1920384000, 1920549600,\n",
       "       1920556800, 1920564000, 1921093200, 1921168800, 1921266000,\n",
       "       1921514400, 1921525200, 1921680000, 1922119200, 1922130000,\n",
       "       1922184000, 1922292000, 1922371200, 1922443200, 1922450400,\n",
       "       1922464800, 1922709600, 1922716800, 1922724000, 1922803200,\n",
       "       1922889600, 1922918400, 1923328800, 1923339600, 1923688800,\n",
       "       1925244000, 1925503200])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.recordtimestamp[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1897480800, 1897502400, 1897592400, 1899385200, 1899406800,\n",
       "       1899493200, 1900098000, 1900360800, 1900368000, 1900447200,\n",
       "       1900533600, 1900684800, 1900702800, 1901545200, 1901631600,\n",
       "       1901829600, 1902430800, 1902528000, 1902776400, 1902949200,\n",
       "       1903024800, 1903449600, 1903464000, 1903640400, 1904076000,\n",
       "       1904133600, 1904569200, 1904587200, 1904745600, 1904760000,\n",
       "       1905379200, 1905796800, 1905804000, 1905969600, 1906048800,\n",
       "       1906059600, 1906070400, 1906495200, 1906567200, 1906578000,\n",
       "       1906750800, 1907096400, 1907107200, 1907179200, 1907186400,\n",
       "       1907258400, 1908554400, 1908878400, 1908892800, 1908972000,\n",
       "       1909000800, 1909051200, 1909065600, 1909159200, 1909173600,\n",
       "       1909494000, 1909519200, 1909584000, 1909605600, 1910088000,\n",
       "       1910098800, 1910260800, 1910358000, 1910606400, 1910613600,\n",
       "       1910620800, 1910725200, 1910865600, 1910952000, 1910962800,\n",
       "       1910988000, 1911391200, 1911398400, 1911470400, 1911477600,\n",
       "       1911592800, 1911823200, 1911902400, 1911913200, 1911988800,\n",
       "       1911996000, 1912003200, 1912089600, 1912428000, 1912514400,\n",
       "       1912615200, 1912690800, 1912701600, 1912712400, 1912788000,\n",
       "       1913025600, 1913198400, 1913205600, 1913385600, 1913630400,\n",
       "       1913644800, 1913716800, 1913731200, 1913803200, 1913810400,\n",
       "       1913922000, 1913976000, 1913986800, 1914235200, 1914242400,\n",
       "       1914321600, 1914328800, 1914336000, 1914408000, 1914415200,\n",
       "       1914526800, 1914580800, 1914588000, 1914940800, 1914962400,\n",
       "       1915056000, 1915113600, 1915185600, 1915192800, 1915740000,\n",
       "       1916168400, 1916236800, 1916323200, 1916341200, 1916427600,\n",
       "       1916848800, 1917446400, 1917550800, 1917982800, 1918155600,\n",
       "       1918576800, 1918663200, 1918742400, 1918760400, 1918836000,\n",
       "       1919451600, 1919937600, 1919948400, 1920384000, 1920549600,\n",
       "       1920556800, 1920564000, 1921093200, 1921168800, 1921266000,\n",
       "       1921514400, 1921525200, 1921680000, 1922119200, 1922130000,\n",
       "       1922184000, 1922292000, 1922371200, 1922443200, 1922450400,\n",
       "       1922464800, 1922709600, 1922716800, 1922724000, 1922803200,\n",
       "       1922889600, 1922918400, 1923328800, 1923339600, 1923688800,\n",
       "       1925244000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.recordtimestamp[()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allvars = data.observations_table.observed_variable[()]\n",
    "# allvars.sort()\n",
    "# allvars = np.unique(allvars)\n",
    "# # recordindices einzeln sortieren - f√ºr alle variablen eigene listen erstellen - dazu recordindices erstellen - alle daten hintereinander legen - len aller vorhergehender rec_in zu den nachkommenden addieren.\n",
    "# #\n",
    "# ri = data.recordindex[()]\n",
    "# rt = data.recordtimestamp[()]\n",
    "# keys = data.observations_table.keys()\n",
    "# recordindices = [[] for i in range(len(np.unique(allvars)))]\n",
    "# recordtimestamps = [[] for i in range(len(np.unique(allvars)))]\n",
    "\n",
    "# variables = [[] for i in range(len(np.unique(allvars)))]\n",
    "# values = [[] for i in range(len(np.unique(allvars)))]\n",
    "# zcoords = [[] for i in range(len(np.unique(allvars)))]\n",
    "\n",
    "# for i in range(len(ri)):\n",
    "#     try:\n",
    "#         start = ri[i]\n",
    "#         end = ri[i+1]\n",
    "#     except:\n",
    "#         break\n",
    "        \n",
    "#     a = data.observations_table.observed_variable[()][start:end]\n",
    "#     b = data.observations_table.observation_value[()][start:end]\n",
    "#     c = data.observations_table.z_coordinate[()][start:end]\n",
    "\n",
    "#     sa, sb = zip(*sorted(zip(a, b)))\n",
    "#     sa, sc = zip(*sorted(zip(a, c)))\n",
    "#     for j in range(len(allvars)):\n",
    "#         for k in range(len(sa)):\n",
    "#             if sa[k] == allvars[j]:\n",
    "#                 variables[j].append(sa[k])\n",
    "#                 values[j].append(sb[k])\n",
    "#                 zcoords[j].append(sc[k])\n",
    "#         recordindices[j].append(len(variables[j]))\n",
    "#         recordtimestamps[j].append(rt[i])\n",
    "        \n",
    "# lenadd = 0\n",
    "# for i in range(len(recordindices)):\n",
    "#     recordindices[i] = np.asarray(np.append([0], recordindices[i][:-1])) + lenadd\n",
    "#     lenadd += len(variables[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allvars = data.observations_table.observed_variable[()]\n",
    "# allvars.sort()\n",
    "# allvars = np.unique(allvars)\n",
    "# #\n",
    "# ri = data.recordindex[()]\n",
    "# rt = data.recordtimestamp[()]\n",
    "# keys = data.observations_table.keys()[:-1]\n",
    "# recordindices = [[] for i in range(len(np.unique(allvars)))]\n",
    "# recordtimestamps = [[] for i in range(len(np.unique(allvars)))]\n",
    "\n",
    "# # output variables (from observations_table)\n",
    "# ov = []\n",
    "# for o in keys:\n",
    "#     ov.append([[] for i in range(len(np.unique(allvars)))])\n",
    "    \n",
    "# for i in range(len(ri)):\n",
    "#     try:\n",
    "#         start = ri[i]\n",
    "#         end = ri[i+1]\n",
    "#     except:\n",
    "#         break\n",
    "        \n",
    "#     a = data.observations_table.observed_variable[()][start:end]\n",
    "#     helpvar = []\n",
    "#     for o in range(len(keys)):\n",
    "#         b = data.observations_table[keys[o]][()][start:end]\n",
    "#         try: # all varibales with different shape won't work here\n",
    "#             sa, sb = zip(*sorted(zip(a, b)))\n",
    "#             helpvar.append(sb)\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#     for j in range(len(allvars)):\n",
    "#         for k in range(len(sa)):\n",
    "#             if sa[k] == allvars[j]:\n",
    "#                 for m in range(len(helpvar)):\n",
    "#                     try: # all varibales with different shape won't work here\n",
    "#                         ov[m][j].append(helpvar[m][k])\n",
    "#                     except:\n",
    "#                         pass\n",
    "#         recordindices[j].append(len(ov[0][j]))\n",
    "#         recordtimestamps[j].append(rt[i])\n",
    "        \n",
    "# lenadd = 0\n",
    "# for i in range(len(recordindices)):\n",
    "#     recordindices[i] = np.asarray(np.append([0], recordindices[i][:-1])) + lenadd\n",
    "#     lenadd += len(variables[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
