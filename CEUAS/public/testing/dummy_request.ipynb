{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no config found\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import cProfile\n",
    "import glob\n",
    "import gzip\n",
    "import json\n",
    "import os \n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import zipfile\n",
    "from datetime import date\n",
    "\n",
    "import cdsapi\n",
    "import h5py\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib3\n",
    "import xarray as xr\n",
    "import ydata_profiling\n",
    "\n",
    "sys.path.append(os.getcwd() + \"/../cds-backend/code/\")\n",
    "import cds_eua4 as eua\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.insert(0, os.getcwd() + \"/../resort/rasotools-master/\")\n",
    "import matplotlib\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as maplt\n",
    "import seaborn\n",
    "\n",
    "import rasotools\n",
    "\n",
    "matplotlib.rcParams.update({\"font.size\": 20})\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "font = {\n",
    "    \"family\": \"normal\",\n",
    "    # 'weight' : 'bold',\n",
    "    \"size\": 22,\n",
    "}\n",
    "matplotlib.rc(\"font\", **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/users/staff/uvoggenberger/scratch/hug/config_v11/active.json\") as json_file:\n",
    "    active_v11 = json.load(json_file)\n",
    "sids = list(active_v11.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0-20000-0-59431', '0-20300-0-59431']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s for s in sids if \"59431\" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_to_datetime(seconds, ref=\"1900-01-01\"):\n",
    "    \"\"\"from seconds to datetime64\"\"\"\n",
    "    seconds = np.asarray(seconds)\n",
    "    return pd.to_datetime(seconds, unit=\"s\", origin=ref, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22.780000686645508, 108.55000305175781,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1978-12-31 23:00:00')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seconds_to_datetime(2492982000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rs_drift\n",
    "from rs_drift import drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "trajectory() missing 6 required positional arguments: 'lat', 'lon', 'u', 'v', 'pressure', and 'temperature'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrs_drift\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrift\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrajectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: trajectory() missing 6 required positional arguments: 'lat', 'lon', 'u', 'v', 'pressure', and 'temperature'"
     ]
    }
   ],
   "source": [
    "rs_drift.drift.trajectory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "\n",
    "def datetime_to_seconds(dates, ref=\"1900-01-01T00:00:00\"):\n",
    "    \"\"\"from datetime64 to seconds since 1900-01-01 00:00:00\"\"\"\n",
    "    return ((dates - np.datetime64(ref)) / np.timedelta64(1, \"s\")).astype(np.int64)\n",
    "\n",
    "\n",
    "def seconds_to_datetime(seconds, ref=\"1900-01-01\"):\n",
    "    \"\"\"from seconds to datetime64\"\"\"\n",
    "    seconds = np.asarray(seconds)\n",
    "    return pd.to_datetime(seconds, unit=\"s\", origin=ref, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/users/staff/uvoggenberger/scratch/hug/config_v9/active.json\") as json_file:\n",
    "    active_v9 = json.load(json_file)\n",
    "with open(\"/users/staff/uvoggenberger/scratch/hug/config_v11/active.json\") as json_file:\n",
    "    active_v11 = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>date_time</th>\n",
       "      <th>fg_depar</th>\n",
       "      <th>an_depar</th>\n",
       "      <th>latitude_displacement</th>\n",
       "      <th>longitude_displacement</th>\n",
       "      <th>RAOBCORE_bias_estimate</th>\n",
       "      <th>RASE_bias_estimate</th>\n",
       "      <th>RICH_bias_estimate</th>\n",
       "      <th>RISE_bias_estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>275.600006</td>\n",
       "      <td>86800.0</td>\n",
       "      <td>2016-10-13 23:00:00</td>\n",
       "      <td>0.701121</td>\n",
       "      <td>0.291900</td>\n",
       "      <td>0.042170</td>\n",
       "      <td>-0.044194</td>\n",
       "      <td>0.296366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.296366</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>279.000000</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>2016-10-13 23:00:00</td>\n",
       "      <td>-0.025871</td>\n",
       "      <td>-0.218117</td>\n",
       "      <td>0.023124</td>\n",
       "      <td>-0.028220</td>\n",
       "      <td>0.195295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.195295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>283.399994</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2016-10-13 23:00:00</td>\n",
       "      <td>0.669929</td>\n",
       "      <td>0.547652</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.066160</td>\n",
       "      <td>0.06616</td>\n",
       "      <td>0.066160</td>\n",
       "      <td>0.06616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>283.399994</td>\n",
       "      <td>100600.0</td>\n",
       "      <td>2016-10-13 23:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     temperature  pressure           date_time  fg_depar  an_depar  \\\n",
       "169   275.600006   86800.0 2016-10-13 23:00:00  0.701121  0.291900   \n",
       "170   279.000000   92500.0 2016-10-13 23:00:00 -0.025871 -0.218117   \n",
       "171   283.399994  100000.0 2016-10-13 23:00:00  0.669929  0.547652   \n",
       "172   283.399994  100600.0 2016-10-13 23:00:00       NaN       NaN   \n",
       "\n",
       "     latitude_displacement  longitude_displacement  RAOBCORE_bias_estimate  \\\n",
       "169               0.042170               -0.044194                0.296366   \n",
       "170               0.023124               -0.028220                0.195295   \n",
       "171               0.001225                0.000273                0.066160   \n",
       "172               0.000000                0.000000                     NaN   \n",
       "\n",
       "     RASE_bias_estimate  RICH_bias_estimate  RISE_bias_estimate  \n",
       "169                 NaN            0.296366                 NaN  \n",
       "170                 NaN            0.195295                 NaN  \n",
       "171             0.06616            0.066160             0.06616  \n",
       "172                 NaN                 NaN                 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "import glob\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def datetime_to_seconds(dates, ref=\"1900-01-01T00:00:00\"):\n",
    "    \"\"\"from datetime64 to seconds since 1900-01-01 00:00:00\"\"\"\n",
    "    return ((dates - np.datetime64(ref)) / np.timedelta64(1, \"s\")).astype(np.int64)\n",
    "\n",
    "def seconds_to_datetime(seconds, ref=\"1900-01-01\"):\n",
    "    \"\"\"from seconds to datetime64\"\"\"\n",
    "    seconds = np.asarray(seconds)\n",
    "    return pd.to_datetime(seconds, unit=\"s\", origin=ref, errors=\"coerce\")\n",
    "\n",
    "\n",
    "\n",
    "input_str = \"0401820161013230000\"\n",
    "date = (\n",
    "    str(input_str[5:9]) + \"-\" + str(input_str[9:11]) + \"-\" + str(input_str[11:13])\n",
    ")  # + ' ' + str(input_str[13:15]) + ':' + str(input_str[15:17])\n",
    "\n",
    "\"\"\" New Files will go online in a few days. \"\"\"\n",
    "file_dir = glob.glob('/mnt/users/scratch/leo/scratch/converted_v11/long/*'+str(input_str[:5])+'*_CEUAS_merged_v1.nc')[0]\n",
    "\"\"\" For now use the old data: \"\"\"\n",
    "# file_dir = glob.glob(\"/mnt/users/scratch/leo/scratch/converted_v9/*\" + str(input_str[:5]) + \"*_CEUAS_merged_v1.nc\")[0]\n",
    "\n",
    "# create output dict\n",
    "output = {}\n",
    "# open file\n",
    "with h5py.File(\n",
    "    file_dir,\n",
    "    \"r\",\n",
    ") as file:\n",
    "    # indexing\n",
    "    dt_from = datetime_to_seconds(np.datetime64(date))\n",
    "    dt_to = dt_from + 48 * 60 * 60\n",
    "    rts = file[\"recordindices\"][\"recordtimestamp\"][:]\n",
    "    idx = np.where(np.logical_and((rts >= dt_from), (rts <= dt_to)))[0]\n",
    "    idx_d = file[\"recordindices\"][\"126\"][idx]\n",
    "\n",
    "    #reading data\n",
    "    output[\"temperature\"] = file[\"observations_table\"][\"observation_value\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"pressure\"] = file[\"observations_table\"][\"z_coordinate\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"date_time\"] = seconds_to_datetime(\n",
    "        file[\"observations_table\"][\"date_time\"][idx_d[0] : idx_d[-1]]\n",
    "    )\n",
    "    output[\"fg_depar\"] = file[\"era5fb\"][\"fg_depar@body\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"an_depar\"] = file[\"era5fb\"][\"an_depar@body\"][idx_d[0] : idx_d[-1]]\n",
    "    \n",
    "    output[\"latitude_displacement\"] = file[\"advanced_homogenisation\"][\"latitude_displacement\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"longitude_displacement\"] = file[\"advanced_homogenisation\"][\"longitude_displacement\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"RAOBCORE_bias_estimate\"] = file[\"advanced_homogenisation\"][\"RAOBCORE_bias_estimate\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"RASE_bias_estimate\"] = file[\"advanced_homogenisation\"][\"RASE_bias_estimate\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"RICH_bias_estimate\"] = file[\"advanced_homogenisation\"][\"RICH_bias_estimate\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"RISE_bias_estimate\"] = file[\"advanced_homogenisation\"][\"RISE_bias_estimate\"][idx_d[0] : idx_d[-1]]\n",
    "\n",
    "# put output to file\n",
    "df = pd.DataFrame.from_dict(output)\n",
    "# select only the chosen hour -> take care, sometimes it's not a fixed time, it may update with each ascent level\n",
    "# skip to investigate the data manually \n",
    "df = df[df.date_time.dt.hour == int(input_str[13:15])]\n",
    "display(df)\n",
    "# df.to_csv(\"test_file_\"+str(input_str)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>date_time</th>\n",
       "      <th>fg_depar</th>\n",
       "      <th>an_depar</th>\n",
       "      <th>latitude_displacement</th>\n",
       "      <th>longitude_displacement</th>\n",
       "      <th>RAOBCORE_bias_estimate</th>\n",
       "      <th>RASE_bias_estimate</th>\n",
       "      <th>RICH_bias_estimate</th>\n",
       "      <th>RISE_bias_estimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>275.600006</td>\n",
       "      <td>86800.0</td>\n",
       "      <td>2016-10-13 23:00:00</td>\n",
       "      <td>0.701121</td>\n",
       "      <td>0.291900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>279.000000</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>2016-10-13 23:00:00</td>\n",
       "      <td>-0.025871</td>\n",
       "      <td>-0.218117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.097980</td>\n",
       "      <td>-0.097980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>283.399994</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>2016-10-13 23:00:00</td>\n",
       "      <td>0.669929</td>\n",
       "      <td>0.547652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-6.315786</td>\n",
       "      <td>-6.315786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     temperature  pressure           date_time  fg_depar  an_depar  \\\n",
       "165   275.600006   86800.0 2016-10-13 23:00:00  0.701121  0.291900   \n",
       "166   279.000000   92500.0 2016-10-13 23:00:00 -0.025871 -0.218117   \n",
       "167   283.399994  100000.0 2016-10-13 23:00:00  0.669929  0.547652   \n",
       "\n",
       "     latitude_displacement  longitude_displacement  RAOBCORE_bias_estimate  \\\n",
       "165                    NaN                     NaN                     NaN   \n",
       "166                    NaN                     NaN                    -0.0   \n",
       "167                    NaN                     NaN                    -0.0   \n",
       "\n",
       "     RASE_bias_estimate  RICH_bias_estimate  RISE_bias_estimate  \n",
       "165                 NaN                 NaN                 NaN  \n",
       "166                -0.0           -0.097980           -0.097980  \n",
       "167                -0.0           -6.315786           -6.315786  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "import glob\n",
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def datetime_to_seconds(dates, ref=\"1900-01-01T00:00:00\"):\n",
    "    \"\"\"from datetime64 to seconds since 1900-01-01 00:00:00\"\"\"\n",
    "    return ((dates - np.datetime64(ref)) / np.timedelta64(1, \"s\")).astype(np.int64)\n",
    "\n",
    "def seconds_to_datetime(seconds, ref=\"1900-01-01\"):\n",
    "    \"\"\"from seconds to datetime64\"\"\"\n",
    "    seconds = np.asarray(seconds)\n",
    "    return pd.to_datetime(seconds, unit=\"s\", origin=ref, errors=\"coerce\")\n",
    "\n",
    "\n",
    "\n",
    "input_str = \"0401820161013230000\"\n",
    "date = (\n",
    "    str(input_str[5:9]) + \"-\" + str(input_str[9:11]) + \"-\" + str(input_str[11:13])\n",
    ")  # + ' ' + str(input_str[13:15]) + ':' + str(input_str[15:17])\n",
    "\n",
    "\"\"\" New Files will go online in a few days. \"\"\"\n",
    "# file_dir = glob.glob('/mnt/users/scratch/leo/scratch/converted_v11/long/*'+str(input_str[:5])+'*_CEUAS_merged_v1.nc')[0]\n",
    "\"\"\" For now use the old data: \"\"\"\n",
    "file_dir = glob.glob(\"/mnt/users/scratch/leo/scratch/converted_v9/*\" + str(input_str[:5]) + \"*_CEUAS_merged_v1.nc\")[0]\n",
    "\n",
    "# create output dict\n",
    "output = {}\n",
    "# open file\n",
    "with h5py.File(\n",
    "    file_dir,\n",
    "    \"r\",\n",
    ") as file:\n",
    "    # indexing\n",
    "    dt_from = datetime_to_seconds(np.datetime64(date))\n",
    "    dt_to = dt_from + 48 * 60 * 60\n",
    "    rts = file[\"recordindices\"][\"recordtimestamp\"][:]\n",
    "    idx = np.where(np.logical_and((rts >= dt_from), (rts <= dt_to)))[0]\n",
    "    idx_d = file[\"recordindices\"][\"126\"][idx]\n",
    "\n",
    "    #reading data\n",
    "    output[\"temperature\"] = file[\"observations_table\"][\"observation_value\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"pressure\"] = file[\"observations_table\"][\"z_coordinate\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"date_time\"] = seconds_to_datetime(\n",
    "        file[\"observations_table\"][\"date_time\"][idx_d[0] : idx_d[-1]]\n",
    "    )\n",
    "    output[\"fg_depar\"] = file[\"era5fb\"][\"fg_depar@body\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"an_depar\"] = file[\"era5fb\"][\"an_depar@body\"][idx_d[0] : idx_d[-1]]\n",
    "    \n",
    "    output[\"latitude_displacement\"] = file[\"advanced_homogenisation\"][\"latitude_displacement\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"longitude_displacement\"] = file[\"advanced_homogenisation\"][\"longitude_displacement\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"RAOBCORE_bias_estimate\"] = file[\"advanced_homogenisation\"][\"RAOBCORE_bias_estimate\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"RASE_bias_estimate\"] = file[\"advanced_homogenisation\"][\"RASE_bias_estimate\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"RICH_bias_estimate\"] = file[\"advanced_homogenisation\"][\"RICH_bias_estimate\"][idx_d[0] : idx_d[-1]]\n",
    "    output[\"RISE_bias_estimate\"] = file[\"advanced_homogenisation\"][\"RISE_bias_estimate\"][idx_d[0] : idx_d[-1]]\n",
    "\n",
    "# put output to file\n",
    "df = pd.DataFrame.from_dict(output)\n",
    "# select only the chosen hour -> take care, sometimes it's not a fixed time, it may update with each ascent level\n",
    "# skip to investigate the data manually \n",
    "df = df[df.date_time.dt.hour == int(input_str[13:15])]\n",
    "display(df)\n",
    "# df.to_csv(\"test_file_\"+str(input_str)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(input_str[13:15])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDS API\n",
    "### Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    {\n",
    "        \"day\": [\"1\"],\n",
    "        \"format\": \"csv\",\n",
    "        \"month\": \"7\",\n",
    "        \"statid\": \"11035\",\n",
    "        \"pressure_level\": [\"100\"],  # USE hPa for CDSAPI! Pa everywhere else!\n",
    "        \"observed_variable\": [\"air_temperature\"],\n",
    "        \"year\": \"1997\",\n",
    "        \"optional\": [\"obs_minus_bg\", \"obs_minus_an\", \"bias_estimate\"],\n",
    "    },\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['temperature', 'air_temperature',\n",
    " 'u_component_of_wind', 'eastward_wind_speed',\n",
    " 'v_component_of_wind', 'northward_wind_speed',\n",
    " 'wind_speed',\n",
    " 'wind_direction', 'wind_from_direction',\n",
    " 'relative_humidity',\n",
    " 'specific_humidity',\n",
    " 'dew_point_temperature',\n",
    " 'geopotential', 'geopotential_height',\n",
    " 'dew_point_depression', 'dewpoint_departure','dewpoint_depression', 'dew_point_departure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    }
   ],
   "source": [
    "import cdsapi\n",
    "\n",
    "c = cdsapi.Client(\n",
    "    url=\"https://cds-test.copernicus-climate.eu/api/v2\",\n",
    "    key=\"2548:a32dce56-b04a-42fc-8fc3-a972f94772ad\",\n",
    "    progress=True,\n",
    "    retry_max=5,\n",
    ")\n",
    "r = c.retrieve(\n",
    "    \"insitu-comprehensive-upper-air-observation-network\",\n",
    "    {\n",
    "        # \"statid\": \"58666\",\n",
    "        \"observed_variable\": [\"air_temperature\", \"relative_humidity\", 'eastward_wind_speed', 'northward_wind_speed', 'geopotential'],\n",
    "        \"format\": \"csv\",\n",
    "        \"date\": [\"19820201\", \"19820231\"],\n",
    "        \"area\": [48,13,45.8,17.8],\n",
    "        # 45.8°N bis 48°N und 13°E bis 17.8°E.\n",
    "        # \"optional\": [\n",
    "        #     \"RISE_bias_estimate\",\n",
    "        #     \"RICH_bias_estimate\",\n",
    "        #     \"RASE_bias_estimate\",\n",
    "        #     \"RAOBCORE_bias_estimate\",\n",
    "        #     \"latitude_displacement\",\n",
    "        #     \"longitude_displacement\",\n",
    "        #     \"obs_minus_bg\",\n",
    "        #     \"obs_minus_an\",\n",
    "        # ],\n",
    "        \"dummy\": \"test1548741\",\n",
    "    },\n",
    "    target=\"download4.zip\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./tmp_heimo/CDS_CUON_output_file.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>report_id</th>\n",
       "      <th>station_id</th>\n",
       "      <th>z_coordinate</th>\n",
       "      <th>variable</th>\n",
       "      <th>observation_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1982-02-28 23:00:00+00</td>\n",
       "      <td>47.270000</td>\n",
       "      <td>16.629999</td>\n",
       "      <td>100000000051793</td>\n",
       "      <td>0-20000-0-12812</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>air_temperature</td>\n",
       "      <td>228.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1982-02-28 23:00:00+00</td>\n",
       "      <td>47.270000</td>\n",
       "      <td>16.629999</td>\n",
       "      <td>100000000051793</td>\n",
       "      <td>0-20000-0-12812</td>\n",
       "      <td>12900.0</td>\n",
       "      <td>air_temperature</td>\n",
       "      <td>229.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1982-02-28 23:00:00+00</td>\n",
       "      <td>47.270000</td>\n",
       "      <td>16.629999</td>\n",
       "      <td>100000000051793</td>\n",
       "      <td>0-20000-0-12812</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>air_temperature</td>\n",
       "      <td>230.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1982-02-28 23:00:00+00</td>\n",
       "      <td>47.270000</td>\n",
       "      <td>16.629999</td>\n",
       "      <td>100000000051793</td>\n",
       "      <td>0-20000-0-12812</td>\n",
       "      <td>17500.0</td>\n",
       "      <td>air_temperature</td>\n",
       "      <td>230.699997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1982-02-28 23:00:00+00</td>\n",
       "      <td>47.270000</td>\n",
       "      <td>16.629999</td>\n",
       "      <td>100000000051793</td>\n",
       "      <td>0-20000-0-12812</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>air_temperature</td>\n",
       "      <td>221.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21751</th>\n",
       "      <td>1982-02-28 12:00:00+00</td>\n",
       "      <td>46.029999</td>\n",
       "      <td>13.180000</td>\n",
       "      <td>100000000037908</td>\n",
       "      <td>0-20001-0-16045</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>relative_humidity</td>\n",
       "      <td>0.582795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21752</th>\n",
       "      <td>1982-02-28 12:00:00+00</td>\n",
       "      <td>46.029999</td>\n",
       "      <td>13.180000</td>\n",
       "      <td>100000000037908</td>\n",
       "      <td>0-20001-0-16045</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>relative_humidity</td>\n",
       "      <td>0.209468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21753</th>\n",
       "      <td>1982-02-28 12:00:00+00</td>\n",
       "      <td>46.029999</td>\n",
       "      <td>13.180000</td>\n",
       "      <td>100000000037908</td>\n",
       "      <td>0-20001-0-16045</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>relative_humidity</td>\n",
       "      <td>0.208628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21754</th>\n",
       "      <td>1982-02-28 12:00:00+00</td>\n",
       "      <td>46.029999</td>\n",
       "      <td>13.180000</td>\n",
       "      <td>100000000037908</td>\n",
       "      <td>0-20001-0-16045</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>relative_humidity</td>\n",
       "      <td>0.452413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21755</th>\n",
       "      <td>1982-02-28 12:00:00+00</td>\n",
       "      <td>46.029999</td>\n",
       "      <td>13.180000</td>\n",
       "      <td>100000000037908</td>\n",
       "      <td>0-20001-0-16045</td>\n",
       "      <td>100700.0</td>\n",
       "      <td>relative_humidity</td>\n",
       "      <td>0.423610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21756 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date_time   latitude  longitude        report_id  \\\n",
       "0      1982-02-28 23:00:00+00  47.270000  16.629999  100000000051793   \n",
       "1      1982-02-28 23:00:00+00  47.270000  16.629999  100000000051793   \n",
       "2      1982-02-28 23:00:00+00  47.270000  16.629999  100000000051793   \n",
       "3      1982-02-28 23:00:00+00  47.270000  16.629999  100000000051793   \n",
       "4      1982-02-28 23:00:00+00  47.270000  16.629999  100000000051793   \n",
       "...                       ...        ...        ...              ...   \n",
       "21751  1982-02-28 12:00:00+00  46.029999  13.180000  100000000037908   \n",
       "21752  1982-02-28 12:00:00+00  46.029999  13.180000  100000000037908   \n",
       "21753  1982-02-28 12:00:00+00  46.029999  13.180000  100000000037908   \n",
       "21754  1982-02-28 12:00:00+00  46.029999  13.180000  100000000037908   \n",
       "21755  1982-02-28 12:00:00+00  46.029999  13.180000  100000000037908   \n",
       "\n",
       "            station_id  z_coordinate           variable  observation_value  \n",
       "0      0-20000-0-12812       10000.0    air_temperature         228.300003  \n",
       "1      0-20000-0-12812       12900.0    air_temperature         229.500000  \n",
       "2      0-20000-0-12812       15000.0    air_temperature         230.100006  \n",
       "3      0-20000-0-12812       17500.0    air_temperature         230.699997  \n",
       "4      0-20000-0-12812       20000.0    air_temperature         221.500000  \n",
       "...                ...           ...                ...                ...  \n",
       "21751  0-20001-0-16045       50000.0  relative_humidity           0.582795  \n",
       "21752  0-20001-0-16045       70000.0  relative_humidity           0.209468  \n",
       "21753  0-20001-0-16045       85000.0  relative_humidity           0.208628  \n",
       "21754  0-20001-0-16045      100000.0  relative_humidity           0.452413  \n",
       "21755  0-20001-0-16045      100700.0  relative_humidity           0.423610  \n",
       "\n",
       "[21756 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tempdir = \"./tmp_heimo/\"\n",
    "delete_dl = True\n",
    "with zipfile.ZipFile(\"download4.zip\", \"r\") as zip_ref:\n",
    "    try:\n",
    "        os.mkdir(tempdir)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    zip_ref.extractall(tempdir)\n",
    "\n",
    "for i in glob.glob(tempdir + \"*\"):\n",
    "    print(i)\n",
    "    df = pd.read_csv(i, header=14)\n",
    "    display(df)\n",
    "\n",
    "#if delete_dl:\n",
    "#    shutil.rmtree(tempdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0-20000-0-12812', '0-20000-0-14240', '0-20000-0-16040',\n",
       "       '0-20001-0-16045'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.station_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EUA Request\n",
    "### Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_v11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_str = '0401820161013230000'\n",
    "# file_dir = glob.glob('/mnt/users/scratch/leo/scratch/converted_v11/long/*'+str(input_str[:5])+'*_CEUAS_merged_v1.nc')[0]\n",
    "# date = str(input_str[5:9]) + '-' + str(input_str[9:11]) + '-' + str(input_str[11:13]) + ' ' + str(input_str[13:15]) + ':' + str(input_str[15:17])\n",
    "\n",
    "rq = {\n",
    "    \"statid\": \"33791\",\n",
    "    \"date\": [\"19800601\"],\n",
    "    \"variable\": [\"relative_humidity\"],\n",
    "    \"format\": \"nc\",\n",
    "    # \"cdm\": [\"station_configuration/platform_type\"],\n",
    "    # \"cdm\": [\"source_configuration/source_file\"],\n",
    "    # \"dummy\": \"14854ad8add478asdopf48a4s48d45\",\n",
    "}\n",
    "df_v11 = eua.vm_request_wrapper(rq, overwrite=True)# , vm_url=\"http://127.0.0.1:8007\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hur</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>obs</th>\n",
       "      <th>plev</th>\n",
       "      <th>report_id</th>\n",
       "      <th>station_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.486059</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.459986</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568539</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.469204</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.469838</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>50200.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.477378</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>55100.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.616930</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>57300.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.606766</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.506946</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.386177</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>81700.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.270402</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>84000.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.292334</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.563062</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>93400.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.634816</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>96200.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.636171</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>99300.0</td>\n",
       "      <td>100000000001081</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.603253</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>74100.0</td>\n",
       "      <td>100000000001083</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.739338</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>76600.0</td>\n",
       "      <td>100000000001083</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.390003</td>\n",
       "      <td>47.93</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>0</td>\n",
       "      <td>99600.0</td>\n",
       "      <td>100000000001083</td>\n",
       "      <td>/mnt/scratch/sc</td>\n",
       "      <td>1980-06-01 12:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         hur    lat        lon  obs     plev        report_id  \\\n",
       "0   0.486059  47.93  33.330002    0  25000.0  100000000001081   \n",
       "1   0.459986  47.93  33.330002    0  30000.0  100000000001081   \n",
       "2   0.568539  47.93  33.330002    0  40000.0  100000000001081   \n",
       "3   0.469204  47.93  33.330002    0  50000.0  100000000001081   \n",
       "4   0.469838  47.93  33.330002    0  50200.0  100000000001081   \n",
       "5   0.477378  47.93  33.330002    0  55100.0  100000000001081   \n",
       "6   0.616930  47.93  33.330002    0  57300.0  100000000001081   \n",
       "7   0.606766  47.93  33.330002    0  70000.0  100000000001081   \n",
       "8   0.506946  47.93  33.330002    0  79000.0  100000000001081   \n",
       "9   0.386177  47.93  33.330002    0  81700.0  100000000001081   \n",
       "10  0.270402  47.93  33.330002    0  84000.0  100000000001081   \n",
       "11  0.292334  47.93  33.330002    0  85000.0  100000000001081   \n",
       "12  0.563062  47.93  33.330002    0  93400.0  100000000001081   \n",
       "13  0.634816  47.93  33.330002    0  96200.0  100000000001081   \n",
       "14  0.636171  47.93  33.330002    0  99300.0  100000000001081   \n",
       "15  0.603253  47.93  33.330002    0  74100.0  100000000001083   \n",
       "16  0.739338  47.93  33.330002    0  76600.0  100000000001083   \n",
       "17  0.390003  47.93  33.330002    0  99600.0  100000000001083   \n",
       "\n",
       "         station_id                time  \n",
       "0   /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "1   /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "2   /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "3   /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "4   /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "5   /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "6   /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "7   /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "8   /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "9   /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "10  /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "11  /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "12  /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "13  /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "14  /mnt/scratch/sc 1980-06-01 00:00:00  \n",
       "15  /mnt/scratch/sc 1980-06-01 12:00:00  \n",
       "16  /mnt/scratch/sc 1980-06-01 12:00:00  \n",
       "17  /mnt/scratch/sc 1980-06-01 12:00:00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v11.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dest_0-20000-0-33791_air_temperature\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dest_20999-coordinate-orphan_era5.conv.??????.33791.txt.gz_air_temperature\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in df_v11.keys():\n",
    "    print(i)\n",
    "    display(df_v11[i].station_configuration.platform_type[:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CDMDatasetList' object has no attribute 'to_dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_v11\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dataframe\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CDMDatasetList' object has no attribute 'to_dataframe'"
     ]
    }
   ],
   "source": [
    "df_v11.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825\n",
      "825\n",
      "825\n",
      "865\n"
     ]
    }
   ],
   "source": [
    "print(len(glob.glob(\"./test_dest/*relative_humidity.nc\")))\n",
    "print(len(glob.glob(\"./test_dest/*specific_humidity.nc\")))\n",
    "print(len(glob.glob(\"./test_dest/*dew_point_temperature.nc\")))\n",
    "print(len(glob.glob(\"./test_dest/*air_temperature.nc\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1982-05-01T06:00:00.000000000', '1982-05-02T06:00:00.000000000',\n",
       "       '1982-05-03T06:00:00.000000000', '1982-05-04T06:00:00.000000000',\n",
       "       '1982-05-05T06:00:00.000000000', '1982-05-06T06:00:00.000000000',\n",
       "       '1982-05-07T06:00:00.000000000', '1982-05-08T06:00:00.000000000',\n",
       "       '1982-05-09T06:00:00.000000000', '1982-05-10T06:00:00.000000000',\n",
       "       '1982-05-11T06:00:00.000000000', '1982-05-12T06:00:00.000000000',\n",
       "       '1982-05-13T06:00:00.000000000', '1982-05-14T06:00:00.000000000',\n",
       "       '1982-05-15T06:00:00.000000000', '1982-05-16T06:00:00.000000000',\n",
       "       '1982-05-17T06:00:00.000000000', '1982-05-18T06:00:00.000000000',\n",
       "       '1982-05-19T06:00:00.000000000', '1982-05-20T06:00:00.000000000',\n",
       "       '1982-05-21T06:00:00.000000000', '1982-05-22T06:00:00.000000000',\n",
       "       '1982-05-23T06:00:00.000000000', '1982-05-24T06:00:00.000000000',\n",
       "       '1982-05-25T06:00:00.000000000', '1982-05-26T06:00:00.000000000',\n",
       "       '1982-05-27T06:00:00.000000000', '1982-05-28T06:00:00.000000000',\n",
       "       '1982-05-29T06:00:00.000000000', '1982-05-30T06:00:00.000000000',\n",
       "       '1982-05-31T06:00:00.000000000'], dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.time.dt.month == 5].time.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980 21\n",
      "1981 0\n",
      "1982 7758\n",
      "1983 0\n",
      "1984 0\n",
      "1985 0\n",
      "1986 3622\n",
      "1987 6418\n",
      "1988 8145\n",
      "1989 7649\n",
      "1990 7811\n",
      "1991 7849\n",
      "1992 7677\n",
      "1993 8374\n",
      "1994 8756\n",
      "1995 12320\n",
      "1996 12378\n",
      "1997 12072\n",
      "1998 11730\n",
      "1999 12308\n",
      "2000 21619\n",
      "2001 21838\n",
      "2002 18553\n",
      "2003 15216\n",
      "2004 13915\n",
      "2005 13039\n",
      "2006 14068\n",
      "2007 13938\n",
      "2008 14100\n",
      "2009 13776\n",
      "2010 13823\n",
      "2011 14011\n",
      "2012 13632\n",
      "2013 13595\n",
      "2014 20765\n",
      "2015 25892\n",
      "2016 27825\n",
      "2017 619163\n",
      "2018 1256949\n",
      "2019 1312221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1980, 2024):\n",
    "    print(i, len(df[df.time.dt.year == i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remote VM machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rq = {\n",
    "    \"statid\": [\"06610\"],\n",
    "    \"variable\": [\"air_temperature\"],\n",
    "    \"date\": \"20001231-20010101\",\n",
    "    \"format\": \"nc\",\n",
    "    \"pressure_level\": [\"85000\"],\n",
    "}\n",
    "df_v11 = eua.vm_request_wrapper(rq, overwrite=True)  # , vm_url=\"http://127.0.0.1:8009\")\n",
    "df = df_v11.to_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi file output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-20000-0-10184\n",
      "0-20000-0-10184_CEUAS_merged_v1.nc            100% 4966MB  20.5MB/s   04:01    \n",
      "0-20000-0-10488\n",
      "0-20000-0-10488_CEUAS_merged_v1.nc            100%  275MB  17.3MB/s   00:15    \n",
      "0-20000-0-10771\n",
      "0-20000-0-10771_CEUAS_merged_v1.nc            100% 8326MB  16.7MB/s   08:19    \n",
      "0-20000-0-10868\n",
      "0-20000-0-10868_CEUAS_merged_v1.nc            100% 4873MB  12.8MB/s   06:21    \n",
      "0-20000-0-11010\n",
      "0-20000-0-11010_CEUAS_merged_v1.nc            100% 1357MB  18.4MB/s   01:13    \n",
      "0-20000-0-11120\n",
      "0-20000-0-11120_CEUAS_merged_v1.nc            100% 1540MB  24.0MB/s   01:04    \n",
      "0-20000-0-11240\n",
      "0-20000-0-11240_CEUAS_merged_v1.nc            100% 1378MB  23.0MB/s   00:59    \n",
      "0-20000-0-11520\n",
      "0-20000-0-11520_CEUAS_merged_v1.nc            100% 5760MB  15.0MB/s   06:24    \n",
      "0-20000-0-11723\n",
      "0-20000-0-11723_CEUAS_merged_v1.nc            100%   39MB  50.3MB/s   00:00    \n",
      "0-20000-0-11952\n",
      "0-20000-0-11952_CEUAS_merged_v1.nc            100% 5299MB  17.3MB/s   05:05    \n",
      "0-20000-0-12120\n",
      "0-20000-0-12120_CEUAS_merged_v1.nc            100% 3345MB  20.7MB/s   02:41    \n",
      "0-20000-0-12374\n",
      "0-20000-0-12374_CEUAS_merged_v1.nc            100% 4089MB  27.0MB/s   02:31    \n",
      "0-20000-0-12425\n",
      "0-20000-0-12425_CEUAS_merged_v1.nc            100% 3356MB  15.1MB/s   03:42    \n",
      "0-20000-0-12843\n",
      "0-20000-0-12843_CEUAS_merged_v1.nc            100% 2644MB  25.7MB/s   01:43    \n",
      "0-20000-0-12982\n",
      "0-20000-0-12982_CEUAS_merged_v1.nc            100% 1168MB  31.1MB/s   00:37    \n",
      "0-20000-0-14015\n",
      "0-20000-0-14015_CEUAS_merged_v1.nc            100%  938MB  83.8MB/s   00:11    \n",
      "0-20000-0-14240\n",
      "0-20000-0-14240_CEUAS_merged_v1.nc            100%  421MB  71.1MB/s   00:05    \n",
      "0-20000-0-15120\n",
      "0-20000-0-15120_CEUAS_merged_v1.nc            100%  298MB   5.6MB/s   00:52    \n",
      "0-20000-0-33631\n",
      "0-20000-0-33631_CEUAS_merged_v1.nc            100%  201MB  12.2MB/s   00:16    \n",
      "0-20001-0-10393\n",
      "0-20001-0-10393_CEUAS_merged_v1.nc            100%   11GB   7.8MB/s   25:00    \n",
      "0-20001-0-10548\n",
      "0-20001-0-10548_CEUAS_merged_v1.nc            100% 5026MB  23.0MB/s   03:38    \n",
      "0-20001-0-11035\n",
      "0-20001-0-11035_CEUAS_merged_v1.nc            100% 2192MB  80.9MB/s   00:27    \n",
      "0-20001-0-16045\n",
      "0-20001-0-16045_CEUAS_merged_v1.nc            100% 4819MB  16.0MB/s   05:01    \n"
     ]
    }
   ],
   "source": [
    "rq = {\n",
    "    # \"statid\": [\"72520\"],\n",
    "    \"area\": [55, 10, 45, 25],\n",
    "    \"variable\": [\"air_temperature\"],#[\"northward_wind_speed\", \"eastward_wind_speed\"],\n",
    "    # \"optional\": [\"wind_bias_estimate\"],\n",
    "    \"date\": \"20000101-20000101\",\n",
    "    \"format\": \"nc\",\n",
    "}\n",
    "df_v11 = eua.vm_request_wrapper(rq)  # , overwrite=True, vm_url='http://127.0.0.1:8009')\n",
    "for i in df_v11:\n",
    "    stat = i.split(\"_air_temperature\")[0].split(\"dest_\")[-1]\n",
    "    stat = glob.glob('/mnt/users/scratch/leo/scratch/converted_v11/long/*'+stat+'*v1.nc')[0]\n",
    "    print(i.split(\"_air_temperature\")[0].split(\"dest_\")[-1])\n",
    "    !scp {stat} sis@136.156.154.104:/data/private/v1.10_test/bbox/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EUA CDM\n",
    "### File Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File: <HDF5 file \"0-20001-0-53845_CEUAS_merged_v1.nc\" (mode r)>\n",
       "Filesize: 533.71 MB\n",
       "Filename: /users/staff/uvoggenberger/scratch/converted_v12/0-20001-0-53845_CEUAS_merged_v1.nc\n",
       "(G)roups/(V)ariables: \n",
       "\n",
       " - G | advanced_homogenisation______________________ : : 11\n",
       " - G | advanced_uncertainty_________________________ : : 9\n",
       " - G | crs__________________________________________ : : 5\n",
       " - G | era5fb_______________________________________ : : 72\n",
       " - G | header_table_________________________________ : : 56\n",
       " - G | observations_table___________________________ : : 51\n",
       " - G | observed_variable____________________________ : : 10\n",
       " - G | recordindices________________________________ : : 13\n",
       " - G | sensor_configuration_________________________ : : 13\n",
       " - G | source_configuration_________________________ : : 3\n",
       " - G | station_configuration________________________ : : 48\n",
       " - G | station_configuration_codes__________________ : : 8\n",
       " - G | station_type_________________________________ : : 5\n",
       " - G | units________________________________________ : : 7\n",
       " - G | z_coordinate_type____________________________ : : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "source_configuration:\n",
       "\n",
       "index_____________________________________________ : : (49589,)\n",
       "source_file_______________________________________ : : (49589, 70)\n",
       "string70__________________________________________ : : (70,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "observations_table:\n",
       "\n",
       "adjustment_id_____________________________________ : : (9246959,)\n",
       "advanced_assimilation_feedback____________________ : : (9246959,)\n",
       "advanced_homogenisation___________________________ : : (9246959,)\n",
       "advanced_qc_______________________________________ : : (9246959,)\n",
       "advanced_uncertainty______________________________ : : (9246959,)\n",
       "bbox_max_latitude_________________________________ : : (9246959,)\n",
       "bbox_max_longitude________________________________ : : (9246959,)\n",
       "bbox_min_latitude_________________________________ : : (9246959,)\n",
       "bbox_min_longitude________________________________ : : (9246959,)\n",
       "code_table________________________________________ : : (9246959,)\n",
       "conversion_flag___________________________________ : : (9246959,)\n",
       "conversion_method_________________________________ : : (9246959,)\n",
       "crs_______________________________________________ : : (9246959,)\n",
       "data_policy_licence_______________________________ : : (9246959,)\n",
       "date_time_________________________________________ : : (9246959,)\n",
       "date_time_meaning_________________________________ : : (9246959,)\n",
       "exposure_of_sensor________________________________ : : (9246959,)\n",
       "index_____________________________________________ : : (9246959,)\n",
       "latitude__________________________________________ : : (9246959,)\n",
       "location_method___________________________________ : : (9246959,)\n",
       "location_precision________________________________ : : (9246959,)\n",
       "longitude_________________________________________ : : (9246959,)\n",
       "numerical_precision_______________________________ : : (9246959,)\n",
       "observation_duration______________________________ : : (9246959,)\n",
       "observation_height_above_station_surface__________ : : (9246959,)\n",
       "observation_id____________________________________ : : (9246959, 21)\n",
       "observation_value_________________________________ : : (9246959,)\n",
       "observed_variable_________________________________ : : (9246959,)\n",
       "original_code_table_______________________________ : : (9246959,)\n",
       "original_precision________________________________ : : (9246959,)\n",
       "original_units____________________________________ : : (9246959,)\n",
       "original_value____________________________________ : : (9246959,)\n",
       "processing_level__________________________________ : : (9246959,)\n",
       "quality_flag______________________________________ : : (9246959,)\n",
       "report_id_________________________________________ : : (9246959, 21)\n",
       "secondary_value___________________________________ : : (9246959,)\n",
       "secondary_variable________________________________ : : (9246959,)\n",
       "sensor_automation_status__________________________ : : (9246959,)\n",
       "sensor_id_________________________________________ : : (9246959, 4)\n",
       "source_id_________________________________________ : : (9246959, 9)\n",
       "spatial_representativeness________________________ : : (9246959,)\n",
       "station_elevation_________________________________ : : (9246959,)\n",
       "string21__________________________________________ : : (20,)\n",
       "string4___________________________________________ : : (4,)\n",
       "string9___________________________________________ : : (9,)\n",
       "traceability______________________________________ : : (9246959,)\n",
       "units_____________________________________________ : : (9246959,)\n",
       "value_significance________________________________ : : (9246959,)\n",
       "z_coordinate______________________________________ : : (9246959,)\n",
       "z_coordinate_method_______________________________ : : (9246959,)\n",
       "z_coordinate_type_________________________________ : : (9246959,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 49586, 49587, 49588])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfile = glob.glob('/users/staff/uvoggenberger/scratch/converted_v12/0-20001-0-53845_CEUAS_merged_v1.nc')[0]\n",
    "\n",
    "with eua.CDMDataset(\n",
    "    gfile\n",
    ") as file:\n",
    "    display(file)\n",
    "    # display(file[\"header_table\"]['report_id'][:])\n",
    "    display(file[\"source_configuration\"])\n",
    "    display(file[\"observations_table\"])\n",
    "    rn = file[\"station_configuration\"][\"record_number\"][:]\n",
    "    display(rn)\n",
    "len(np.unique(rn)) == len(rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File: <HDF5 file \"0-20001-0-11035_CEUAS_merged_v1.nc\" (mode r)>\n",
       "Filesize: 4632.25 MB\n",
       "Filename: /mnt/users/scratch/leo/scratch/converted_v11/long/0-20001-0-11035_CEUAS_merged_v1.nc\n",
       "(G)roups/(V)ariables: \n",
       "\n",
       " - G | advanced_homogenisation______________________ : : 11\n",
       " - G | crs__________________________________________ : : 5\n",
       " - G | era5fb_______________________________________ : : 72\n",
       " - G | header_table_________________________________ : : 56\n",
       " - G | observations_table___________________________ : : 51\n",
       " - G | observed_variable____________________________ : : 10\n",
       " - G | recordindices________________________________ : : 13\n",
       " - G | sensor_configuration_________________________ : : 13\n",
       " - G | source_configuration_________________________ : : 3\n",
       " - G | station_configuration________________________ : : 48\n",
       " - G | station_configuration_codes__________________ : : 8\n",
       " - G | station_type_________________________________ : : 5\n",
       " - G | units________________________________________ : : 7\n",
       " - G | z_coordinate_type____________________________ : : 5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "recordindices:\n",
       "\n",
       "0_________________________________________________ : : (121852,)\n",
       "106_______________________________________________ : : (121852,)\n",
       "107_______________________________________________ : : (121852,)\n",
       "117_______________________________________________ : : (121852,)\n",
       "126_______________________________________________ : : (121852,)\n",
       "137_______________________________________________ : : (121852,)\n",
       "138_______________________________________________ : : (121852,)\n",
       "139_______________________________________________ : : (121852,)\n",
       "140_______________________________________________ : : (121852,)\n",
       "34________________________________________________ : : (121852,)\n",
       "39________________________________________________ : : (121852,)\n",
       "index_____________________________________________ : : (121852,)\n",
       "recordtimestamp___________________________________ : : (121851,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "observations_table:\n",
       "\n",
       "adjustment_id_____________________________________ : : (129269984,)\n",
       "advanced_assimilation_feedback____________________ : : (129269984,)\n",
       "advanced_homogenisation___________________________ : : (129269984,)\n",
       "advanced_qc_______________________________________ : : (129269984,)\n",
       "advanced_uncertainty______________________________ : : (129269984,)\n",
       "bbox_max_latitude_________________________________ : : (129269984,)\n",
       "bbox_max_longitude________________________________ : : (129269984,)\n",
       "bbox_min_latitude_________________________________ : : (129269984,)\n",
       "bbox_min_longitude________________________________ : : (129269984,)\n",
       "code_table________________________________________ : : (129269984,)\n",
       "conversion_flag___________________________________ : : (129269984,)\n",
       "conversion_method_________________________________ : : (129269984,)\n",
       "crs_______________________________________________ : : (129269984,)\n",
       "data_policy_licence_______________________________ : : (129269984,)\n",
       "date_time_________________________________________ : : (129269984,)\n",
       "date_time_meaning_________________________________ : : (129269984,)\n",
       "exposure_of_sensor________________________________ : : (129269984,)\n",
       "index_____________________________________________ : : (129269984,)\n",
       "latitude__________________________________________ : : (129269984,)\n",
       "location_method___________________________________ : : (129269984,)\n",
       "location_precision________________________________ : : (129269984,)\n",
       "longitude_________________________________________ : : (129269984,)\n",
       "numerical_precision_______________________________ : : (129269984,)\n",
       "observation_duration______________________________ : : (129269984,)\n",
       "observation_height_above_station_surface__________ : : (129269984,)\n",
       "observation_id____________________________________ : : (129269984, 21)\n",
       "observation_value_________________________________ : : (129269984,)\n",
       "observed_variable_________________________________ : : (129269984,)\n",
       "original_code_table_______________________________ : : (129269984,)\n",
       "original_precision________________________________ : : (129269984,)\n",
       "original_units____________________________________ : : (129269984,)\n",
       "original_value____________________________________ : : (129269984,)\n",
       "processing_level__________________________________ : : (129269984,)\n",
       "quality_flag______________________________________ : : (129269984,)\n",
       "report_id_________________________________________ : : (129269984, 21)\n",
       "secondary_value___________________________________ : : (129269984,)\n",
       "secondary_variable________________________________ : : (129269984,)\n",
       "sensor_automation_status__________________________ : : (129269984,)\n",
       "sensor_id_________________________________________ : : (129269984, 4)\n",
       "source_id_________________________________________ : : (129269984, 6)\n",
       "spatial_representativeness________________________ : : (129269984,)\n",
       "station_elevation_________________________________ : : (129269984,)\n",
       "string21__________________________________________ : : (20,)\n",
       "string4___________________________________________ : : (4,)\n",
       "string6___________________________________________ : : (6,)\n",
       "traceability______________________________________ : : (129269984,)\n",
       "units_____________________________________________ : : (129269984,)\n",
       "value_significance________________________________ : : (129269984,)\n",
       "z_coordinate______________________________________ : : (129269984,)\n",
       "z_coordinate_method_______________________________ : : (129269984,)\n",
       "z_coordinate_type_________________________________ : : (129269984,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-20400-0-5023_CEUAS_merged_v1.nc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z_coordinate</th>\n",
       "      <th>z_coordinate_type</th>\n",
       "      <th>date_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1949-04-08 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1949-04-08 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1949-04-12 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1949-04-12 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1949-04-13 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129269979</th>\n",
       "      <td>99440.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-31 11:30:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129269980</th>\n",
       "      <td>99470.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-31 11:30:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129269981</th>\n",
       "      <td>99530.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-31 11:30:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129269982</th>\n",
       "      <td>99540.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-31 11:30:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129269983</th>\n",
       "      <td>99900.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-31 11:30:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129269984 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           z_coordinate  z_coordinate_type           date_time\n",
       "0                   NaN                  2 1949-04-08 03:00:00\n",
       "1                   NaN                  2 1949-04-08 03:00:00\n",
       "2                   NaN                  2 1949-04-12 03:00:00\n",
       "3                   NaN                  2 1949-04-12 03:00:00\n",
       "4                   NaN                  2 1949-04-13 03:00:00\n",
       "...                 ...                ...                 ...\n",
       "129269979       99440.0                  1 2022-12-31 11:30:23\n",
       "129269980       99470.0                  1 2022-12-31 11:30:23\n",
       "129269981       99530.0                  1 2022-12-31 11:30:23\n",
       "129269982       99540.0                  1 2022-12-31 11:30:23\n",
       "129269983       99900.0                  1 2022-12-31 11:30:23\n",
       "\n",
       "[129269984 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with eua.CDMDataset(\n",
    "    \"/mnt/users/scratch/leo/scratch/converted_v11/long/0-20001-0-11035_CEUAS_merged_v1.nc\"\n",
    ") as file:\n",
    "    display(file)\n",
    "    display(file[\"recordindices\"])\n",
    "    display(file[\"observations_table\"])\n",
    "    df = file.to_dataframe(\n",
    "        groups=[\"observations_table\"],\n",
    "        variables=[\"z_coordinate\", \"z_coordinate_type\", \"date_time\"],\n",
    "    )\n",
    "# df[\"conv_report_timestamp\"] = seconds_to_datetime(df.date_time.values)\n",
    "print('0-20400-0-5023_CEUAS_merged_v1.nc')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_coordinate_t = np.array([1000,750,500,800,10])\n",
    "checksorting = (lambda zc: np.all(zc[:-1] >= zc[1:]))\n",
    "checksorting(z_coordinate_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "iter(v, w): v must be callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m iz \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mz_coordinate_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: iter(v, w): v must be callable"
     ]
    }
   ],
   "source": [
    "iz = iter(z_coordinate_t, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miz\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(iz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([750, 500, 300,  10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_coordinate_t[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_coordinate_t[:-1] < z_coordinate_t[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H5PY\n",
    "### File Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['alternative_name', 'bbox_max_latitude', 'bbox_max_longitude', 'bbox_min_latitude', 'bbox_min_longitude', 'city', 'comment', 'contact', 'end_date', 'index', 'latitude', 'local_gravity', 'longitude', 'measuring_system_id', 'measuring_system_model', 'metadata_contact', 'metadata_contact_role', 'observed_variables', 'observing_frequency', 'operating_institute', 'operating_territory', 'optional_data', 'platform_sub_type', 'platform_type', 'primary_id', 'primary_id_scheme', 'record_number', 'reporting_time', 'role', 'secondary_id', 'secondary_id_scheme', 'start_date', 'station_abbreviation', 'station_automation', 'station_crs', 'station_name', 'station_type', 'string1', 'string12', 'string15', 'string198', 'string20', 'string3', 'string34', 'string4', 'string8', 'telecommunication_method']>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File(\n",
    "    \"/mnt/users/scratch/leo/scratch/converted_v11/long/0-20300-0-99010_CEUAS_merged_v1.nc\",\n",
    "    \"r\",\n",
    ") as file:\n",
    "    display(file['station_configuration'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = '0401820161013230000'\n",
    "# file_dir = glob.glob('/mnt/users/scratch/leo/scratch/converted_v11/long/*'+str(input_str[:5])+'*_CEUAS_merged_v1.nc')[0]\n",
    "file_dir = glob.glob('/mnt/users/scratch/leo/scratch/converted_v9/*'+str(input_str[:5])+'*_CEUAS_merged_v1.nc')[0]\n",
    "\n",
    "date = str(input_str[5:9]) + '-' + str(input_str[9:11]) + '-' + str(input_str[11:13]) + ' ' + str(input_str[13:15]) + ':' + str(input_str[15:17]) \n",
    "\n",
    "output = {}\n",
    "with h5py.File(\n",
    "    file_dir,\n",
    "    \"r\",\n",
    ") as file:\n",
    "    dt_from = datetime_to_seconds(np.datetime64(date))\n",
    "    dt_to = dt_from + 12*60*60\n",
    "    rts = file[\"recordindices\"][\"recordtimestamp\"][:]\n",
    "    idx = np.where(np.logical_and((rts >= dt_from), (rts <= dt_to)))[0]\n",
    "    idx_d = file[\"recordindices\"][\"126\"][idx]\n",
    "\n",
    "    output['temperature'] = file[\"observations_table\"][\"observation_value\"][idx_d[0]:idx_d[-1]]\n",
    "    output['pressure'] = file[\"observations_table\"][\"z_coordinate\"][idx_d[0]:idx_d[-1]]\n",
    "    output['date_time'] = file[\"observations_table\"][\"date_time\"][idx_d[0]:idx_d[-1]]\n",
    "    output['sensor_id'] = file[\"observations_table\"][\"sensor_id\"][idx_d[0]:idx_d[-1]]\n",
    "    output['fg_depar'] = file[\"era5fb\"][\"fg_depar@body\"][idx_d[0]:idx_d[-1]]\n",
    "    output['an_depar'] = file[\"era5fb\"][\"an_depar@body\"][idx_d[0]:idx_d[-1]]\n",
    "    output['RAOBCORE_bias_estimate'] = file[\"advanced_homogenisation\"][\"RAOBCORE_bias_estimate\"][idx_d[0]:idx_d[-1]]\n",
    "    output['RASE_bias_estimate'] = file[\"advanced_homogenisation\"][\"RASE_bias_estimate\"][idx_d[0]:idx_d[-1]]\n",
    "    output['RICH_bias_estimate'] = file[\"advanced_homogenisation\"][\"RICH_bias_estimate\"][idx_d[0]:idx_d[-1]]\n",
    "    output['RISE_bias_estimate'] = file[\"advanced_homogenisation\"][\"RISE_bias_estimate\"][idx_d[0]:idx_d[-1]]\n",
    "\n",
    "    \n",
    "df = pd.DataFrame.from_dict(output)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': array([275.6, 279. , 283.4], dtype=float32),\n",
       " 'pressure': array([ 86800.,  92500., 100000.], dtype=float32),\n",
       " 'date_time': array([3685388400, 3685388400, 3685388400]),\n",
       " 'sensor_id': array([[b'n'],\n",
       "        [b'n'],\n",
       "        [b'n']], dtype='|S1'),\n",
       " 'fg_depar': array([ 0.7011206 , -0.02587065,  0.66992944], dtype=float32),\n",
       " 'an_depar': array([ 0.29189965, -0.21811682,  0.5476524 ], dtype=float32),\n",
       " 'RAOBCORE_bias_estimate': array([nan, -0., -0.], dtype=float32),\n",
       " 'RASE_bias_estimate': array([nan, -0., -0.], dtype=float32),\n",
       " 'RICH_bias_estimate': array([        nan, -0.09797987, -6.3157864 ], dtype=float32),\n",
       " 'RISE_bias_estimate': array([        nan, -0.09797987, -6.3157864 ], dtype=float32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/frame.py:1762\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1757\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for orient parameter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1758\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morient\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1759\u001b[0m     )\n\u001b[1;32m   1761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1764\u001b[0m     realdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/frame.py:662\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    656\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    657\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    658\u001b[0m     )\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 662\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/internals/construction.py:653\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    651\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 653\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(output)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notnan = df[~np.isnan(df.latd)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latd</th>\n",
       "      <th>dt</th>\n",
       "      <th>obsv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [latd, dt, obsv]\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_notnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latd</th>\n",
       "      <th>lond</th>\n",
       "      <th>tsl</th>\n",
       "      <th>tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184716884</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184716885</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184716886</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184716887</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184716888</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184716889 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           latd  lond  tsl  tt\n",
       "0           NaN   NaN  NaN NaN\n",
       "1           NaN   NaN  NaN NaN\n",
       "2           NaN   NaN  NaN NaN\n",
       "3           NaN   NaN  NaN NaN\n",
       "4           NaN   NaN  NaN NaN\n",
       "...         ...   ...  ...  ..\n",
       "184716884   NaN   NaN  NaN NaN\n",
       "184716885   NaN   NaN  NaN NaN\n",
       "184716886   NaN   NaN  NaN NaN\n",
       "184716887   NaN   NaN  NaN NaN\n",
       "184716888   NaN   NaN  NaN NaN\n",
       "\n",
       "[184716889 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_dir = glob.glob('/users/staff/uvoggenberger/scratch/converted_v11/trajectory_files_20230502/*04018*')[0]\n",
    "output = {}\n",
    "with h5py.File(\n",
    "    file_dir,\n",
    "    \"r\",\n",
    ") as file:\n",
    "    output['latd'] = file[\"advanced_homogenisation\"][\"latitude_displacement\"][:] #[idx_d[0]:idx_d[-1]]\n",
    "    output['lond'] = file[\"advanced_homogenisation\"][\"longitude_displacement\"][:] #[idx_d[0]:idx_d[-1]]\n",
    "    output['tsl'] = file[\"advanced_homogenisation\"]['time_since_launch'][:] #[idx_d[0]:idx_d[-1]]\n",
    "    output['tt'] = file[\"advanced_homogenisation\"]['true_time'][:] #[idx_d[0]:idx_d[-1]]\n",
    "df_only = pd.DataFrame.from_dict(output)\n",
    "df_only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latd</th>\n",
       "      <th>lond</th>\n",
       "      <th>tsl</th>\n",
       "      <th>tt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92173532</th>\n",
       "      <td>0.180172</td>\n",
       "      <td>-0.179681</td>\n",
       "      <td>908.756208</td>\n",
       "      <td>1.451665e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92173533</th>\n",
       "      <td>0.150439</td>\n",
       "      <td>-0.150822</td>\n",
       "      <td>780.267377</td>\n",
       "      <td>1.451665e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92173534</th>\n",
       "      <td>0.126596</td>\n",
       "      <td>-0.127699</td>\n",
       "      <td>660.122743</td>\n",
       "      <td>1.451665e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92173535</th>\n",
       "      <td>0.105028</td>\n",
       "      <td>-0.106799</td>\n",
       "      <td>547.238120</td>\n",
       "      <td>1.451665e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92173536</th>\n",
       "      <td>0.083630</td>\n",
       "      <td>-0.086079</td>\n",
       "      <td>440.509153</td>\n",
       "      <td>1.451664e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110398748</th>\n",
       "      <td>0.000114</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>4.069281</td>\n",
       "      <td>3.881430e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110398749</th>\n",
       "      <td>0.000071</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>2.658360</td>\n",
       "      <td>3.881430e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110398750</th>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>1.406633</td>\n",
       "      <td>3.881430e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110398751</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.781316</td>\n",
       "      <td>3.881430e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110398752</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.881430e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18142267 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               latd      lond         tsl            tt\n",
       "92173532   0.180172 -0.179681  908.756208  1.451665e+09\n",
       "92173533   0.150439 -0.150822  780.267377  1.451665e+09\n",
       "92173534   0.126596 -0.127699  660.122743  1.451665e+09\n",
       "92173535   0.105028 -0.106799  547.238120  1.451665e+09\n",
       "92173536   0.083630 -0.086079  440.509153  1.451664e+09\n",
       "...             ...       ...         ...           ...\n",
       "110398748  0.000114 -0.000333    4.069281  3.881430e+09\n",
       "110398749  0.000071 -0.000208    2.658360  3.881430e+09\n",
       "110398750  0.000036 -0.000105    1.406633  3.881430e+09\n",
       "110398751  0.000019 -0.000058    0.781316  3.881430e+09\n",
       "110398752  0.000000  0.000000    0.000000  3.881430e+09\n",
       "\n",
       "[18142267 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_only[~np.isnan(df_only.tsl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/staff/uvoggenberger/scratch/converted_v11/trajectory_files_20230426/trajectory_0-20001-0-11035_CEUAS_merged_v1.nc'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfile_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "input_str = '0401820161013230000'\n",
    "# input_str = '1103520161013230000'\n",
    "file_dir = glob.glob('/mnt/users/scratch/leo/scratch/converted_v11/long/*'+str(input_str[:5])+'*_CEUAS_merged_v1.nc')[0]\n",
    "# file_dir = glob.glob('/mnt/users/scratch/leo/scratch/converted_v9/*'+str(input_str[:5])+'*_CEUAS_merged_v1.nc')[0]\n",
    "\n",
    "date = str(input_str[5:9]) + '-' + str(input_str[9:11]) + '-' + str(input_str[11:13]) + ' ' + str(input_str[13:15]) + ':' + str(input_str[15:17]) \n",
    "\n",
    "output = {}\n",
    "with h5py.File(\n",
    "    file_dir,\n",
    "    \"r\",\n",
    ") as file:\n",
    "    i = 2000\n",
    "    # display(file['advanced_homogenisation'].keys())\n",
    "    # for i in range(1990,2020,1):\n",
    "    dt_from = datetime_to_seconds(np.datetime64(str(i)+\"-01-01\"))\n",
    "    dt_to = datetime_to_seconds(np.datetime64(str(i)+\"-01-02\"))\n",
    "    rts = file[\"recordindices\"][\"recordtimestamp\"][:]\n",
    "    idx = np.where(np.logical_and((rts >= dt_from), (rts <= dt_to)))[0]\n",
    "    idx_d = file[\"recordindices\"][\"126\"][idx]\n",
    "gfile = glob.glob('/users/staff/uvoggenberger/scratch/converted_v11/trajectory_files_20230426/*11035*')[0]\n",
    "with h5py.File(\n",
    "gfile,\n",
    "\"r\",\n",
    ") as gfile:\n",
    "    test = gfile[\"advanced_homogenisation\"][\"longitude_displacement\"][idx_d[0]:idx_d[-1]]\n",
    "    print(len(test))\n",
    "    print(len(test[~np.isnan(test)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3755289600"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69290, 69291])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': array([196.24, 196.25, 196.23, ..., 275.04, 274.8 , 274.89], dtype=float32),\n",
       " 'pressure': array([  1680.,   1690.,   1700., ..., 100430., 100490., 100600.],\n",
       "       dtype=float32),\n",
       " 'date_time': array([3755329405, 3755329405, 3755329405, ..., 3786692334, 3786692334,\n",
       "        3786692334]),\n",
       " 'sensor_id': array([[b'1', b'4', b'2', b''],\n",
       "        [b'1', b'4', b'2', b''],\n",
       "        [b'1', b'4', b'2', b''],\n",
       "        ...,\n",
       "        [b'1', b'4', b'2', b''],\n",
       "        [b'1', b'4', b'2', b''],\n",
       "        [b'1', b'4', b'2', b'']], dtype='|S1'),\n",
       " 'fg_depar': array([ 2.2318075 ,  2.2000031 ,  2.1381989 , ..., -0.93545824,\n",
       "        -1.1558708 ,         nan], dtype=float32),\n",
       " 'an_depar': array([ 1.3021971 ,  1.2760303 ,  1.2198635 , ..., -0.65341526,\n",
       "        -0.8557439 ,         nan], dtype=float32),\n",
       " 'RAOBCORE_bias_estimate': array([nan, nan, nan, ..., nan, nan, nan], dtype=float32),\n",
       " 'RASE_bias_estimate': array([nan, nan, nan, ..., nan, nan, nan], dtype=float32),\n",
       " 'RICH_bias_estimate': array([nan, nan, nan, ..., nan, nan, nan], dtype=float32),\n",
       " 'RISE_bias_estimate': array([nan, nan, nan, ..., nan, nan, nan], dtype=float32)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Per-column arrays must each be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/frame.py:1762\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1757\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for orient parameter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1758\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morient\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1759\u001b[0m     )\n\u001b[1;32m   1761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1764\u001b[0m     realdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/frame.py:662\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    656\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    657\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    658\u001b[0m     )\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 662\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/internals/construction.py:653\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    651\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 653\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"
     ]
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['advanced_homogenisation', 'crs', 'era5fb', 'header_table', 'observations_table', 'observed_variable', 'recordindices', 'sensor_configuration', 'source_configuration', 'station_configuration', 'station_configuration_codes', 'station_type', 'units', 'z_coordinate_type']>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['adjustment_id', 'advanced_assimilation_feedback', 'advanced_homogenisation', 'advanced_qc', 'advanced_uncertainty', 'bbox_max_latitude', 'bbox_max_longitude', 'bbox_min_latitude', 'bbox_min_longitude', 'code_table', 'conversion_flag', 'conversion_method', 'crs', 'data_policy_licence', 'date_time', 'date_time_meaning', 'exposure_of_sensor', 'index', 'latitude', 'location_method', 'location_precision', 'longitude', 'numerical_precision', 'observation_duration', 'observation_height_above_station_surface', 'observation_id', 'observation_value', 'observed_variable', 'original_code_table', 'original_precision', 'original_units', 'original_value', 'processing_level', 'quality_flag', 'report_id', 'secondary_value', 'secondary_variable', 'sensor_automation_status', 'sensor_id', 'source_id', 'spatial_representativeness', 'station_elevation', 'string21', 'string4', 'string9', 'traceability', 'units', 'value_significance', 'z_coordinate', 'z_coordinate_method', 'z_coordinate_type']>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['albedo@modsurf', 'an_depar@body', 'an_depar@surfbody_feedback', 'an_sens_obs@body', 'andate', 'antime', 'biascorr@body', 'biascorr_fg@body', 'bufrtype@hdr', 'class', 'codetype@hdr', 'collection_identifier@conv', 'date@hdr', 'datum_anflag@body', 'datum_event1@body', 'datum_rdbflag@body', 'datum_sfc_event@surfbody_feedback', 'datum_status@body', 'datum_status@surfbody_feedback', 'eda_spread@errstat', 'entryno@body', 'expver', 'fg_depar@body', 'fg_depar@surfbody_feedback', 'fg_error@errstat', 'final_obs_error@errstat', 'groupid@hdr', 'index', 'lat@hdr', 'lon@hdr', 'lsm@modsurf', 'lsm@surfbody_feedback', 'numtsl@desc', 'obs_error@errstat', 'obstype@hdr', 'obsvalue@body', 'orography@modsurf', 'ppcode@conv_body', 'qc_pge@body', 'report_event1@hdr', 'report_rdbflag@hdr', 'report_status@hdr', 'reportype', 'seaice@modsurf', 'sensor@hdr', 'seqno@hdr', 'snow_density@surfbody_feedback', 'snow_depth@modsurf', 'snow_depth@surfbody_feedback', 'sonde_type@conv', 'source@hdr', 'source_id', 'stalt@hdr', 'statid@hdr', 'station_type@conv', 'stream', 'string10', 'string6', 'string9', 'subtype@hdr', 'time@hdr', 'timeseries_index@conv', 'timeslot@timeslot_index', 'tsfc@modsurf', 'type', 'unique_identifier@conv', 'varbc_ix@body', 'varno@body', 'vertco_reference_1@body', 'vertco_reference_2@body', 'vertco_type@body', 'windspeed10m@modsurf']>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['RAOBCORE_bias_estimate', 'RASE_bias_estimate', 'RICH_bias_estimate', 'RISE_bias_estimate', 'humidity_bias_estimate', 'index', 'latitude_displacement', 'longitude_displacement', 'time_since_launch', 'true_time', 'wind_bias_estimate']>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_str = '0401820161013230000'\n",
    "file = glob.glob('/mnt/users/scratch/leo/scratch/converted_v11/long/*'+str(input_str[:5])+'*_CEUAS_merged_v1.nc')[0]\n",
    "date = str(input_str[5:9]) + '-' + str(input_str[9:11]) + '-' + str(input_str[11:13]) + ' ' + str(input_str[13:15]) + ':' + str(input_str[15:17]) \n",
    "\n",
    "output = {}\n",
    "with h5py.File(\n",
    "    file,\n",
    "    \"r\",\n",
    ") as file:\n",
    "    display(file.keys())\n",
    "    display(file['observations_table'].keys())\n",
    "    display(file['era5fb'].keys())\n",
    "    display(file['advanced_homogenisation'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = str(input_str[5:9]) + '-' + str(input_str[9:11]) + '-' + str(input_str[11:13]) + ' ' + str(input_str[13:15]) + ':' + str(input_str[15:17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016-10-13 23:00'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe concatination with h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_file = glob.glob(\n",
    "    \"/mnt/users/scratch/leo/scratch/converted_v11/long//0-20001-0-11035_CEUAS_merged_v1.nc\"\n",
    ")[0]\n",
    "dt_from = datetime_to_seconds(np.datetime64(\"1970-01-01\"))\n",
    "dt_to = datetime_to_seconds(np.datetime64(\"1970-01-02\"))\n",
    "\n",
    "df_dict = {}\n",
    "h_df_dict = {}\n",
    "\n",
    "with h5py.File(conv_file, \"r\") as file:\n",
    "    rts = file[\"recordindices\"][\"recordtimestamp\"][:]\n",
    "    idx = np.where(np.logical_and((rts >= dt_from), (rts <= dt_to)))[0]\n",
    "    plevs = [\n",
    "        1000,\n",
    "        2000,\n",
    "        3000,\n",
    "        5000,\n",
    "        7000,\n",
    "        10000,\n",
    "        15000,\n",
    "        20000,\n",
    "        25000,\n",
    "        30000,\n",
    "        40000,\n",
    "        50000,\n",
    "        70000,\n",
    "        85000,\n",
    "        92500,\n",
    "        100000,\n",
    "    ]\n",
    "\n",
    "    idx_d = {}\n",
    "    var_d = {\n",
    "        \"air_temperature\": \"126\",\n",
    "        \"relative_humidty\": \"138\",\n",
    "        \"geopotential\": \"117\",\n",
    "        \"eastward_wind_speed\": \"139\",\n",
    "        \"northward_wind_speed\": \"140\",\n",
    "        \"dew_point\": \"137\",\n",
    "        \"specific_humidity\": \"39\",\n",
    "    }\n",
    "    for i in var_d:\n",
    "        idx_d[i] = file[\"recordindices\"][var_d[i]][idx]\n",
    "\n",
    "    masks = {}\n",
    "    for i in idx_d:\n",
    "        masks[i] = file[\"observations_table\"][\"z_coordinate\"][\n",
    "            idx_d[i][0] : idx_d[i][-1]\n",
    "        ]\n",
    "        masks[i] = np.isin(masks[i], plevs)\n",
    "        # masks[i] = np.isfinite(masks[i])\n",
    "\n",
    "    mask = masks[\"air_temperature\"]\n",
    "    t_idx = idx_d[\"air_temperature\"]\n",
    "    df_dict[\"z_coordinate\"] = list(\n",
    "        file[\"observations_table\"][\"z_coordinate\"][t_idx[0] : t_idx[-1]][mask]\n",
    "    )\n",
    "    df_dict[\"date_time\"] = seconds_to_datetime(\n",
    "        list(file[\"observations_table\"][\"date_time\"][t_idx[0] : t_idx[-1]][mask])\n",
    "    )\n",
    "    df_dict[\"latitude\"] = list(\n",
    "        file[\"observations_table\"][\"latitude\"][t_idx[0] : t_idx[-1]][mask]\n",
    "    )\n",
    "    df_dict[\"longitude\"] = list(\n",
    "        file[\"observations_table\"][\"longitude\"][t_idx[0] : t_idx[-1]][mask]\n",
    "    )\n",
    "    repid = np.asarray(\n",
    "        file[\"observations_table\"][\"report_id\"][t_idx[0] : t_idx[-1]][mask]\n",
    "    )\n",
    "    df_dict[\"report_id\"] = list(\n",
    "        repid.view(\"|S{}\".format(repid.shape[1])).flatten().astype(str)\n",
    "    )\n",
    "    # df_dict['RASE_bias_estimate'] = list(file['advanced_homogenisation']['RASE_bias_estimate'][t_idx[0]:t_idx[-1]][mask])\n",
    "    # df_dict['latitude_displacement'] = list(file['advanced_homogenisation']['latitude_displacement'][t_idx[0]:t_idx[-1]][mask])\n",
    "    # df_dict['longitude_displacement'] = list(file['advanced_homogenisation']['longitude_displacement'][t_idx[0]:t_idx[-1]][mask])\n",
    "    # df_dict['time_since_launch'] = list(file['advanced_homogenisation']['time_since_launch'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict[\"air_temperature\"] = list(\n",
    "        file[\"observations_table\"][\"observation_value\"][t_idx[0] : t_idx[-1]][mask]\n",
    "    )\n",
    "\n",
    "    df_dict_d = {}\n",
    "    for i in masks:\n",
    "        if i != \"air_temperature\":\n",
    "            df_dict_d[i] = {}\n",
    "    for i in masks:\n",
    "        if i != \"air_temperature\":\n",
    "            df_dict_d[i][\"z_coordinate\"] = list(\n",
    "                file[\"observations_table\"][\"z_coordinate\"][idx_d[i][0] : idx_d[i][-1]][\n",
    "                    masks[i]\n",
    "                ]\n",
    "            )\n",
    "            df_dict_d[i][\"date_time\"] = seconds_to_datetime(\n",
    "                list(\n",
    "                    file[\"observations_table\"][\"date_time\"][idx_d[i][0] : idx_d[i][-1]][\n",
    "                        masks[i]\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            df_dict_d[i][i] = list(\n",
    "                file[\"observations_table\"][\"observation_value\"][\n",
    "                    idx_d[i][0] : idx_d[i][-1]\n",
    "                ][masks[i]]\n",
    "            )\n",
    "\n",
    "    # df_dict['date_time'] = seconds_to_datetime(df_dict['date_time'])\n",
    "    df = pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "    # h_df_dict['date_time'] = seconds_to_datetime(h_df_dict['date_time'])\n",
    "    h_df = pd.DataFrame.from_dict(h_df_dict)\n",
    "\n",
    "    # put dfs together:\n",
    "    for i in df_dict_d:\n",
    "        if i != \"air_temperature\":\n",
    "            df = df.merge(\n",
    "                pd.DataFrame.from_dict(df_dict_d[i]),\n",
    "                how=\"left\",\n",
    "                on=[\"date_time\", \"z_coordinate\"],\n",
    "            )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uvn10",
   "language": "python",
   "name": "uvn10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
