{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81341ac5-d07c-47e4-b49a-56d381e7e851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import os, glob, sys\n",
    "import calendar\n",
    "\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e26eb5f-c216-408d-8e2b-cc828a7cd776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def datetime_to_seconds(dates, ref='1900-01-01T00:00:00'):\n",
    "    \"\"\" from datetime64 to seconds since 1900-01-01 00:00:00\"\"\"\n",
    "    return ((dates - numpy.datetime64(ref)) / numpy.timedelta64(1, 's')).astype(numpy.int64)\n",
    "\n",
    "class TimeBatch:\n",
    "    def __init__(self, year, month):\n",
    "        self.year = year\n",
    "        self.month = month\n",
    "\n",
    "def read_nc_file(\n",
    "        file: str, table_name: str, time_batch: TimeBatch = None\n",
    ") -> pandas.DataFrame:\n",
    "    \"\"\"Read nc table using h5py.\"\"\"\n",
    "    \n",
    "    sorted_by_variable = ['advanced_homogenisation', 'advanced_uncertainty', 'era5fb', 'observations_table', ]\n",
    "    sorted_by_date = ['header_table', 'source_configuration']\n",
    "    \n",
    "    # check if file is available\n",
    "    nc_file = glob.glob(file)\n",
    "    if len(nc_file) != 1:\n",
    "        raise FileNotFoundError\n",
    "    \n",
    "    # create time indices if time_batch is given\n",
    "    if time_batch is not None:\n",
    "        year = time_batch.year\n",
    "        month = time_batch.month\n",
    "        last_month_day = calendar.monthrange(year, month)[1]\n",
    "        start = f\"{year}-{month:02d}-01T00:00:00\"\n",
    "        end = f\"{year}-{month:02d}-{last_month_day}T23:59:59\"\n",
    "        selected_start = datetime_to_seconds(numpy.datetime64(start))\n",
    "        selected_end = datetime_to_seconds(numpy.datetime64(end))\n",
    "    # select all if no time_batch is given\n",
    "    else:\n",
    "        start = \"1900-01-01T00:00:00\"\n",
    "        end = \"2999-01-01T00:00:00\"\n",
    "        selected_start = datetime_to_seconds(numpy.datetime64(start))\n",
    "        selected_end = datetime_to_seconds(numpy.datetime64(end))\n",
    "    \n",
    "    # open file and select only data necessary to read\n",
    "    with h5py.File(file) as hfile:\n",
    "        var_dfs = {}\n",
    "        \n",
    "        # iterating through the variables and their indices in recordindices\n",
    "        # store them in a dataframe dictionary for further use\n",
    "        if table_name in sorted_by_variable:\n",
    "            file_vars = numpy.array(hfile['recordindices'])\n",
    "            time_index = hfile['recordindices']['recordtimestamp'][:]\n",
    "            for variable in file_vars[(file_vars != 'index') & (file_vars != 'recordtimestamp')]:\n",
    "\n",
    "                selector = (time_index >= selected_start) & (time_index <= selected_end)\n",
    "                if selector[-1]:\n",
    "                    selector = numpy.append(selector, True)\n",
    "                else:\n",
    "                    selector = numpy.append(selector, False)\n",
    "                var_index = hfile['recordindices'][variable][:][selector]\n",
    "\n",
    "                data = {}\n",
    "                # selected table is read\n",
    "                for i in numpy.array(hfile[table_name]):\n",
    "                    # dropping string dims - not necessary for dataframes\n",
    "                    if \"string\" not in str(i):\n",
    "                        # recover byte array strings - not necessary for dataframes\n",
    "                        if len(hfile[table_name][i].shape) > 1:\n",
    "                            data[i] = hfile[table_name][i][var_index[0]:var_index[-1]].astype(object).sum(axis=1).astype(\n",
    "                                str)\n",
    "                        else:\n",
    "                            data[i] = numpy.array(hfile[table_name][i][var_index[0]:var_index[-1]])\n",
    "                var_dfs[variable] = (pd.DataFrame(data))\n",
    "        \n",
    "        elif table_name in sorted_by_date:\n",
    "            time_index = hfile['header_table']['report_timestamp'][:]\n",
    "            selector = (time_index >= selected_start) & (time_index <= selected_end)\n",
    "            print(len(selector),selector)\n",
    "            data = {}\n",
    "            # selected table is read\n",
    "            for i in numpy.array(hfile[table_name]):\n",
    "                # dropping string dims - not necessary for dataframes\n",
    "                if \"string\" not in str(i):\n",
    "                    # recover byte array strings - not necessary for dataframes\n",
    "                    if len(hfile[table_name][i].shape) > 1:\n",
    "                        data[i] = hfile[table_name][i][:][selector].astype(object).sum(axis=1).astype(\n",
    "                            str)\n",
    "                    else:\n",
    "                        data[i] = numpy.array(hfile[table_name][i][:][selector])\n",
    "            var_dfs[table_name] = (pd.DataFrame(data))\n",
    "            \n",
    "        else:\n",
    "            data = {}\n",
    "            # selected table is read\n",
    "            for i in numpy.array(hfile[table_name]):\n",
    "                # dropping string dims - not necessary for dataframes\n",
    "                if \"string\" not in str(i):\n",
    "                    # recover byte array strings - not necessary for dataframes\n",
    "                    if len(hfile[table_name][i].shape) > 1:\n",
    "                        data[i] = hfile[table_name][i][:].astype(object).sum(axis=1).astype(\n",
    "                            str)\n",
    "                    else:\n",
    "                        data[i] = numpy.array(hfile[table_name][i][:])\n",
    "            var_dfs[table_name] = (pd.DataFrame(data))\n",
    "\n",
    "\n",
    "    # create dataframe as needed, example: stack all the variables:\n",
    "    keys = list(var_dfs.keys())\n",
    "    df_out = var_dfs[keys[0]]\n",
    "    for i in keys[1:]:\n",
    "        df_out = df_out.append(var_dfs[i], ignore_index=True)\n",
    "\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9985b249-7b80-456a-8c3e-11701d954b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>domain</th>\n",
       "      <th>name</th>\n",
       "      <th>observed_variable_len</th>\n",
       "      <th>parameter_group</th>\n",
       "      <th>sub_domain</th>\n",
       "      <th>units</th>\n",
       "      <th>variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vertical column integral of spectral aerosol a...</td>\n",
       "      <td></td>\n",
       "      <td>aerosol absorption optical depth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>aerosols</td>\n",
       "      <td></td>\n",
       "      <td>Dimensionless</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2D field of the column burden of condensed par...</td>\n",
       "      <td></td>\n",
       "      <td>aerosol column burden</td>\n",
       "      <td>0.0</td>\n",
       "      <td>aerosols</td>\n",
       "      <td></td>\n",
       "      <td>g m-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-D field of concentration of dust or sand in ...</td>\n",
       "      <td></td>\n",
       "      <td>aerosol dust concentration</td>\n",
       "      <td>0.0</td>\n",
       "      <td>aerosols</td>\n",
       "      <td></td>\n",
       "      <td>g kg-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D field of mean aerosol particle size, define...</td>\n",
       "      <td></td>\n",
       "      <td>aerosol effective radius</td>\n",
       "      <td>0.0</td>\n",
       "      <td>aerosols</td>\n",
       "      <td></td>\n",
       "      <td>micro m</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3D field of spectral volumetric extinction cro...</td>\n",
       "      <td></td>\n",
       "      <td>aerosol extinction coefficient</td>\n",
       "      <td>0.0</td>\n",
       "      <td>aerosols</td>\n",
       "      <td></td>\n",
       "      <td>m-1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Level partial pressure of ozone in milli-Pasca...</td>\n",
       "      <td>atmospheric</td>\n",
       "      <td>ozone partial pressure</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>upper-air</td>\n",
       "      <td>Pa</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Level mixing ratio of ozone in ppmv</td>\n",
       "      <td>atmospheric</td>\n",
       "      <td>ozone concentration</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>upper-air</td>\n",
       "      <td>ppmv</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Ozone (DU) integrated up to the current altitu...</td>\n",
       "      <td>atmospheric</td>\n",
       "      <td>total ozone column</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>upper-air</td>\n",
       "      <td>DU</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Ozone amount integrated over the whole balloon...</td>\n",
       "      <td>atmospheric</td>\n",
       "      <td>flight summary integrated O3</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>upper-air</td>\n",
       "      <td>DU</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Atmospheric pressure when balloon burst in hPa.</td>\n",
       "      <td></td>\n",
       "      <td>sampling method burst ozone pressure</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Pa</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           description       domain  \\\n",
       "0    Vertical column integral of spectral aerosol a...                \n",
       "1    2D field of the column burden of condensed par...                \n",
       "2    3-D field of concentration of dust or sand in ...                \n",
       "3    3D field of mean aerosol particle size, define...                \n",
       "4    3D field of spectral volumetric extinction cro...                \n",
       "..                                                 ...          ...   \n",
       "137  Level partial pressure of ozone in milli-Pasca...  atmospheric   \n",
       "138                Level mixing ratio of ozone in ppmv  atmospheric   \n",
       "139  Ozone (DU) integrated up to the current altitu...  atmospheric   \n",
       "140  Ozone amount integrated over the whole balloon...  atmospheric   \n",
       "141    Atmospheric pressure when balloon burst in hPa.                \n",
       "\n",
       "                                     name  observed_variable_len  \\\n",
       "0        aerosol absorption optical depth                    0.0   \n",
       "1                   aerosol column burden                    0.0   \n",
       "2              aerosol dust concentration                    0.0   \n",
       "3                aerosol effective radius                    0.0   \n",
       "4          aerosol extinction coefficient                    0.0   \n",
       "..                                    ...                    ...   \n",
       "137                ozone partial pressure                    0.0   \n",
       "138                   ozone concentration                    0.0   \n",
       "139                   total ozone column                     0.0   \n",
       "140          flight summary integrated O3                    0.0   \n",
       "141  sampling method burst ozone pressure                    0.0   \n",
       "\n",
       "    parameter_group sub_domain          units variable  \n",
       "0          aerosols             Dimensionless        0  \n",
       "1          aerosols                     g m-2        1  \n",
       "2          aerosols                    g kg-1        2  \n",
       "3          aerosols                   micro m        3  \n",
       "4          aerosols                       m-1        4  \n",
       "..              ...        ...            ...      ...  \n",
       "137                  upper-air             Pa      150  \n",
       "138                  upper-air           ppmv      151  \n",
       "139                  upper-air             DU      152  \n",
       "140                  upper-air             DU      153  \n",
       "141                                        Pa      154  \n",
       "\n",
       "[142 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb = TimeBatch(2000,1)\n",
    "file = glob.glob('/mnt/users/scratch/leo/scratch/converted_v8/*11035*')[0]\n",
    "table_name = 'observed_variable' # 'header_table' # 'observations_table'\n",
    "\n",
    "df = read_nc_file(file, table_name, tb)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6022a2b7-b34c-4af1-9d5e-1a12295ce157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File: <HDF5 file \"0-20001-0-11035_CEUAS_merged_v1.nc\" (mode r)>\n",
       "Filesize: 2465.82 MB\n",
       "Filename: /mnt/users/scratch/leo/scratch/converted_v8/0-20001-0-11035_CEUAS_merged_v1.nc\n",
       "(G)roups/(V)ariables: \n",
       "\n",
       " - G | advanced_homogenisation______________________ : : 7\n",
       " - G | advanced_uncertainty_________________________ : : 9\n",
       " - G | crs__________________________________________ : : 4\n",
       " - V | dateindex____________________________________ : : (28103,)\n",
       " - G | era5fb_______________________________________ : : 72\n",
       " - G | header_table_________________________________ : : 56\n",
       " - G | observations_table___________________________ : : 50\n",
       " - G | observed_variable____________________________ : : 9\n",
       " - G | recordindices________________________________ : : 13\n",
       " - G | sensor_configuration_________________________ : : 12\n",
       " - G | source_configuration_________________________ : : 2\n",
       " - G | station_configuration________________________ : : 46\n",
       " - G | station_configuration_codes__________________ : : 7\n",
       " - G | station_type_________________________________ : : 4\n",
       " - G | units________________________________________ : : 6\n",
       " - G | z_coordinate_type____________________________ : : 4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "z_coordinate_type:\n",
       "\n",
       "description_______________________________________ : : (2, 80)\n",
       "string80__________________________________________ : : (80,)\n",
       "type______________________________________________ : : (2,)\n",
       "z_coordinate_type_len_____________________________ : : (2,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "header_table:\n",
       "\n",
       "application_area__________________________________ : : (97514,)\n",
       "crs_______________________________________________ : : (97514,)\n",
       "duplicate_status__________________________________ : : (97514,)\n",
       "duplicates________________________________________ : : (97514, 70)\n",
       "events_at_station_________________________________ : : (97514,)\n",
       "height_of_station_above_local_ground______________ : : (97514,)\n",
       "height_of_station_above_sea_level_________________ : : (97514,)\n",
       "height_of_station_above_sea_level_accuracy________ : : (97514,)\n",
       "index_____________________________________________ : : (97514,)\n",
       "instrument________________________________________ : : (97514, 20)\n",
       "latitude__________________________________________ : : (97514,)\n",
       "location_accuracy_________________________________ : : (97514,)\n",
       "location_method___________________________________ : : (97514,)\n",
       "location_quality__________________________________ : : (97514,)\n",
       "longitude_________________________________________ : : (97514,)\n",
       "number_of_pressure_levels_________________________ : : (97514,)\n",
       "observing_programme_______________________________ : : (97514,)\n",
       "owner_____________________________________________ : : (97514, 20)\n",
       "platform_sub_type_________________________________ : : (97514,)\n",
       "platform_type_____________________________________ : : (97514,)\n",
       "primary_station_id________________________________ : : (97514, 15)\n",
       "primary_station_id_scheme_________________________ : : (97514,)\n",
       "processing_codes__________________________________ : : (97514,)\n",
       "processing_level__________________________________ : : (97514,)\n",
       "product_name______________________________________ : : (97514, 20)\n",
       "product_version___________________________________ : : (97514,)\n",
       "profile_id________________________________________ : : (97514, 20)\n",
       "record_timestamp__________________________________ : : (97514,)\n",
       "references________________________________________ : : (97514, 20)\n",
       "region____________________________________________ : : (97514,)\n",
       "report_duration___________________________________ : : (97514,)\n",
       "report_id_________________________________________ : : (97514, 11)\n",
       "report_meaning_of_timestamp_______________________ : : (97514,)\n",
       "report_quality____________________________________ : : (97514,)\n",
       "report_synoptic_time______________________________ : : (97514,)\n",
       "report_time_accuracy______________________________ : : (97514,)\n",
       "report_time_quality_______________________________ : : (97514,)\n",
       "report_time_reference_____________________________ : : (97514,)\n",
       "report_timestamp__________________________________ : : (97514,)\n",
       "report_type_______________________________________ : : (97514,)\n",
       "sea_level_datum___________________________________ : : (97514,)\n",
       "source_id_________________________________________ : : (97514, 9)\n",
       "source_record_id__________________________________ : : (97514, 20)\n",
       "station_course____________________________________ : : (97514,)\n",
       "station_heading___________________________________ : : (97514,)\n",
       "station_name______________________________________ : : (97514, 25)\n",
       "station_record_number_____________________________ : : (97514,)\n",
       "station_speed_____________________________________ : : (97514,)\n",
       "station_type______________________________________ : : (97514,)\n",
       "string11__________________________________________ : : (11,)\n",
       "string15__________________________________________ : : (15,)\n",
       "string20__________________________________________ : : (20,)\n",
       "string25__________________________________________ : : (20,)\n",
       "string70__________________________________________ : : (20,)\n",
       "string9___________________________________________ : : (9,)\n",
       "sub_region________________________________________ : : (97514,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([3849118240, 3849161784, 3849204640, 3849248079, 3849291056,\n",
       "       3849334398, 3849377518, 3849420628, 3849463845, 3849507003,\n",
       "       3849550217, 3849593454, 3849636666, 3849680440, 3849723123,\n",
       "       3849766228, 3849809658, 3849852628, 3849895825, 3849939201])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[array([  0,   0,   0, ..., 140, 140, 140])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sys.path.append(os.getcwd()+'/../cds-backend/code/')\n",
    "import cds_eua4 as eua\n",
    "\n",
    "with eua.CDMDataset(file) as ofile:\n",
    "    display(ofile)\n",
    "    display(ofile.z_coordinate_type)\n",
    "#     display(ofile.recordindices)\n",
    "#     display(ofile.recordindices.recordtimestamp[-20:])\n",
    "#     display(ofile.recordindices['39'][-20:])\n",
    "    display(ofile.header_table)\n",
    "    display(ofile.header_table.report_timestamp[-20:])\n",
    "    display(ofile.load_variable_from_file(name='observed_variable', group='observations_table', return_data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0ae89-6342-4241-9d34-cc6cd98e3eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UV",
   "language": "python",
   "name": "uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
