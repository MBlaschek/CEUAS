{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import cartopy.crs as ccrs\n",
    "import os,sys\n",
    "import os\n",
    "import json\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import shapely\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from tqdm import tqdm\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools  import partial\n",
    "\n",
    "import numpy\n",
    "import glob\n",
    "import urllib3\n",
    "import h5py\n",
    "import cdsapi, zipfile, os, time\n",
    "import warnings\n",
    "import shutil\n",
    "import xarray\n",
    "from datetime import date\n",
    "warnings.filterwarnings('ignore')\n",
    "import pycountry\n",
    "sys.path.append(os.getcwd()+'/../cds-backend/code/')\n",
    "import cds_eua3 as eua\n",
    "# import numbaprocess\n",
    "import copy\n",
    "import glob\n",
    "from numba import njit\n",
    "import pandas\n",
    "import pickle\n",
    "import matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_WMO_regions_gpd():\n",
    "    \"\"\" Getting the WMO regions json file \"\"\"\n",
    "    WMO_json = 'WMO_regions.json'\n",
    "    if not os.path.isfile(WMO_json):\n",
    "        os.system( 'wget https://cpdb.wmo.int/js/json/WMO_regions.json --no-check-certificate ')\n",
    "\n",
    "    WMO =  gpd.read_file('WMO_regions.json')\n",
    "    return WMO\n",
    "\n",
    "\n",
    "# colorbar\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy\n",
    "\n",
    "def rgb(r,g,b):\n",
    "    return tuple(numpy.asarray([r,g,b],dtype=numpy.float))\n",
    "\n",
    "def make_colormap(seq):\n",
    "        \"\"\"Return a LinearSegmentedColormap\n",
    "        seq: a sequence of floats and RGB-tuples. The floats should be increasing\n",
    "        and in the interval (0,1).\n",
    "        \"\"\"\n",
    "        se = [(None,) * 3, 0.0]\n",
    "        for s in seq:\n",
    "            se.append(s[0])\n",
    "            se.append(s[1])#+ list(seq) +\n",
    "            seq=se+[ (None,) * 3]\n",
    "            cdict = {'red': [], 'green': [], 'blue': []}\n",
    "        for i, item in enumerate(seq):\n",
    "            if isinstance(item, float):\n",
    "                r1, g1, b1 = seq[i - 1]\n",
    "                r2, g2, b2 = seq[i + 1]\n",
    "                cdict['red'].append([item, r1, r2])\n",
    "                cdict['green'].append([item, g1, g2])\n",
    "                cdict['blue'].append([item, b1, b2])\n",
    "        return mcolors.LinearSegmentedColormap('CustomMap', cdict)\n",
    "\n",
    "rgblist=[\"rgb(0,0,0.3)\", \"rgb(0,0,0.5)\",\n",
    "                 \"rgb(0,0,0.7)\", \"rgb(0,0,0.9)\", \"rgb(0,0.15,1)\",\n",
    "                 \"rgb(0,0.3,1)\", \"rgb(0,0.45,1)\", \"rgb(0,0.6,1)\",\n",
    "                 \"rgb(0,0.75,1)\", \"rgb(0,0.85,1)\", \"rgb(0.2,0.95,1)\",\n",
    "                 \"rgb(0.45,1,1)\", \"rgb(0.75,1,1)\", \"rgb(1,1,0)\",\n",
    "                 \"rgb(1,0.9,0)\", \"rgb(1,0.8,0)\", \"rgb(1,0.7,0)\",\n",
    "                 \"rgb(1,0.6,0)\", \"rgb(1,0.5,0)\", \"rgb(1,0.4,0)\",\n",
    "                 \"rgb(1,0.3,0)\", \"rgb(1,0.15,0)\", \"rgb(0.9,0,0)\",\n",
    "                 \"rgb(0.7,0,0)\", \"rgb(0.5,0,0)\", \"rgb(0.3,0,0)\"]\n",
    "rgblist2=zip([eval(rgblist[l]) for l in range(len(rgblist))],numpy.linspace(0,1,len(rgblist)))\n",
    "                 \n",
    "CM = make_colormap(rgblist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(file = '', var='ta'):\n",
    "    \n",
    "    df = xr.load_dataset(file).to_dataframe()\n",
    "    df.reset_index(inplace=True)  \n",
    "    return df\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_gpd(df, var, press, size, date, text=''):\n",
    "\n",
    "#def make_plot_gpd(WMO, sc = '', database = '', date = '', what = 'a', press = 85000, size = 10 ):\n",
    "    # https://stackoverflow.com/questions/59417997/how-to-plot-a-list-of-shapely-points                                                                                                                                                                                                   \n",
    "\n",
    "    date_s = date\n",
    "    date = np.datetime64(date.split('T')[0])\n",
    "    \n",
    "    WMO =  loading_WMO_regions_gpd()\n",
    "\n",
    "    \"\"\" Loading from geopandas built-in methods \"\"\"\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    #world = gpd.read_file('Europe_coastline.shp')\n",
    "    #world = world.query( 'continent == \"Europe\"' )\n",
    "    w = world.plot()\n",
    "\n",
    "    h = date_s.split('T')[1]\n",
    "    if h[0]=='0':\n",
    "        hour = 0\n",
    "    else:\n",
    "        hour = 12\n",
    "    \"\"\" Select data from DF \"\"\"\n",
    "    reduced = df.loc[ (df['pressure']==press) & (df['time']==date) & (df['hour']==hour) ]\n",
    "\n",
    "    points_lat = reduced['lat'].values\n",
    "    points_lon = reduced['lon'].values\n",
    "    anomaly = reduced[ var + '_anomaly'].values\n",
    "    average = reduced[ var + '_average'].values\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    def plot(what = ''):\n",
    "        w = world.plot()\n",
    "        WMO.plot( ax=w,  facecolor=\"none\", edgecolor=\"lightgray\", lw = 0.8)        \n",
    "        plt.xlim([-180.,180.])\n",
    "        plt.ylim([-95.,95.])   \n",
    "        \n",
    "        if size == 10:\n",
    "            marker_size = 75\n",
    "        elif size == 5:\n",
    "            marker_size = 17\n",
    "        \n",
    "        x_t = list(range(-180,181,30))\n",
    "        y_t = [ -90,-70,-50,-30,-10,0,10,30,50,70,90]\n",
    "        y_t_l = ['90S','70S','50S','30S','10S','0','10N','30N','50N','70N','90N']\n",
    "        x_t_l = ['180W','150W','120W','90W','60W','30W','0','30E','60E','90E','120E','150E','180E']\n",
    "    \n",
    "        plt.xticks(x_t, x_t_l, rotation=45, fontsize = 7)\n",
    "        plt.yticks(y_t, y_t_l, fontsize = 7)\n",
    "        \n",
    "        if what == 'anomaly':\n",
    "            plt.scatter( points_lon, points_lat , c= anomaly,  s = marker_size, marker = 's', cmap='bwr', alpha = 0.8, \n",
    "                     edgecolor = 'black' , linewidths=0.3 )\n",
    "            cbar = plt.colorbar(fraction=0.03, pad=0.03) # pad moves bar to left-right, fractions is the length of the bar        \n",
    "            cbar.set_label('Temperature Anomaly over 20 years [K]')\n",
    "            plt.clim(-5, 5)\n",
    "            \n",
    "        elif what == 'average':\n",
    "            plt.scatter( points_lon, points_lat , c= average,  s = marker_size, marker = 's', cmap= CM , alpha = 0.8,\n",
    "                     edgecolor = 'black' , linewidths=0.3)\n",
    "        \n",
    "            cbar = plt.colorbar(fraction=0.03, pad=0.03) # pad moves bar to left-right, fractions is the length of the bar        \n",
    "            cbar.set_label('Average Temperature [K]')\n",
    "            plt.clim(200, 330)\n",
    "        \n",
    "        \n",
    "        #leg = plt.legend(fontsize = 7, loc = 'lower left', framealpha = 1, facecolor = 'lime')\n",
    "        #for lh in leg.legendHandles: \n",
    "        #    lh.set_alpha(1)\n",
    "\n",
    "        plt.title (text + ' Climate Studies using Radiosonde Data - ' + date_s + ', p=' +  str(press)[:-2] + ' [hPa] ' , fontsize = 8)\n",
    "        plt.savefig(out_dir + '/ClimateChange_' + date_s + '_' + what + '_' + '_plevel_' + str(press) + '_gridsize_' + \n",
    "                    str(size) + '_' + text + '_netCDFgridded.png', dpi= 150,   bbox_inches = 'tight' )\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        print('Done +++' , date , ' ' , what )\n",
    "        \n",
    "    dummy = plot(what='anomaly')\n",
    "    dummy = plot(what='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-05 09:57:37,698 INFO Welcome to the CDS\n",
      "2021-03-05 09:57:37,699 INFO Sending request to https://sis-dev.climate.copernicus.eu/api/v2/resources/insitu-comprehensive-upper-air-observation-network\n",
      "2021-03-05 09:57:37,947 INFO Request is completed\n",
      "2021-03-05 09:57:37,948 INFO Downloading http://136.156.132.176/cache-compute-0002/cache/data1/adaptor.comprehensive_upper_air.retrieve-1614934256.1681364-27835-7-d9c16690-40f7-4d5d-8143-7b3eadb66d83.zip to download.zip (113.5K)\n",
      "2021-03-05 09:57:38,060 INFO Download rate 1023.6K/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request took: 0.28009510040283203 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Requesting data from CDS \"\"\"\n",
    "def request(rqdict, source='', remove_file=True):\n",
    "    t0 = time.time()\n",
    "\n",
    "    c = cdsapi.Client()\n",
    "    r = c.retrieve(source, rqdict)\n",
    "    print('Request took: ' + str(time.time() - t0) + ' seconds')\n",
    "    if True:\n",
    "        r.download(target='download.zip')\n",
    "        assert os.stat('download.zip').st_size == r.content_length, \"Downloaded file is incomplete\"\n",
    "    z = zipfile.ZipFile('download.zip')\n",
    "    z.extractall(path='./download/')\n",
    "    z.close()\n",
    "    \n",
    "    \n",
    "    file = glob.glob('./download/*.nc')[0]\n",
    "    return file \n",
    "   \n",
    "   \n",
    "\n",
    "cuon = 'insitu-comprehensive-upper-air-observation-network'\n",
    "\n",
    "\n",
    "\n",
    "#std_plevs    = [1000, 2000, 3000, 5000, 7000, 10000, 15000, 20000, 25000, 30000, 40000, 50000, 70000, 85000, 92500, 100000]\n",
    "plevels = [ 10000, 50000, 92500 ]\n",
    "\n",
    "\n",
    "out_dir = 'Plots/CDS'\n",
    "os.system('mkdir ' + out_dir )\n",
    "var = 'ta'\n",
    "\n",
    "\n",
    "\"\"\" Selecting the dates \"\"\"\n",
    "days = [ '1990-06-15T12:00' ,  '2019-06-15T12:00' ,  '2019-06-15T00:00' ]\n",
    "mind, maxd = '19900615' , '20190615' \n",
    "\n",
    "\"\"\" Download the file from CDS \"\"\"\n",
    "file_cds = request({ 'variable':['temperature'],'gridded': [0,0,60,30],'date': [mind, maxd], 'time':12, 'pressure_level':500}, source=cuon, remove_file=True)\n",
    "df_cds = read(file = file_cds, var='ta')\n",
    "a = make_plot_gpd (df_cds , var , 50000, 10, '2019-06-15T12:00', text = 'CDS') # text will appear in the title and in the file name as extra string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'request' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-538a4ca0bb80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_cds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m'variable'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'temperature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'gridded'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'time'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pressure_level'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcuon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_cds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_cds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ta'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_plot_gpd\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf_cds\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2019-06-15T12:00'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'CDS'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# text will appear in the title and in the file name as extra string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'request' is not defined"
     ]
    }
   ],
   "source": [
    "file_cds = request({ 'variable':['temperature'],'gridded': [0,-180,90,180],'date': [mind, maxd], 'time':12, 'pressure_level':500}, source=cuon, remove_file=True)\n",
    "df_cds = read(file = file_cds, var='ta')\n",
    "a = make_plot_gpd (df_cds , var , 50000, 10, '2019-06-15T12:00', text = 'CDS') # text will appear in the title and in the file name as extra string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
