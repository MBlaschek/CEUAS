{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fe2b790-dfd9-4bc1-a696-3740d6ad0c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no config found\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import netCDF4\n",
    "import matplotlib.pylab as plt\n",
    "import os,sys,glob\n",
    "from multiprocessing import Pool\n",
    "#import odb\n",
    "from eccodes import *\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "import subprocess\n",
    "import json\n",
    "import gzip\n",
    "import copy\n",
    "import pickle\n",
    "import xarray as xr\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from pandas import Timestamp\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as maplt\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(os.getcwd()+'/../cds-backend/code/')\n",
    "import cds_eua4 as eua\n",
    "import trajectory as trj\n",
    "\n",
    "import h5py\n",
    "import ray\n",
    "# ray.init(num_cpus=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efc38e55-84c1-4b1c-b91a-2a33efd39a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx]\n",
    "\n",
    "def drop_dims(input_array):\n",
    "    input_array = np.array(input_array)\n",
    "    dim = []\n",
    "    for i in list(np.shape(input_array)):\n",
    "        if i != 1:\n",
    "            dim.append(i)\n",
    "    return input_array.reshape(dim)\n",
    "\n",
    "def datetime_to_seconds(dates, ref='1900-01-01T00:00:00'):\n",
    "    \"\"\" from datetime64 to seconds since 1900-01-01 00:00:00\"\"\"\n",
    "    return ((dates - np.datetime64(ref)) / np.timedelta64(1, 's')).astype(np.int64)\n",
    "\n",
    "def seconds_to_datetime(seconds, ref='1900-01-01'):\n",
    "    \"\"\" from seconds to datetime64 \"\"\"\n",
    "    seconds = np.asarray(seconds)\n",
    "    return pd.to_datetime(seconds, unit='s', origin=ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e020f11-998a-483b-8bdb-e527e4e896db",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2000\n",
    "mon = 1\n",
    "sid = 'AUM00011035'\n",
    "conv_file = glob.glob('/mnt/users/staff/uvoggenberger/scratch/RHARM_2/*' + str(sid) + '.nc')[0]\n",
    "\n",
    "dt_from = datetime_to_seconds(np.datetime64(str(year)+'-01-01'))\n",
    "dt_to = datetime_to_seconds(np.datetime64(str(year)+'-12-31'))\n",
    "\n",
    "df_dict = {}\n",
    "h_df_dict = {}\n",
    "\n",
    "with h5py.File(conv_file, 'r') as file:\n",
    "    rts = file['datum'][:]\n",
    "    idx = np.where(np.logical_and((rts >= dt_from), (rts <= dt_to)))[0]\n",
    "    if len(idx) == 0:\n",
    "        print('(1) NO DATA FOUND IN IGRA: ', sid)\n",
    "\n",
    "    h_idx = idx\n",
    "    t_idx = idx\n",
    "    plevs = [1000,2000,3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,70000,85000,92500,100000]\n",
    "    mask = file['press'][t_idx[0]:t_idx[-1]]\n",
    "    mask = np.isin(mask,plevs)\n",
    "\n",
    "    h_mask = mask\n",
    "    t_len = len(mask[mask == True])\n",
    "\n",
    "    df_dict['press'] = list(file['press'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['date_time'] = list(file['datum'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['ta'] = list(file['ta'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['u'] = list(file['u'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['v'] = list(file['v'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['latitude'] = list(file['lat'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['longitude'] = list(file['lon'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['rh'] = list(file['rh'][h_idx[0]:h_idx[-1]][h_mask])\n",
    "\n",
    "    df_dict['date_time'] = seconds_to_datetime(df_dict['date_time'])\n",
    "    df = pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "files = glob.glob('/mnt/scratch/scratch/leo/scratch/era5/gridded/era5fct.'+str(year)+str(mon).zfill(2)+'*.130.nc')[0]\n",
    "ds_fc = xr.load_dataset(files)\n",
    "\n",
    "look_at = df[df.date_time.dt.month == mon]\n",
    "look_at = np.unique(look_at.date_time)\n",
    "for i in look_at[:15]:\n",
    "    var_list = []\n",
    "    undis_list = []\n",
    "    cuon_list = []\n",
    "    cuon_press = []\n",
    "    \n",
    "    out_dict = {}\n",
    "    ds_fc_time = ds_fc.sel(time=i, method='nearest')\n",
    "    station_lat = df.latitude.iloc[0]\n",
    "    station_lon = df.longitude.iloc[0]\n",
    "    lon = station_lon\n",
    "    if lon < 0:\n",
    "        lon = 360.+lon\n",
    "    ds_now = ds_fc_time.interp(latitude=[station_lat], method=\"linear\").interp(longitude=[lon], method='linear')\n",
    "    undis_list = np.array(ds_now.t) ########### !\n",
    "    \n",
    "    for j in np.array(ds_fc_time.level): #10,20,...,1000\n",
    "        step = find_nearest(df.press, j*100)\n",
    "        input_data_step = df[df.press == step]\n",
    "        station_lat = df.latitude.iloc[0] + np.array(input_data_step.latitude_displacement)[0]\n",
    "        station_lon = df.longitude.iloc[0] + np.array(input_data_step.longitude_displacement)[0]\n",
    "        lon = station_lon\n",
    "        if lon < 0:\n",
    "            lon = 360.+lon\n",
    "\n",
    "        \n",
    "        ds_now = ds_fc_time.interp(latitude=[station_lat], longitude=[lon], method=\"linear\")\n",
    "        var = ds_now.t.sel(level = j) ######### !\n",
    "        var_list.append(float(var))\n",
    "        cv = df[np.logical_and(df.date_time == i,  df.press == step)].observation_value.values\n",
    "        cuon_list.append((np.nan if len(cv) == 0 else float(cv[0])))\n",
    "        cuon_press.append(step)\n",
    "        \n",
    "    out_dict['era5_displaced'] = drop_dims(var_list)\n",
    "    out_dict['era5'] = drop_dims(undis_list)\n",
    "    out_dict['cuon'] = drop_dims(cuon_list)\n",
    "    \n",
    "    out_dict['pressure'] = drop_dims(ds_fc_time.level) * 100.\n",
    "    out_dict['cuon_pressure']= drop_dims(cuon_press)\n",
    "    out_df = pd.DataFrame.from_dict(out_dict)\n",
    "\n",
    "    lineplt = px.line(\n",
    "        title = str(sid) + ' ' + str(i),\n",
    "        data_frame = out_df,\n",
    "        x=['era5_displaced', 'era5', 'cuon'],\n",
    "        y='pressure',\n",
    "        # color= 'Country',\n",
    "        hover_name='pressure',\n",
    "        width= 1000, height=1000,\n",
    "        # color_discrete_sequence=['rgb(23, 153, 59)','rgb(214, 163, 21)','rgb(40, 48, 165)', 'rgb(210, 0, 38)'],\n",
    "    )\n",
    "    lineplt['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "    lineplt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6a539-2e05-4f8e-98d7-3094423b3ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06e7bb27-1a6c-4737-9150-9957fab33657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['datum', 'hour', 'lat', 'lon', 'press', 'pressure', 'rh', 'station', 'ta', 'time', 'u', 'v']>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([  1000.,   2000.,   3000.,   5000.,   7000.,  10000.,  15000.,\n",
       "        20000.,  25000.,  30000.,  40000.,  50000.,  70000.,  85000.,\n",
       "        92500., 100000.], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File(conv_file, 'r') as file:\n",
    "    display(file.keys())\n",
    "    display(file['press'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ad909b0-a5a0-4e62-aa16-5e929944edfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'numpy.ndarray' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[np\u001b[38;5;241m.\u001b[39mlogical_and(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m reltime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdt_from\u001b[49m , df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m reltime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m dt_to)]\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/arraylike.py:60\u001b[0m, in \u001b[0;36mOpsMixin.__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ge__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/series.py:6096\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6093\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6095\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6096\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:293\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:82\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.conda/envs/uvn10/lib/python3.10/site-packages/pandas/_libs/ops.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'numpy.ndarray' and 'str'"
     ]
    }
   ],
   "source": [
    "df[np.logical_and(df[' reltime'] >= dt_from , df[' reltime'] < dt_to)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37e69923-3b02-4350-965d-cc09d3ffe6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2000-01-01')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3368bd-06a6-44b9-89a6-559ad298eace",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2000\n",
    "mon = 1\n",
    "sid = '11035'\n",
    "conv_file = glob.glob('/mnt/users/scratch/leo/scratch/converted_v9/*' + sid + '*_CEUAS_merged_v1.nc')[0]\n",
    "\n",
    "dt_from = datetime_to_seconds(np.datetime64(str(year)+'-01-01'))\n",
    "dt_to = datetime_to_seconds(np.datetime64(str(year)+'-12-31'))\n",
    "\n",
    "df_dict = {}\n",
    "h_df_dict = {}\n",
    "\n",
    "with h5py.File(conv_file, 'r') as file:\n",
    "    rts = file['recordindices']['recordtimestamp'][:]\n",
    "    idx = np.where(np.logical_and((rts >= dt_from), (rts <= dt_to)))[0]\n",
    "    if len(idx) == 0:\n",
    "        print('(1) NO DATA FOUND IN CONVERTED_V9: ', sid)\n",
    "\n",
    "    h_idx = file['recordindices']['139'][idx]\n",
    "    t_idx = file['recordindices']['126'][idx]\n",
    "    plevs = [1000,2000,3000,5000,7000,10000,15000,20000,25000,30000,40000,50000,70000,85000,92500,100000]\n",
    "\n",
    "\n",
    "    mask = file['observations_table']['z_coordinate'][t_idx[0]:t_idx[-1]]\n",
    "    mask = np.isin(mask,plevs)\n",
    "\n",
    "    h_mask = file['observations_table']['z_coordinate'][h_idx[0]:h_idx[-1]]\n",
    "    h_mask = np.isin(h_mask,plevs)\n",
    "\n",
    "    t_len = len(mask[mask == True])\n",
    "\n",
    "    df_dict['z_coordinate'] = list(file['observations_table']['z_coordinate'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['date_time'] = list(file['observations_table']['date_time'][t_idx[0]:t_idx[-1]][mask])\n",
    "#             df_dict['observation_value'] = list(file['observations_table']['observation_value'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['latitude'] = list(file['observations_table']['latitude'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['longitude'] = list(file['observations_table']['longitude'][t_idx[0]:t_idx[-1]][mask])\n",
    "    repid = np.asarray(file['observations_table']['report_id'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['report_id'] = list(repid.view('|S{}'.format(repid.shape[1])).flatten().astype(str))\n",
    "\n",
    "    df_dict['latitude_displacement'] = list(file['advanced_homogenisation']['latitude_displacement'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['longitude_displacement'] = list(file['advanced_homogenisation']['longitude_displacement'][t_idx[0]:t_idx[-1]][mask])\n",
    "    df_dict['time_since_launch'] = list(file['advanced_homogenisation']['time_since_launch'][t_idx[0]:t_idx[-1]][mask])\n",
    "\n",
    "    h_df_dict['z_coordinate'] = list(file['observations_table']['z_coordinate'][h_idx[0]:h_idx[-1]][h_mask])\n",
    "    h_df_dict['date_time'] = list(file['observations_table']['date_time'][h_idx[0]:h_idx[-1]][h_mask])\n",
    "    h_df_dict['observation_value'] = list(file['observations_table']['observation_value'][h_idx[0]:h_idx[-1]][h_mask])\n",
    "\n",
    "    df_dict['variable'] = ['v']*t_len\n",
    "\n",
    "    df_dict['date_time'] = seconds_to_datetime(df_dict['date_time'])\n",
    "    df = pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "    h_df_dict['date_time'] = seconds_to_datetime(h_df_dict['date_time'])\n",
    "    h_df = pd.DataFrame.from_dict(h_df_dict)\n",
    "\n",
    "    # put dfs together:\n",
    "    df = df.merge(h_df, how='inner', on=['date_time','z_coordinate'])\n",
    "\n",
    "\n",
    "files = glob.glob('/mnt/scratch/scratch/leo/scratch/era5/gridded/era5fct.'+str(year)+str(mon).zfill(2)+'*.132.nc')[0]\n",
    "ds_fc = xr.load_dataset(files)\n",
    "\n",
    "look_at = df[df.date_time.dt.month == mon]\n",
    "look_at = np.unique(look_at.date_time)\n",
    "for i in look_at[:15]:\n",
    "    var_list = []\n",
    "    undis_list = []\n",
    "    cuon_list = []\n",
    "    cuon_press = []\n",
    "    \n",
    "    out_dict = {}\n",
    "    ds_fc_time = ds_fc.sel(time=i, method='nearest')\n",
    "    station_lat = df.latitude.iloc[0]\n",
    "    station_lon = df.longitude.iloc[0]\n",
    "    lon = station_lon\n",
    "    if lon < 0:\n",
    "        lon = 360.+lon\n",
    "    ds_now = ds_fc_time.interp(latitude=[station_lat], longitude=[lon], method=\"linear\")\n",
    "    undis_list = np.array(ds_now.v)\n",
    "    \n",
    "    for j in np.array(ds_fc_time.level): #10,20,...,1000\n",
    "        step = find_nearest(df.z_coordinate, j*100)\n",
    "        input_data_step = df[df.z_coordinate == step]\n",
    "        station_lat = df.latitude.iloc[0] + np.array(input_data_step.latitude_displacement)[0]\n",
    "        station_lon = df.longitude.iloc[0] + np.array(input_data_step.longitude_displacement)[0]\n",
    "        lon = station_lon\n",
    "        if lon < 0:\n",
    "            lon = 360.+lon\n",
    "\n",
    "        \n",
    "        ds_now = ds_fc_time.interp(latitude=[station_lat], longitude=[lon], method=\"linear\")\n",
    "        var = ds_now.v.sel(level = j)\n",
    "        var_list.append(float(var))\n",
    "        cv = df[np.logical_and(df.date_time == i,  df.z_coordinate == step)].observation_value.values\n",
    "        cuon_list.append((np.nan if len(cv) == 0 else float(cv[0])))\n",
    "        cuon_press.append(step)\n",
    "        \n",
    "    out_dict['era5_displaced'] = drop_dims(var_list)\n",
    "    out_dict['era5'] = drop_dims(undis_list)\n",
    "    out_dict['cuon'] = drop_dims(cuon_list)\n",
    "    \n",
    "    out_dict['pressure'] = drop_dims(ds_fc_time.level) * 100.\n",
    "    out_dict['cuon_pressure']= drop_dims(cuon_press)\n",
    "    out_df = pd.DataFrame.from_dict(out_dict)\n",
    "\n",
    "    lineplt = px.line(\n",
    "        title = str(sid) + ' ' + str(i),\n",
    "        data_frame = out_df,\n",
    "        x=['era5_displaced', 'era5', 'cuon'],\n",
    "        y='pressure',\n",
    "        # color= 'Country',\n",
    "        hover_name='pressure',\n",
    "        width= 1000, height=1000,\n",
    "        # color_discrete_sequence=['rgb(23, 153, 59)','rgb(214, 163, 21)','rgb(40, 48, 165)', 'rgb(210, 0, 38)'],\n",
    "    )\n",
    "    lineplt['layout']['yaxis']['autorange'] = \"reversed\"\n",
    "    lineplt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c9f6ba5d-71e8-41f3-9017-3a1bdaf6346e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>era5_displaced</th>\n",
       "      <th>era5</th>\n",
       "      <th>cuon</th>\n",
       "      <th>pressure</th>\n",
       "      <th>cuon_pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.327043</td>\n",
       "      <td>6.599079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.624808</td>\n",
       "      <td>7.503764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.413554</td>\n",
       "      <td>10.205155</td>\n",
       "      <td>36.859203</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.715236</td>\n",
       "      <td>9.543031</td>\n",
       "      <td>29.885841</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.076183</td>\n",
       "      <td>9.108226</td>\n",
       "      <td>24.620193</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.984727</td>\n",
       "      <td>10.608481</td>\n",
       "      <td>14.488888</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.373085</td>\n",
       "      <td>12.583600</td>\n",
       "      <td>17.854160</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>15000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.353759</td>\n",
       "      <td>13.184678</td>\n",
       "      <td>16.914467</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.810933</td>\n",
       "      <td>11.671628</td>\n",
       "      <td>21.297953</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.869077</td>\n",
       "      <td>12.429174</td>\n",
       "      <td>19.917156</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>30000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.479813</td>\n",
       "      <td>8.129689</td>\n",
       "      <td>18.384777</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>40000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9.341615</td>\n",
       "      <td>8.473711</td>\n",
       "      <td>18.840498</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.159952</td>\n",
       "      <td>8.098823</td>\n",
       "      <td>7.070664</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.227932</td>\n",
       "      <td>7.150432</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>85000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.062904</td>\n",
       "      <td>7.048820</td>\n",
       "      <td>-7.778174</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>92500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.756692</td>\n",
       "      <td>4.756692</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    era5_displaced       era5       cuon  pressure  cuon_pressure\n",
       "0         2.327043   6.599079        NaN    1000.0         1000.0\n",
       "1         7.624808   7.503764        NaN    2000.0         2000.0\n",
       "2        10.413554  10.205155  36.859203    3000.0         3000.0\n",
       "3         7.715236   9.543031  29.885841    5000.0         5000.0\n",
       "4         9.076183   9.108226  24.620193    7000.0         7000.0\n",
       "5        10.984727  10.608481  14.488888   10000.0        10000.0\n",
       "6        13.373085  12.583600  17.854160   15000.0        15000.0\n",
       "7        14.353759  13.184678  16.914467   20000.0        20000.0\n",
       "8        12.810933  11.671628  21.297953   25000.0        25000.0\n",
       "9        12.869077  12.429174  19.917156   30000.0        30000.0\n",
       "10        8.479813   8.129689  18.384777   40000.0        40000.0\n",
       "11        9.341615   8.473711  18.840498   50000.0        50000.0\n",
       "12        8.159952   8.098823   7.070664   70000.0        70000.0\n",
       "13        7.227932   7.150432  -3.500000   85000.0        85000.0\n",
       "14        7.062904   7.048820  -7.778174   92500.0        92500.0\n",
       "15        4.756692   4.756692  -5.000000  100000.0       100000.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8bf5069-0032-45e7-a6b8-17459575a149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.17377851, 15.51925622, 18.59532102, 25.20482479, 29.15550479,\n",
       "       25.05850861, 24.98092437, 23.09036804, 23.62125107, 20.19012695,\n",
       "       16.35775046, 12.8530231 ,  9.29385183,  5.74726214,  3.20873402,\n",
       "        2.05549003])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undis_list.reshape()flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d1ac2c6-eb3a-493b-a224-9a0fe7dbf0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.17377851, 15.51925622, 18.59532102, 25.20482479, 29.15550479,\n",
       "       25.05850861, 24.98092437, 23.09036804, 23.62125107, 20.19012695,\n",
       "       16.35775046, 12.8530231 ,  9.29385183,  5.74726214,  3.20873402,\n",
       "        2.05549003])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_dims(undis_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792956eb-0495-4c06-ba87-4598e9faf1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uvn10",
   "language": "python",
   "name": "uvn10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
